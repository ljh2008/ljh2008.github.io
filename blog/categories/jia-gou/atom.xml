<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[☺分类☺：架构 | 刘江华的博客]]></title>
  <link href="http://yanyaner.com/blog/categories/jia-gou/atom.xml" rel="self"/>
  <link href="http://yanyaner.com/"/>
  <updated>2014-06-04T13:59:08+08:00</updated>
  <id>http://yanyaner.com/</id>
  <author>
    <name><![CDATA[冰雨]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[分布式文件系统fastdfs解析-配置]]></title>
    <link href="http://yanyaner.com/blog/2014/06/03/fastDFS-config/"/>
    <updated>2014-06-03T15:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/06/03/fastDFS-config</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;我计划在两台服务器上安装fdfs，ip分别是:192.168.68.133（1号服务器）, 192.168.68.136（2号服务器），fdfs在两台服务器上的安装部署图如下。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/05/fdfs_deploy.jpg' width='' height='' title='fastdfs部署示意图'><span class='caption-text'>fastdfs部署示意图</span></span></p>

<p>&emsp;&emsp;1号服务器上安装tracker实例一个，storage实例2个，分别位于group1,group2两个不同的组中；2号服务器上也安装tracker实例一个，storage实例1个，这个storage和1号服务器中的其中一个storage位于同一个组中。下面给大家贴出具体配置。</p>

<p>&emsp;&emsp;1号服务器中，我们先： vim /usr/local/fastdfs/conf/storage_ids.conf</p>

<p>```</p>

<h1><id>  &lt;group_name>  &lt;ip_or_hostname></h1>

<p>100001   group1  192.168.68.133
100002   group2  192.168.68.133
100003   group1  192.168.68.136
```</p>

<p>&emsp;&emsp;在这个文件中为所有存储服务器指定id, 这样可以免更换ip带来的影响，也就是说当服务器ip发生改变后只需要更改这个文件中的ip地址即可。</p>

<p>&emsp;&emsp;编辑tracker.conf，vim /usr/local/fastdfs/conf/tracker.conf配置文件，以下仅仅列出我改过的或者我认为需要给大家说明的配置项，没有贴出的均保持配置文件中的默认值。</p>

<p>```</p>

<h1>the tracker server port</h1>

<p>port=22122</p>

<h1>the base path to store data and log files</h1>

<p>base_path=/var/fastdfs/tracker</p>

<h1>the method of selecting group to upload files</h1>

<h1>0: round robin</h1>

<h1>1: specify group</h1>

<h1>2: load balance, select the max free space group to upload file</h1>

<p>store_lookup=2</p>

<h1>which group to upload file</h1>

<h1>when store_lookup set to 1, must set store_group to the group name</h1>

<p>store_group=group2</p>

<h1>unix group name to run this program,</h1>

<h1>not set (empty) means run by the group of current user</h1>

<p>run_by_group=</p>

<h1>unix username to run this program,</h1>

<h1>not set (empty) means run by current user</h1>

<p>run_by_user=</p>

<h1>if use storage ID instead of IP address</h1>

<h1>default value is false</h1>

<h1>since V4.00</h1>

<p>use_storage_id = true</p>

<h1>the max time of storage sync a file</h1>

<h1>default value is 300 seconds</h1>

<h1>since V2.00</h1>

<p>storage_sync_file_max_time = 300</p>

<p>```</p>

<p>&emsp;&emsp;现对上面列出的一些配置项进行解释：</p>

<p>&emsp;&emsp;<strong>port</strong>：tracker服务器的端口号，如果一台服务器上要运行多个tracker实例就需要更改此端口号以避免冲突。</p>

<p>&emsp;&emsp;<strong>base_path</strong>：tracker自身配置信息以及日志信息保存的位置，这个目录本不会占用太大的空间，但日志文件会随着使用而慢慢变大。</p>

<p>&emsp;&emsp;<strong>store_lookup</strong>：负载分配机制，2表示选择存储空间最大的组来保存文件。</p>

<p>&emsp;&emsp;<strong>run_by_group，run_by_user</strong>：指定运行tracker的用户组及用户，这是为了保存系统的安全，我们一般会为fdfs新建组及用户。</p>

<p>&emsp;&emsp;<strong>use_storage_id</strong>：使用存储服务器id替代ip地址，我们刚才编辑的storage_ids.conf中指定了每个实例的id。</p>

<p>&emsp;&emsp;<strong>storage_sync_file_max_time</strong>：同一组中的不同storate进行文件同步的时间，默认是5分钟内完成同步，你可以根据实际情况把这个值改小（改变这个值后可以观察到文件同步的效果，这个值不要设置得太小以避免造成系统同步网络压力）。</p>

<p>&emsp;&emsp;接下来我们配置本台服务器上的storage实例，先配置storage1.conf实例，这个实例位于group1中。</p>

<p>&emsp;&emsp;vim /usr/local/fastdfs/conf/storage1.conf，同样限于篇幅，我仅仅贴出重要配置项，其它的使用默认值。<!-- more--></p>

<p>```</p>

<h1>the name of the group this storage server belongs to</h1>

<p>group_name=group1</p>

<h1>the storage server port</h1>

<p>port=23001</p>

<h1>the base path to store data and log files</h1>

<p>base_path=/var/fastdfs/storage1</p>

<h1>store_path#, based 0, if store_path0 not exists, it&rsquo;s value is base_path</h1>

<h1>the paths must be exist</h1>

<p>store_path0=/var/fastdfs/store_group1_path0</p>

<h1>tracker_server can ocur more than once, and tracker_server format is</h1>

<h1>&ldquo;host:port&rdquo;, host can be hostname or ip address</h1>

<p>tracker_server=192.168.68.133:22122
tracker_server=192.168.68.136:22122</p>

<p>run_by_group=
run_by_user=</p>

<p>```
&emsp;&emsp;现在对上面的配置项进行解释：</p>

<p>&emsp;&emsp;<strong>group_name</strong>：本storage实例所属的组名称。</p>

<p>&emsp;&emsp;<strong>port</strong>：storage的端口号，同一组的storage实例必须采用同样的端口号，这就是说同一组中的storage实例必须部署在不同学的机器上，因为同一台机器上的端口号不能相同。</p>

<p>&emsp;&emsp;<strong>base_path</strong>：本storage的配置数据及运行日志文件存放的位置，和tracker中的base_path含义相同。</p>

<p>&emsp;&emsp;<strong>store_path0</strong>：真正的用户上传文件保存的位置目录，fastDfs会在该目录下新建许多子目录，在第一次启动实例时会进行这个操作。store_path可以有多个，一般可以分配成单独的磁盘挂载点。</p>

<p>&emsp;&emsp;<strong>tracker_server</strong>：指定本storaged的信息会注册到哪些tracker中去，故这里的tracker_server可以配置多个。</p>

<p>&emsp;&emsp;<strong>run_by_group、run_by_user</strong>与tracker中的含义相同，不再细说。</p>

<p>&emsp;&emsp;接下来，我们再来看本服务器上的另一个storage实例，这个实例是运行在group2中的，端口号与上面配置的那个storage是不同的，请看配置关键项：</p>

<p>```</p>

<h1>the name of the group this storage server belongs to</h1>

<p>group_name=group2</p>

<h1>the storage server port</h1>

<p>port=23002</p>

<p>base_path=/var/fastdfs/storage2</p>

<h1>store_path#, based 0, if store_path0 not exists, it&rsquo;s value is base_path</h1>

<h1>the paths must be exist</h1>

<p>store_path0=/var/fastdfs/store_group2_path0</p>

<h1>tracker_server can ocur more than once, and tracker_server format is</h1>

<h1>&ldquo;host:port&rdquo;, host can be hostname or ip address</h1>

<p>tracker_server=192.168.68.133:22122</p>

<p>```</p>

<p>&emsp;&emsp;上面配置文件中的内容和storage1.conf中的类似，只不过group_name、port不相同，两个文件的保存路径也是不同的，经过这些配置后，我们就可以启动服务实例了。</p>

<p>&emsp;&emsp;先来启动tracker实例，先编辑启动脚本文，vim /etc/init.d/fdfs_trackerd。</p>

<p>``` sh fdfs_trackerd</p>

<h1>!/bin/bash</h1>

<p>#</p>

<h1>fdfs_trackerd Starts fdfs_trackerd</h1>

<p>#
#</p>

<h1>chkconfig: 2345 99 01</h1>

<h1>description: FastDFS tracker server</h1>

<h3>BEGIN INIT INFO</h3>

<h1>Provides: $fdfs_trackerd</h1>

<h3>END INIT INFO</h3>

<h1>Source function library.</h1>

<p>. /etc/init.d/functions
FastDfs=&lsquo;/usr/local/fastdfs&rsquo;
CONF=&ldquo;$FastDfs/conf/tracker.conf&rdquo;
if [ ! -f $CONF ]; then
  echo &ldquo;file $CONF does not exist!&rdquo;
  exit 2
fi
PRG=&ldquo;$FastDfs/bin/fdfs_trackerd&rdquo;
if [ ! -f $PRG ]; then
  echo &ldquo;file $PRG does not exist!&rdquo;
  exit 2
fi
Stop=&ldquo;$FastDfs/bin/stop.sh&rdquo;
if [ ! -f $Stop ]; then
  echo &ldquo;file $Stop does not exist!&rdquo;
  exit 2
fi
Restart=&ldquo;$FastDfs/bin/restart.sh&rdquo;
if [ ! -f $Restart ]; then
  echo &ldquo;file $Restart does not exist!&rdquo;
  exit 2
fi
RETVAL=0
start() {</p>

<pre><code>echo -n $"Starting FastDFS tracker server: "
$PRG $CONF &amp;
RETVAL=$?
echo
return $RETVAL
</code></pre>

<p>}
stop() {</p>

<pre><code>echo -n $"Stop FastDFS tracker server: "
$Stop $PRG $CONF
RETVAL=$?
return $RETVAL
</code></pre>

<p>}
rhstatus() {</p>

<pre><code>status fdfs_trackerd
</code></pre>

<p>}
restart() {</p>

<pre><code>    $Restart $PRG $CONF &amp;
</code></pre>

<p>}
case &ldquo;$1&rdquo; in
  start)</p>

<pre><code>start
;;
</code></pre>

<p>  stop)</p>

<pre><code>stop
;;
</code></pre>

<p>  status)</p>

<pre><code>rhstatus
;;
</code></pre>

<p>  restart|reload)</p>

<pre><code>restart
;;
</code></pre>

<p>  condrestart)</p>

<pre><code>restart
;;
</code></pre>

<p>  *)</p>

<pre><code>echo $"Usage: $0 {start|stop|status|restart|condrestart}"
exit 1
</code></pre>

<p>esac
exit $?
```</p>

<p>&emsp;&emsp;这篇启动脚本中，主要修改的地方是FastDfs及CONF变量参数，这两个用来指定tracker配置文件所在的位置。</p>

<p>&emsp;&emsp;完成编辑后，使用命令：sudo /etc/init.d/fdfs_trackerd start，即可完成服务器的启动，如果启动成功你可通过netstat -lnpt查看到tracker的端口号。</p>

<p>&emsp;&emsp;接下来，将fdfs_storaged拷贝为fdfs_storaged1，用于启动storage1实例，要修改的地方也是FastDfs及CONF参数，这两个参数用来指定storage1.conf文件的在的目录及配置文件的名称。</p>

<p>``` sh fdfs_storaged1</p>

<h1>!/bin/bash</h1>

<p>#</p>

<h1>fdfs_storaged Starts fdfs_storaged</h1>

<p>#
#</p>

<h1>chkconfig: 2345 99 01</h1>

<h1>description: FastDFS storage server</h1>

<h3>BEGIN INIT INFO</h3>

<h1>Provides: $fdfs_storaged</h1>

<h3>END INIT INFO</h3>

<h1>Source function library.</h1>

<p>. /etc/init.d/functions
FastDfs=&lsquo;/usr/local/fastdfs&rsquo;
CONF=&ldquo;$FastDfs/conf/storage1.conf&rdquo;
if [ ! -f $CONF ]; then
  echo &ldquo;file $CONF does not exist!&rdquo;
  exit 2
fi
PRG=&ldquo;$FastDfs/bin/fdfs_storaged&rdquo;
if [ ! -f $PRG ]; then
  echo &ldquo;file $PRG does not exist!&rdquo;
  exit 2
fi
Stop=&ldquo;$FastDfs/bin/stop.sh&rdquo;
if [ ! -f $Stop ]; then
  echo &ldquo;file $Stop does not exist!&rdquo;
  exit 2
fi
Restart=&ldquo;$FastDfs/bin/restart.sh&rdquo;
if [ ! -f $Restart ]; then
  echo &ldquo;file $Restart does not exist!&rdquo;
  exit 2
fi
RETVAL=0
start() {</p>

<pre><code>echo -n $"Starting FastDFS storage server: "
$PRG $CONF &amp;
RETVAL=$?
echo
return $RETVAL
</code></pre>

<p>}
stop() {</p>

<pre><code>echo -n $"Stop FastDFS storage server: "
$Stop $PRG $CONF
RETVAL=$?
return $RETVAL
</code></pre>

<p>}
rhstatus() {</p>

<pre><code>status fdfs_storaged
</code></pre>

<p>}
restart() {</p>

<pre><code>    $Restart $PRG $CONF &amp;
</code></pre>

<p>}
case &ldquo;$1&rdquo; in
  start)</p>

<pre><code>start
;;
</code></pre>

<p>  stop)</p>

<pre><code>stop
;;
</code></pre>

<p>  status)</p>

<pre><code>rhstatus
;;
</code></pre>

<p>  restart|reload)</p>

<pre><code>restart
;;
</code></pre>

<p>  condrestart)</p>

<pre><code>restart
;;
</code></pre>

<p>  *)</p>

<pre><code>echo $"Usage: $0 {start|stop|status|restart|condrestart}"
exit 1
</code></pre>

<p>esac</p>

<p>exit $?
```</p>

<p>&emsp;&emsp;好，该来启动storaged1实例了，命令： sudo /etc/init.d/fdfs_storaged1 start，如果是第一次启动会观察到创建存储目录的过程。</p>

<p>&emsp;&emsp;启动storaged2实例的过程和storaged1相同，先编辑fdfs_storaged2文件，再fdfs_storaged2 start即完成。</p>

<p>&emsp;&emsp;当1号服务器上的fdfs全部服务都成功启动后，我们可以看到如下目录结构会建立起来。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/05/fdfs_dir_struct.jpg' width='' height='' title='fastdfs目录结构'><span class='caption-text'>fastdfs目录结构</span></span></p>

<p>&emsp;&emsp;至此，1号服务器上的所有配置及服务启动工作已经完成。2号服务器的配置及服务实例启动与1号服务器基本相同，惟一需要大家要注意的是group的名称，port端口号等，要和1号服务器相“呼应”，同时，我们在2号服务器上也配置了一个tracker实例以保证高可用性。</p>

<p>&emsp;&emsp;好了，fastDFS的配置先告一段落，下一篇我们来聊聊客户端对fastDFS的调用，除了java客户端外，还包括tengine-2.0.1服务器上访问插件的配置。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分布式文件系统fastdfs解析之一(安装)]]></title>
    <link href="http://yanyaner.com/blog/2014/05/30/fastDFS-setup/"/>
    <updated>2014-05-30T15:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/05/30/fastDFS-setup</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;fastdfs是一个轻量级的分布式文件系统服务，它在互联网项目中有比较广泛的用途，类似的还有tfs等，但fastdfs和hadoop这些又不相同，hadoop是分布式存储计算框架，比较重量级，而fastdfs针对的是海量的小文件。</p>

<p>&emsp;&emsp;项目中经常会有这样一些应用场景，比如：文件服务器需要存储海量的用户文件并且对外提供用户的访问操作；文件服务器需要高可用性和高性能；文件服务器需要实现负载均衡；文件服务器可实时扩容等等，这些需求在Fastdfs中有实现，因此它可以满足大部的项目需求。</p>

<p>&emsp;&emsp;先给大家简单介绍一下fastdfs的原理，下面这张图有助于大家了解分布式文件系统的原理（hadoop之类的分布式体系与之有相似之处）。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/seq_fastdfs.jpg' width='' height='' title='fastdfs调用时序图'><span class='caption-text'>fastdfs调用时序图</span></span></p>

<p>&emsp;&emsp;上面这张图中客户端针对文件服务系统的调用，首先得通过tracker服务器，这个服务器充当了调度者的作用。客户端可以是任何的程序客户端，比如java客户端、php客户端、nginx插件客户端等。</p>

<p>&emsp;&emsp;在客户端调用之前先得启动tracker server，然后再分别启动各个storage server，每个storage server启动后会注册自己的信息到指定的tracker server中（其实，tracker server服务器也可以有多个，从高可用性方面考虑我们一般会启动多个tracker server实例）。</p>

<p>&emsp;&emsp;storage server负责具体文件的存储。storage server按照分组的方式来保存文件的，比如group1,group2等。一个组中可以有多台服务器，同一个组里的所有服务器中保存的文件内容都是相同的，因为同一个组中的服务器之间会相互自动同步文件，这样就实现了冗余备份及负载均衡的功能（负载均衡由tracker server调试的哦）。</p>

<p>&emsp;&emsp;不同组中的storage server之间是独立的，当系统存储容量不够时，通过添加新服务器并分配到新的组中，tracker server发现新的服务器后会自动调度以实现后续客户文件的写入位置。</p>

<p>&emsp;&emsp;上图中，客户通过询问tracker server得到可用的storage server（tracker server会通过负载均衡及各个storage的存储可用容量大小算法决定，当然这个也可以在配置文件中指定），客户端得到storage server后进行相应的文件操作，同组服务器间会根据操作的结果进行文件同步（时序9，10是同步操作）。</p>

<p>&emsp;&emsp;好了，原理先说到这。下面，我将给大家简单介绍FastDfs的安装及使用，以及一些注意事项。</p>

<p>&emsp;&emsp;我的服务器是ubuntu server，我计划安装在两台服务器上，ip分别是:192.168.68.133, 192.168.68.136，暂时简称为1号服务器，2号服务器。</p>

<p>&emsp;&emsp;一号服务器上，将安装一个tracker server实例，一个位于group1中的storage server实例，一个位于group2中storage server实例。</p>

<p>&emsp;&emsp;二号服务器上，也将安装一个tracker server实例，一个位于group1中的storage server实例。需要大家注意的是，fastdfs中一台服务器上可以安装多个组，但一个组中的多个storade server必须安装在不同的服务器上，并且同组中的storage server的服务端口必须一致，否则无法实现文件同步。</p>

<p>&emsp;&emsp;我先在一号服务器192.168.68.133上安装fastdfs。首先要准备安装环境，不同的linux发行版本可能会有所不同，我用的服务器版本是ubuntu 12.04 server，以下的操作均以这个版本的ubuntu服务器为例。<!--more--></p>

<p><code>
vim /etc/profile
export LANGUAGE="en_US.UTF-8"
export LANG=en_US:zh_CN.UTF-8
export LC_ALL=C
</code>
&emsp;&emsp;接下来让语言环境配置参数立即生效：</p>

<p><code>
source /etc/profile
</code>
&emsp;&emsp;再接着，安装fastdfs编译依赖包，大家要注意的是少一个依赖都不行，我先前安装时缺少了libevent-dev，致使安装不成功但安装过程又不报错，花费了大量的时间。</p>

<p>```
aptitude install libevent
apt-get install libevent-dev</p>

<p>sudo apt-get update
sudo aptitude install build-essential m4</p>

<p>sudo ln -s /lib/lsb/init-functions  /etc/init.d/functions</p>

<p>```</p>

<p>&emsp;&emsp;好了，环境准备好了后就到<a href="https://code.google.com/p/fastdfs">fastdfs官网</a>上去下载安装包吧，地址<a href="https://code.google.com/p/fastdfs/downloads/list">https://code.google.com/p/fastdfs/downloads/list</a>，我下载的是
FastDFS_v4.06.tar.gz ，如果你想要安装最新版本，请用svn去下载最新的5.x版本。</p>

<p><code>
tar -zxvf FastDFS_v4.06.tar.gz
cd FastDFS
</code>
&emsp;&emsp;这样就进入了源代码目录，我们先要对安装的目录做一个规划(4.06版本默认的安装目录似乎不太合理)，我将fastdfs的所有文件都安装到/usr/local/fastdfs中，配置文件存放在/usr/local/fastdfs/conf下，这就需要我们修改源代码目录下的make.sh，下面是一些要修改的地方：</p>

<p><code>
vim make.sh
</code></p>

<p>&emsp;&emsp;需要对：</p>

<ol>
<li><p> TARGET_PREFIX，TARGET_CONF_PATH进行修改;</p></li>
<li><p> 需要对libpthread.so、libpthread.a的路径进行修改，这和ubuntu有关，其它linux发行版本并不需要改这个(你可以用find / -name &lsquo;libpthread.so&rsquo;  ，以及ind / -name &lsquo;libpthread.a&rsquo;  找到这两文件在系统中的位置)；</p></li>
<li><p> 另外要对mkdir,cp操作的几个路径进行修改为我们配置文件所在的路径。</p></li>
</ol>


<p>&emsp;&emsp;我贴出make.sh修改过的地方，请大家自行对照：</p>

<p>```
TARGET_PREFIX=/usr/local/fastdfs
TARGET_CONF_PATH=/usr/local/fastdfs/conf</p>

<p>if [ -f /usr/lib/i386-linux-gnu/libpthread.so ] || [ -f /usr/local/lib/libpthread.so ] || [ -f /lib64/libpthread.so ] || [ -f /usr/lib64/libpthread.so ] || [ -f /usr/lib/i386-linux-gnu/libpthread.a ] || [ -f /usr/local/lib/libpthread.a ] || [ -f /lib64/libpthread.a ] || [ -f /usr/lib64/libpthread.a ]; then
&hellip;&hellip;&hellip;&hellip;
&hellip;&hellip;&hellip;&hellip;</p>

<p>if [ &ldquo;$uname&rdquo; = &ldquo;Linux&rdquo; ]; then</p>

<pre><code>if [ "$WITH_LINUX_SERVICE" = "1" ]; then
  if [ ! -d /usr/local/fastdfs/conf ]; then
    mkdir -p /usr/local/fastdfs/conf
    cp -f conf/tracker.conf /usr/local/fastdfs/conf/
    cp -f conf/storage.conf /usr/local/fastdfs/conf/
    cp -f conf/client.conf /usr/local/fastdfs/conf/
    cp -f conf/http.conf /usr/local/fastdfs/conf/
    cp -f conf/mime.types /usr/local/fastdfs/conf/
  fi
</code></pre>

<p>&hellip;&hellip;&hellip;&hellip;</p>

<p>```</p>

<p>&emsp;&emsp;下面开始安装吧，如下命令：</p>

<p><code>
sudo make;
sudo make install;
sudo make clean;
</code>
&emsp;&emsp;不同的linux发行版本可能存在依赖包没有安装而报错，具体情况需要根据出错信息具体解决，我试过redhead,freebsd,openSuse,centos几个系统，都是要进行一些环境的配置才可以安装成功。</p>

<p>&emsp;&emsp;下一篇文章我将按照文章开头的服务器规划进行具体的配置，请大家关注。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[监控系统中的异步消息使用实例（二）]]></title>
    <link href="http://yanyaner.com/blog/2014/04/09/async_message_architect2/"/>
    <updated>2014-04-09T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/04/09/async_message_architect2</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;接上节，再次贴出架构图，我们接下来要讲的是图中黄色部分的配置。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/monitor_jms1.jpg' width='' height='' title='业务方法监控架构'><span class='caption-text'>业务方法监控架构</span></span></p>

<p>&emsp;&emsp;先将spy程序导成一个jar包，加入到需要监控的目标服务器lib目录，monitor_spy.jar结构如下所示：</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/jarinfo.jpg' width='' height='' title='monitor_spy.jar结构'><span class='caption-text'>monitor_spy.jar结构</span></span></p>

<p>&emsp;&emsp;为了能够实现对目标系统业务方法执行情况进行监控，需要将我们已经写好的拦截器配置到目标系统中去，下面是我的一个配置示例：</p>

<p>``` xml spring-spy.xml</p>

<pre><code>&lt;!-- jms连接工厂 --&gt;         
&lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactoryBean"&gt;
    &lt;property name="connectionFactory"&gt;
        &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt;
            &lt;property name="brokerURL" value="tcp://localhost:61616"&gt;&lt;/property&gt;
        &lt;/bean&gt;
    &lt;/property&gt;
    &lt;!-- 配置池中最大连接数据以及最大活动连接数 --&gt;
    &lt;property name="maxConnections" value="100"&gt;&lt;/property&gt;
    &lt;property name="maximumActive" value="100"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- jms模板方法 --&gt;    
&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt;
    &lt;constructor-arg ref="jmsFactory"&gt;
    &lt;/constructor-arg&gt;
    &lt;!-- 默认会创建queue类型的目标
    &lt;property name="defaultDestinationName" value="queue/methodSpyLogger"&gt;&lt;/property&gt; --&gt;
    &lt;property name="defaultDestination" ref="destinationQueue1"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 发送消息的目的地 --&gt;
&lt;bean id="destinationQueue1" class="org.apache.activemq.command.ActiveMQQueue"&gt;
    &lt;!-- 设置消息队列的名字 --&gt;
    &lt;constructor-arg  value="queue/methodSpyLogger" /&gt;
&lt;/bean&gt;


&lt;!-- 配置Spring和方法相关的监控 --&gt;
&lt;bean id="method-pointcut" class="org.springframework.aop.support.JdkRegexpMethodPointcut"&gt;
    &lt;property name="patterns"&gt;
        &lt;list&gt;
            &lt;value&gt;com.lovo.mis.xjgl.service.impl.*&lt;/value&gt;
        &lt;/list&gt;
    &lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 方法AOP拦截器 --&gt;
&lt;bean id="spy-method-interceptor"
      class="com.monitor.client.spy.SpyMethodIntercepter"&gt;
      &lt;property name="messageDao"&gt;
        &lt;bean class="com.monitor.client.dao.JMSMessageDaoImpl"&gt;
            &lt;property name="jmsTemplate" ref="jmsTemplate"&gt;&lt;/property&gt;
        &lt;/bean&gt;
      &lt;/property&gt;
      &lt;property name="userNameSessionKey" value="loginUserName"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 将切面应用到通知上 --&gt;
&lt;aop:config proxy-target-class="true"&gt;
    &lt;aop:advisor advice-ref="spy-method-interceptor"
                 pointcut-ref="method-pointcut" /&gt;
&lt;/aop:config&gt;
</code></pre>

<p>```</p>

<p>&emsp;&emsp;配置文件中有几个地方需要进行说明：<!-- more --></p>

<p>&emsp;&emsp;1、目标机器要修改的部分是JdkRegexpMethodPointcut中的patterns，由patterns指定需要监控的业务类所在的位置。</p>

<p>&emsp;&emsp;2、jmsFactory部分配置你的异步消息服务器连接信息，比如brokerURL等。</p>

<p>&emsp;&emsp;3、jmsTemplate中，通过defaultDestination指定一个Destination，因为一个消息服务器上存在多个Destination。也可以通过defaultDestinationName直接指定消息Destination的名称，系统默认创建的是queue，也就是说，如果你要使用topic类型的消息，就必须通过defaultDestination指定一个Destination。</p>

<p>&emsp;&emsp;4、messageDao可自由替换为其它实现类，比如你可以写一个mongoDB版本的实现以提供更好的性性，支持更大数据量。</p>

<p>&emsp;&emsp;最后来看看消费者代码，是直接使用ActiveMQ驱动实现的。</p>

<p>``` java</p>

<pre><code>    ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory("tcp://localhost:61616");

    Connection connection = factory.createConnection();

    //尝试真正建立连接，这里可以catch Exception
    connection.start();

    //得到一个会话，只有得到会话后，才可进行后续的操作
    Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);

    //创建一个目标队列
    Destination queue = session.createQueue("queue/methodSpyLogger"); 

    MessageConsumer consumer = session.createConsumer(queue);

    //可通过其它一些机制，来改变flag为false，以退出处理
    boolean flag = true;

    while (flag) {
        ObjectMessage msg = (ObjectMessage)consumer.receive();
        MethodLoggerMessage myMsg = (MethodLoggerMessage)msg.getObject();

        System.out.println(myMsg);
        //这里，可调用dao或service，向关系数据库(或nosql)中保存msg中的内容");

    }

    session.close();

    connection.close();
</code></pre>

<p>```</p>

<p>&emsp;&emsp;注意，如果队列中已经没有消息了，代码中的consumer.receive()会阻塞，直到有新的消息后再处理。我们也可以采用监听器的方式来处理消息服务器中的消息，比如下面的代码：</p>

<p>``` java</p>

<pre><code>    //处理消息者
    MessageConsumer consumer = session.createConsumer(queue);

    //处理多条消息
    consumer.setMessageListener(new MessageListener() {
        public void onMessage(Message msg) {
           //转换，这可以对类型进行检测，使用instance of
            TextMessage txtMsg = (TextMessage)msg;
            try {
                System.out.println("得到消息内容："+txtMsg.getText());
                System.out.println("处理完一条消息！！");
                //如果开启了事务，请session.commit();
            } catch (JMSException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
            }
        }
    });
</code></pre>

<p>```</p>

<p>&emsp;&emsp;当目标程序运行时，我们可以打开ActiveMQ的管理界面，即可发现这个queue及上面的消费者。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/active_mq_admin.jpg' width='' height='' title='ActiveMQ的管理界面'><span class='caption-text'>ActiveMQ的管理界面</span></span></p>

<p>&emsp;&emsp;大家还要注意的是，我们的AOP通知中，还获取了调用者的ip，访问者姓名等信息，这些和web环境相关的信息是通过类似于下面的代码实现的：</p>

<p>``` java</p>

<p>ServletRequestAttributes sas = (ServletRequestAttributes)RequestContextHolder.getRequestAttributes();
HttpServletRequest req = sas.getRequest();</p>

<p>logger.setIp(req.getLocalAddr());
logger.setSessionId(sas.getSessionId());</p>

<p>if (req.getSession() != null) {</p>

<pre><code>logger.setOperater((String)req.getSession().getAttribute(userNameSessionKey));
</code></pre>

<p>}</p>

<p>```
 &emsp;&emsp;其中的RequestContextHolder是由spring封装，具体做法是将用户web相关的信息通过filter或listener放入ThreadLocal对象中，在需要的地方通过RequestContextHolder从ThreadLocal中取得，因此，你想让上面的代码正常工作，要记得在web.xml中添加一个spring已经写好的RequestContextListener监听器哦。</p>

<p>``` xml  web.xml</p>

<pre><code>&lt;listener&gt;
    &lt;listener-class&gt;
        org.springframework.web.context.request.RequestContextListener
    &lt;/listener-class&gt;
&lt;/listener&gt;
</code></pre>

<p>```</p>

<p> &emsp;&emsp;当然，本例中所使用的消息服务器是ActiveMQ，这个服务器实现了JMS规范，在企业级应用场景中不会存在问题。如果在互联网行业中，由于会面临高并发、大流量等情况，ActiveMQ不能保证高可用性、稳定性及性能要求，这个时候我们可以考虑其它的第三方消息服务器，比如淘宝的taobao-metaq，alibaba-rocketmq等，这些服务器是经过实际考验的开源产品，值得在互联网场景中使用。当然，这些MQ服务器和JMS规范没有任何关系，JMS企业级要求中并没有考虑过多的并发、大数据量的需求。</p>

<p> &emsp;&emsp;另外，kafka，rabbitmq等消息服务器也具有不错的性能，都可以进入架构的技术方案选型范围。比如，下面是一段rabbitmq的调用示例代码(注：rabbitmq需要er_lang并发程序包支持哦)，和JMS的调用相当类似。</p>

<p>``` java
import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;</p>

<p>&hellip;&hellip;.//略去代码</p>

<pre><code>@Test
public void testSendMessage() throws Exception {
    SimpleDateFormat sf = new SimpleDateFormat("yyyy-MM-dd hh:mm:ss");

    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");

    Connection connection = factory.newConnection();
    Channel channel = connection.createChannel();

    String message = sf.format(new Date()) + ":Hello!!!";
    channel.basicPublish("", "queue/sendEmail", null, message.getBytes());


    channel.close();
    connection.close();

    System.out.println("send message ok!");



}


@Test
public void testReciveMessage() throws Exception {

    System.out.println("recever starting.....");

    String QUEUE_NAME = "queue/sendEmail";

    SimpleDateFormat sf = new SimpleDateFormat("yyyy-MM-dd hh:mm:ss");

    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");

    Connection connection = factory.newConnection();
    Channel channel = connection.createChannel();

    channel.queueDeclare(QUEUE_NAME, false, false, false, null);

    QueueingConsumer consumer = new QueueingConsumer(channel);
    channel.basicConsume(QUEUE_NAME, false, consumer);

    QueueingConsumer.Delivery delivery = consumer.nextDelivery();

    String msg = new String(delivery.getBody());

    System.out.println(msg);

    System.out.println("rec end!!!");
}
</code></pre>

<p>```</p>

<p> &emsp;&emsp;先说到这吧。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[监控系统中的异步消息使用实例（一）]]></title>
    <link href="http://yanyaner.com/blog/2014/04/08/async_message_architect1/"/>
    <updated>2014-04-08T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/04/08/async_message_architect1</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;以后的文章要尽量做到通俗，让非技术人员都读得懂，道理就跟艺术作品一样，一件好的作品，不需要配任何文字说明就足以打动普通观众，做到雅俗共赏而且有深度和内涵，其实，这需要作者相当的功力。</p>

<p>&emsp;&emsp;近期一些童鞋在实现一个监控系统，其中的一个功能是：对监控平台上布署的第三方应用业务方法执行细节进行监控，比如：方法调用者，调用者ip，应用系统名称，子系统名称，方法名称，执行耗时等信息。如何能够让监控系统得到目标机器上需要监控的业务方法执行情况呢？如何保证在监控的过程中不影响对方的业务的正常执行？下面我给出一种参考架构实现，这也是在概要设计的时候就应该明确的东西（专业名词叫架构原型）。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/monitor_jms1.jpg' width='' height='' title='业务方法监控架构'><span class='caption-text'>业务方法监控架构</span></span></p>

<p>&emsp;&emsp;首先，MonitorPlatform是我们的监控平台（图中青色部分），targetServer上运行着需要监控的系统hotel project（图中黄色部分）,如果我们想要获得目标机器上的我们需要的信息，最简单的办法是运行一个spy程序在对方的机器上，图中的spy app是起这个作用的（当然你也可以使用jmx规范来实现类似功能），举个不恰当的例子，就好比你在某人的机器上安装了一个木马程序，通过远程控制端你就可以得到对方机器上你感兴趣的任何东西，甚至包括控制摄像头哦。</p>

<p>&emsp;&emsp;其次，监控平台同时要监控多个目标系统，就我们例子中监控业务方法执行情况而言，就需要把监控得到的信息加以持久化以备后查，如果目标系统业务繁忙，而我们的spy app又要将取到的信息进行数据库持久化，数据库很可能会成为性能瓶颈从而造成性能问题，因此，我在这里采用了异步消息系统的设计，以缓解持久化压力。正如图所示，spy app将采集到的业务方法执行数据直接写入异步消息服务器的queue中，而monitor platform中的处理程序将从queue中取出消息，再进行后续的持久化处理。这种异步的消息设计方式可以有效缓解系统的压力，在很多项目中都可以采用（互联网项目中可用这种方式来"削峰"，缓解高并发压力）。</p>

<p>&emsp;&emsp;最后一个问题,spy如何采集到目标机器业务方法的执行情况呢。最佳答案当然是AOP。大家可以参考我的另一篇文章<a href="/blog/2013/03/26/logger/">一种日志记录解决方案</a>。</p>

<p>&emsp;&emsp;下面，我们一起来看看架构原型中的原代码实现吧。MethodLoggerMessage是需要持久化的消息对象，请注意实现Serializable接口。<!-- more --></p>

<p>``` java MethodLoggerMessage.java</p>

<p>package com.monitor.client.commons;</p>

<p>import java.io.Serializable;
import java.util.Date;</p>

<p>/<em>*
 * 需要持久化的对象消息
 * @author ljh
 *
 </em>/
public class MethodLoggerMessage implements Serializable {</p>

<pre><code>//方法执行时间，单位：毫秒
private double howLong;
//方法名
private String methodName;
//执行者ip地址
private String ip;
//执行者session会话id
private String sessionId;
//执行者
private String operater = "";
//执行时间
private Date execTimer;

public double getHowLong() {
    return howLong;
}
public void setHowLong(double howLong) {
    this.howLong = howLong;
}
public String getMethodName() {
    return methodName;
}
public void setMethodName(String methodName) {
    this.methodName = methodName;
}
public String getIp() {
    return ip;
}
public void setIp(String ip) {
    this.ip = ip;
}
public String getOperater() {
    return operater;
}
public void setOperater(String operater) {
    this.operater = operater;
}
public String getSessionId() {
    return sessionId;
}
public void setSessionId(String sessionId) {
    this.sessionId = sessionId;
}
public Date getExecTimer() {
    return execTimer;
}
public void setExecTimer(Date execTimer) {
    this.execTimer = execTimer;
}
@Override
public String toString() {
    return "MethodLoggerMessage [howLong=" + howLong + ", methodName="
            + methodName + ", ip=" + ip + ", sessionId=" + sessionId
            + ", operater=" + operater + ", execTimer=" + execTimer + "]";
}
</code></pre>

<p>```</p>

<p>&emsp;&emsp;IMessageDao接口用来定义消息持久化行为，可以有很同种不同的实现版本，如基于消息的，关系数据库的或nosql的等等，有了这个接口，我们在intercepter中就可以做到拦截代码和持久化代码的解耦。</p>

<p>``` java IMessageDao.java
package com.monitor.client.dao;</p>

<p>import java.io.Serializable;</p>

<p>/<em>*
 * 持久化消息服务
 * @author ljh
 *
 </em>/
public interface IMessageDao {</p>

<pre><code>public void persist(Serializable msg);
</code></pre>

<p>}
```</p>

<p>&emsp;&emsp;接下来是消息持久化实现类源代码。因为采用了jms，因此我直接使用了spring对jms封装的模板方法实现。</p>

<p>``` java JMSMessageDaoImpl.java
package com.monitor.client.dao;</p>

<p>import java.io.Serializable;</p>

<p>import javax.jms.JMSException;
import javax.jms.Message;
import javax.jms.ObjectMessage;
import javax.jms.Session;</p>

<p>import org.springframework.jms.core.JmsTemplate;
import org.springframework.jms.core.MessageCreator;</p>

<p>/<em>*
 * jms消息处理实现
 * @author ljh
 *
 </em>/
public class JMSMessageDaoImpl implements IMessageDao {</p>

<pre><code>//jms模板
private JmsTemplate jmsTemplate;
//目标队列名称
private String destinationName;

@Override
public void persist(final Serializable msg) {

    MessageCreator mc = new MessageCreator() {

        @Override
        public Message createMessage(Session session) throws JMSException {
            //创建对象消息，并发送之
            ObjectMessage objMsg = session.createObjectMessage();   
            objMsg.setObject(msg);

            return objMsg;
        }
    };

    if (destinationName == null) {
        jmsTemplate.send(mc);
    } else {
        //发送到指定的目标
        jmsTemplate.send(destinationName, mc);
    }


}

public void setJmsTemplate(JmsTemplate jmsTemplate) {
    this.jmsTemplate = jmsTemplate;
}

public void setDestinationName(String destinationName) {
    this.destinationName = destinationName;
}
</code></pre>

<p>}
```</p>

<p>&emsp;&emsp;最重要的就是这个拦截器实现了。环绕拦截器，功能最为强大。</p>

<p>``` java SpyMethodIntercepter.java
package com.monitor.client.spy;</p>

<p>import java.util.Date;</p>

<p>import javax.servlet.http.HttpServletRequest;</p>

<p>import org.aopalliance.intercept.MethodInterceptor;
import org.aopalliance.intercept.MethodInvocation;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.DisposableBean;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;</p>

<p>import com.monitor.client.commons.MethodLoggerMessage;
import com.monitor.client.dao.IMessageDao;
/<em>*
 * 目标服务器方法拦截器，调用信息可以通过异步消息机制持久化，具体要看IMessageDao实现
 * @author ljh
 *
 </em>/
public class SpyMethodIntercepter implements MethodInterceptor{</p>

<pre><code>public static final Logger LOG = LoggerFactory.getLogger(SpyMethodIntercepter.class);

//消息处理dao
private IMessageDao messageDao;
//当前登录者在目标系统中的登录用户名之key,在配置第三方程序时注入
private String userNameSessionKey = "loginedUserName";

@Override
public Object invoke(MethodInvocation method) throws Throwable {

    //取方法执行时的开始时间
    long start = System.nanoTime();

    try {
        return method.proceed();
    } catch (Exception ex) {
        throw ex;
    } finally {

        try {
            //为了不影响目标方法的运行，这里再次try
            //得到访问者request对象
            ServletRequestAttributes sas = (ServletRequestAttributes)RequestContextHolder.getRequestAttributes();
            HttpServletRequest req = sas.getRequest();

            //取方法执行后的时间
            long end = System.nanoTime();

            //方法执行时间
            long howLong = end - start;
            String methodName = method.getMethod().getName();

            //持久化方法调用日志
            MethodLoggerMessage logger = new MethodLoggerMessage();

            logger.setMethodName(methodName);

            //方法执行时间，单位：毫秒
            logger.setHowLong((double)howLong/(1000*1000));

            logger.setIp(req.getLocalAddr());
            logger.setSessionId(sas.getSessionId());

            if (req.getSession() != null) {
                logger.setOperater((String)req.getSession().getAttribute(userNameSessionKey));
            }

            logger.setExecTimer(new Date());

            messageDao.persist(logger);
        } catch (Exception exc) {
            //do nothing or LOG.debug(ex.getMessage());
            LOG.warn("Error in spy: {}", exc);
        }

    }

}

public void setMessageDao(IMessageDao messageDao) {
    this.messageDao = messageDao;
}

public void setUserNameSessionKey(String userNameSessionKey) {
    this.userNameSessionKey = userNameSessionKey;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;至此，spy程序这边基本开发完成了。目标服务器上，该如何配置呢？监控平台的消息处理者又该如何实现呢？</p>

<p>&emsp;&emsp;且听下回分解。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[读写分离架构之mysql实例]]></title>
    <link href="http://yanyaner.com/blog/2014/03/10/db-read-write-split/"/>
    <updated>2014-03-10T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/10/db-read-write-split</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;读写分离架构对提升系统性能非常重要，特别是在互联网项目中，查询操作可能达到90%以上，而且有较高的并发性。</p>

<p>&emsp;&emsp;对于数据库的读写分离，即是把所有的增、删、改操作发送到主数据库，所有查询操作发送到从数据库，通过增加从数据库实例个数以提升查询性能。当然也可以使用noSql数据库(如mongodb,hbase等)、搜索引擎（如lucene）等技术来做查询，关系数据库做核心数据保存，这种方式也是基于读写分离架构。</p>

<p>&emsp;&emsp;更多性能优化文章，大家可以参考我的文章：
<a href="/blog/2010/11/05/prof-web/">系统性能优化总结之表现层</a>，<a href="/blog/2010/11/08/prof-service/">系统性能优化总结之业务层</a>，<a href="/blog/2010/11/09/prof-dao/">系统性能优化总结之持久层篇</a>，技术在不断发展，这三篇文章是几年前写的，目前看来少了很多东西，我后续将把一些近年来新的内容添加上去以符合一些新的场景。</p>

<p>&emsp;&emsp;目前很多数据库都支持主从复制，读写分离，如：Oracle， SqlServer， Mysql等，主数据库在写入数据时同时同步到从数据库。此文以mysql为例给大家加以介绍。网上也有很多这样的文章，大家可以去搜索阅读，但这些文章基本上都是基于*inux平台的，我将以windows平台的配置为例（其实原理都是一样的，只是配置上的一些差异而已）。</p>

<p>&emsp;&emsp;简单起见，机器用我的笔记本。localhost:3307为主服务器master，localhost:3308为从属服务器slave（可以增加多个slave），mysql版本为5.6。先配置主服务器，编辑my.ini，内容如下：<!-- more--></p>

<p>``` ini</p>

<p>[mysqld]
 basedir =D:/server/db/MySQL Server5.6
 datadir =D:/server/db/mysql_db1/dbfile
 port = 3307
 server_id = 1
 log-bin=mysql-bin</p>

<p> skip-character-set-client-handshake
 init-connect = &lsquo;SET NAMES utf8&rsquo;
 character_set_server=utf8
 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</p>

<p>```</p>

<p>&emsp;&emsp;从属数据库配置是(和主服务器的差别在于port、server_id与datadir不同)：</p>

<p><code>ini
[mysqld]
 basedir =D:/server/db/MySQL Server5.6
 datadir =D:/server/db/mysql_db2/dbfile
 port = 3308
 server_id = 10
 log-bin=mysql-bin
 skip-character-set-client-handshake
 init-connect = 'SET NAMES utf8'
 character_set_server=utf8
 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
</code></p>

<p>&emsp;&emsp;为了方便启动，把这两个数据库都注册为win服务，命令如下：</p>

<p>```
 D:\server\db\MySQL Server5.6\bin>mysqld
 &mdash;install mysql5.6.master
 &mdash;defaults-file=D:\server\db\mysql_db1\my.ini</p>

<p>```</p>

<p>&emsp;&emsp;从属服务器的注册与之类似不在写出，我们接下来在系统服务中分别启动这两个服务器实例。</p>

<p>&emsp;&emsp;再接下来要做的事情是配置主从复制功能，主服务器的增、删、改数据操作都将同步到多台从属服务器上，先在主服务器上给从属服务器分配登录账号，这个账号将是从属服务器进行数据同步操作的授权，命令如下（账号是backup，密码是123）：</p>

<p>```
GRANT REPLICATION SLAVE ON
<em>.</em> to &lsquo;backup&rsquo;@&lsquo;localhost&rsquo;
identified by &lsquo;123’;</p>

<p>```</p>

<p>&emsp;&emsp;继续命令行中运行：show master status; 记录下File及Position两个输出内容，这两个参数在配置slave时需要用到。</p>

<p>&emsp;&emsp;登录从服务器，执行下面的命令：</p>

<p><code>
change master to
master_host=’localhost’,
master_port=3307,
master_user=’backup’,
master_password=’123’,
master_log_file=’mysql-bin.000006’,
master_log_pos=120;
</code></p>

<p>&emsp;&emsp;上面命令中的master_host及master_port是主服务器的地址和端口号，master_user及master_password是授权命令输入的账号、密码，master_log_file及master_log_pos是show master status输出的东西。</p>

<p>&emsp;&emsp;接下来，从属服务器上运行start slave就可以启动从属服务，运行show slave status\G查看状态，如果输出的Slave_IO_Running和Slave_SQL_Running都是yes，则表示配置成功（如果配置有误，可stop slave服务，再次运行change master命令）。</p>

<p>&emsp;&emsp;至此，mysql的主从复制功能就配置完成了。也许你会说，我们的所有增、删、改通过对localhost:3307这个数据库操作，查询通过localhost:3308这个数据库操作不就完成了么？确实如你所说，这种方案是可行的，我们可以在spring中配置两个Datasource，并在技术架构上进行处理，把查询接口单独封装出来以使用不同的数据源。大家可以到我的博客文章<a href="/blog/2010/11/01/p4/">四种持久层设计方案比较</a>中，查看其中的方案三设计。</p>

<p>&emsp;&emsp;当然，上面的访问方式也是有缺陷的，主要体现在，读写分离操作对应用程序并不透明，比如有多台读服务器，你的读操作数据源该如何去配置呢？读写分离会影响到应用代码？因此，我们还得寻找另一种对应用透明的访问方式，这就是用代理模式，屏蔽底层访问细节，这个代理类来负责低层的读写分离，缓存连接（相当于连接池），还包括读操作的负载均衡。</p>

<p>&emsp;&emsp;mysql-proxy就是这样一个程序，我下载的是mysql-proxy-0.8.4-win32-x86.zip，解压后运行bin中的mysql-proxy.exe即可。如果mysql-proxy.exe无法运行，可能是缺少vc2008支持包，大家到微软官网下载vcredist_x86.exe并安装。</p>

<p>&emsp;&emsp;为了后期运行方便，可以配置一个bat批处理文件，启动代理程序：</p>

<p><code>
D:\server\db\mysql-proxy\bin\mysql-proxy.exe
 --proxy-backend-addresses=localhost:3307
 --proxy-read-only-backend-addresses=localhost:3308
 --proxy-lua-script=D:\server\db\mysql-proxy\share\doc\mysql-proxy\rw-splitting.lua
</code></p>

<p>&emsp;&emsp;上面的配置中大家要注意：proxy-read-only-backend-addresses可以写多台服务器，用逗号分割开；rw-splitting.lua是读写分离lua脚本文件，您可以进行编辑以符合你的要求（比如有人修改min_idle_connections及max_idle_connections来观察到读写分离的效果），但一般情况下并不需要；你可以通过&mdash;proxy-address=host:port指定代理服务器端口号，如果不指定默认为4040(另，管理端口默认是4041，可以看到一些状态参数)。</p>

<p>&emsp;&emsp;应用程序中通过连接localhost:4040即可操作mysql数据库了，后台的一切都是通过mysql-proxy去处理的，数据库连接对应用程序变得透明了，我们的任务也就完成了。</p>

<p>&emsp;&emsp;下篇给出读写分离的性能测试数据。</p>
]]></content>
  </entry>
  
</feed>
