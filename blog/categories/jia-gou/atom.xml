<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[☺分类☺：架构 | 刘江华的博客]]></title>
  <link href="http://yanyaner.com/blog/categories/jia-gou/atom.xml" rel="self"/>
  <link href="http://yanyaner.com/"/>
  <updated>2014-07-16T14:54:07+08:00</updated>
  <id>http://yanyaner.com/</id>
  <author>
    <name><![CDATA[冰雨]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[spring mvc 表现层测试]]></title>
    <link href="http://yanyaner.com/blog/2014/07/15/spring-mvc-test/"/>
    <updated>2014-07-15T15:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/07/15/spring-mvc-test</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;表现层、业务层、持久层是一个经典的分层架构，在构建软件系统时，一般会从持久层开始，逐渐向上层编码、构建，每一层完成编码后必须保证正确后，再写上一层，这就像修房子一样，打牢地基再砌墙。</p>

<p>&emsp;&emsp;另外需提一下，一般公司的项目中对持久层都有通用的封装（比如baseDao），因此，持久层的代码在这种情况下就表现为ORM注解或sql语句块，如果是hibernate注解，在项目启动时就可以发现大部分配置上的错误，如果是mybatis或ibatis依旧可以放到业务层中去测试。因此，我认为持久层不用专门去写测试代码了，我们针对业务层的测试即可发现持久层的问题。</p>

<p>&emsp;&emsp;还有，表现层在采用了restful及json数据返回格式后，前端的交互编码其实可以很早就进行，即和后台编码同步进行，我计划有时间去实现一个这样的模拟系统服务器，在设计人员完成rest api设计后，就可以将api输入这个模拟服务器系统，前端程序员依照rest api就可以和模拟服务器交互了，这样前后台就可以分工同步开发了，效率一定会提升哦。</p>

<p>&emsp;&emsp;言归正传，下面我主要来讲讲服务器端的action测试，因为在这个时候，我们还没有任何界面交互，而仅仅只有一个restful api。如何对action进行测试，在早期的spring版本中还比较困难，网上很多同学都是自己封装，但依然不方便不强大。好消息是从spring 3.2开始，提供了对spring mvc完善的支持，请看下面的这个登录action代码及测试。<!-- more--></p>

<p>``` java LoginAction.java
/<em>*
 * 登录系统
 * @author ljh
 *
 </em>/
@Controller
public class LoginAction {</p>

<pre><code>@Resource
private IUserService userService;

@Resource
private JsonMapper jm;


@RequestMapping(value="/login", method=RequestMethod.GET)
public void loginSystem(
        @Valid User user,
        BindingResult result,
        HttpSession session,
        HttpServletResponse resp
        ) throws Exception {

    resp.setCharacterEncoding("utf-8");

    RespMessage respMsg = new RespMessage();

    if (respMsg.sendValidationFaildResponse(result, jm, resp)) {
        return ;
    }

    try {
        User u = userService.login(user.getCode(), user.getPassword());
        session.setAttribute(IConst.LOGIN_USER_SESSION_KEY, u);
        respMsg.setData(u);

    } catch (Exception ex) {
        respMsg.setCode(RespMessage.FAIL);
        respMsg.setMsg(ex.getMessage());
    }

    jm.writeValue(new FilterProvider()
    .addIncludeProperties("video_user", "id", "name", "classes") 
    .addIncludeProperties("video_classes", "id" ,"name")
    ,resp.getOutputStream(), respMsg);

}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;对上面这个rest方法如何进行测试呢？非常简单，代码如下：</p>

<p>``` java LoginActionTest.java</p>

<p>import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.http.MediaType;
import org.springframework.test.context.ContextConfiguration;
import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;
import org.springframework.test.context.web.WebAppConfiguration;
import org.springframework.test.web.servlet.MockMvc;
import org.springframework.test.web.servlet.request.MockMvcRequestBuilders;
import org.springframework.test.web.servlet.result.MockMvcResultHandlers;
import org.springframework.test.web.servlet.result.MockMvcResultMatchers;
import org.springframework.test.web.servlet.setup.MockMvcBuilders;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.web.context.WebApplicationContext;</p>

<p>import static org.springframework.test.web.servlet.result.MockMvcResultHandlers.<em>;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.</em>;
import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;</p>

<p>@RunWith(SpringJUnit4ClassRunner.class)
@Transactional
@WebAppConfiguration
@ContextConfiguration(value={&ldquo;classpath:config/spring/spring*.xml&rdquo;})
public class LoginActionTest {</p>

<pre><code>@Resource
private WebApplicationContext wac;

private MockMvc mvc;



@Before
public void setup() {
    mvc = MockMvcBuilders.webAppContextSetup(wac).build();
}



@Test
public void testLogin() throws Exception {

    mvc
    .perform(get("/login").param("name", "ljh").param("password", "123"))
    .andExpect(status().isOk()) //状态码200
    .andExpect(content().string("{msg:10}"))
    .andExpect(content().contentType(MediaType.APPLICATION_JSON))
    .andExpect(jsonPath("$.msg").value(10))
    .andDo(print());


}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;上面的代码，有几个地方需要给大家解释：</p>

<p>&emsp;&emsp;<strong>MockMvc</strong>:这个类是一个核心类，测试必须通过这个类来实现。MockMvc如何实例化呢？这行代码：<strong>MockMvcBuilders</strong>.webAppContextSetup(wac).build()即可实例化，其中的wac需要由容器注入，类型是WebApplicationContext。</p>

<p>&emsp;&emsp;有同学在这个地方或许有点疑问，在没有启动tomcat之类容器的情况下，如何能注入<strong>WebApplicationContext</strong>啊？答案就是类顶上书写的<strong>@WebAppConfiguration</strong>注解，细心的同学会发现，本测试类和service中的测试类上面写的注解基本相同，惟独多了@WebAppConfiguration注解，正因为这个注解所起的作用，使用WebApplicationContext可以注入。</p>

<p>&emsp;&emsp;接下来，我们来看真正的测试方法，在测试过程中，我们主要会做三个事情：</p>

<p>&emsp;&emsp;<strong>1、构建请求，然后执行</strong>。</p>

<p>&emsp;&emsp;请求的构建，需要用到MockMvcRequestBuilders类，这个类可以产生get、post、put、delete等各种请求以及填充参数，构建好请求后，通过perform方法提交这个请求。</p>

<p>&emsp;&emsp;<strong>2、验证请求结果和预期是否一切。</strong></p>

<p>&emsp;&emsp;请求的验证通过MockMvcResultMatchers这个类来做，我们可以从很多方面来验证结果和你预期是否一致，比如：状态码，响应内容，响应视图名称，响应类型码等，上例中我们就使用了status、content、contentType等，更详细的东东请大家去翻阅spring api文档吧。</p>

<p>&emsp;&emsp;<strong>3、打印输出请求与响应的结果（这一步可选，不是必须的哦）。</strong></p>

<p>&emsp;&emsp;MockMvcResultHandlers这个类用来对结果进行处理，比如通过print方法打印，spring mvc对测试结果处理的封装目前仅仅提供了打印这个处理，其它的可由我们自己去实现哦。当然，你也可以将输入的json结果copy出来，放入图形化工具中，人工检查是否正确，可使用的gui工具有JsonView.exe，自己可从网上下载到哦。</p>

<p>&emsp;&emsp;当然，上面都是针对的是json restful结果的断言，如果是传统的mvc方式，又该是如何验证呢？请看示例代码，包含了对跳转页面资源的验证以及对作用域中值的验证等功能：</p>

<p>``` java</p>

<pre><code>            .andExpect(status().isOk())
            .andExpect(view().name("main"))
            .andExpect(MockMvcResultMatchers.forwardedUrl("main"))
            .andExpect(forwardedUrl("main"))
            .andExpect(model().attributeExists("user_key"))
</code></pre>

<p>```</p>

<p>&emsp;&emsp;如果你的需求中需要上传文件，又怎么测试呢？不要着急，spring mvc已经为我们考虑到了这些，代码如下：</p>

<p>``` java</p>

<p>mvc.perform(</p>

<pre><code>            fileUpload("/login")
            .file(
                    new MockMultipartFile("photo", "database.properties", MediaType.IMAGE_JPEG_VALUE, FileUtils.readFileToByteArray(
                            new ClassPathResource("database.properties").getFile())))
                .param("code", "001")
                .param("password", "123")

            )
            .andExpect(status().isOk())
            .andDo(print());
</code></pre>

<p>```</p>

<p>&emsp;&emsp;我们自己实例化了一个MockMultipartFile，并指定了一些参数，比如文件字段名，原始文件名，内容类型，文件内容等。有一点要提醒大家的是，在你的Action中，一定要用MultipartFile类型来接收文件参数，而不是用CommonsMultipartFile哦，切记（其实这也是您对依赖倒转原则理解的体现哦）。</p>

<p>&emsp;&emsp;各位，时间关系，先写到这，以后再补充。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分布式文件系统fastdfs解析之二(配置)]]></title>
    <link href="http://yanyaner.com/blog/2014/06/03/fastDFS-config/"/>
    <updated>2014-06-03T15:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/06/03/fastDFS-config</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;我计划在两台服务器上安装fdfs，ip分别是:192.168.68.133（1号服务器）, 192.168.68.136（2号服务器），fdfs在两台服务器上的安装部署图如下。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/05/fdfs_deploy.jpg' width='' height='' title='fastdfs部署示意图'><span class='caption-text'>fastdfs部署示意图</span></span></p>

<p>&emsp;&emsp;1号服务器上安装tracker实例一个，storage实例2个，分别位于group1,group2两个不同的组中；2号服务器上也安装tracker实例一个，storage实例1个，这个storage和1号服务器中的其中一个storage位于同一个组中。下面给大家贴出具体配置。</p>

<p>&emsp;&emsp;1号服务器中，我们先： vim /usr/local/fastdfs/conf/storage_ids.conf</p>

<p>```</p>

<h1><id>  &lt;group_name>  &lt;ip_or_hostname></h1>

<p>100001   group1  192.168.68.133
100002   group2  192.168.68.133
100003   group1  192.168.68.136
```</p>

<p>&emsp;&emsp;在这个文件中为所有存储服务器指定id, 这样可以免更换ip带来的影响，也就是说当服务器ip发生改变后只需要更改这个文件中的ip地址即可。</p>

<p>&emsp;&emsp;编辑tracker.conf，vim /usr/local/fastdfs/conf/tracker.conf配置文件，以下仅仅列出我改过的或者我认为需要给大家说明的配置项，没有贴出的均保持配置文件中的默认值。</p>

<p>```</p>

<h1>the tracker server port</h1>

<p>port=22122</p>

<h1>the base path to store data and log files</h1>

<p>base_path=/var/fastdfs/tracker</p>

<h1>the method of selecting group to upload files</h1>

<h1>0: round robin</h1>

<h1>1: specify group</h1>

<h1>2: load balance, select the max free space group to upload file</h1>

<p>store_lookup=2</p>

<h1>which group to upload file</h1>

<h1>when store_lookup set to 1, must set store_group to the group name</h1>

<p>store_group=group2</p>

<h1>unix group name to run this program,</h1>

<h1>not set (empty) means run by the group of current user</h1>

<p>run_by_group=</p>

<h1>unix username to run this program,</h1>

<h1>not set (empty) means run by current user</h1>

<p>run_by_user=</p>

<h1>if use storage ID instead of IP address</h1>

<h1>default value is false</h1>

<h1>since V4.00</h1>

<p>use_storage_id = true</p>

<h1>the max time of storage sync a file</h1>

<h1>default value is 300 seconds</h1>

<h1>since V2.00</h1>

<p>storage_sync_file_max_time = 300</p>

<p>```</p>

<p>&emsp;&emsp;现对上面列出的一些配置项进行解释：</p>

<p>&emsp;&emsp;<strong>port</strong>：tracker服务器的端口号，如果一台服务器上要运行多个tracker实例就需要更改此端口号以避免冲突。</p>

<p>&emsp;&emsp;<strong>base_path</strong>：tracker自身配置信息以及日志信息保存的位置，这个目录本不会占用太大的空间，但日志文件会随着使用而慢慢变大。</p>

<p>&emsp;&emsp;<strong>store_lookup</strong>：负载分配机制，2表示选择存储空间最大的组来保存文件。</p>

<p>&emsp;&emsp;<strong>run_by_group，run_by_user</strong>：指定运行tracker的用户组及用户，这是为了保存系统的安全，我们一般会为fdfs新建组及用户。</p>

<p>&emsp;&emsp;<strong>use_storage_id</strong>：使用存储服务器id替代ip地址，我们刚才编辑的storage_ids.conf中指定了每个实例的id。</p>

<p>&emsp;&emsp;<strong>storage_sync_file_max_time</strong>：同一组中的不同storate进行文件同步的时间，默认是5分钟内完成同步，你可以根据实际情况把这个值改小（改变这个值后可以观察到文件同步的效果，这个值不要设置得太小以避免造成系统同步网络压力）。</p>

<p>&emsp;&emsp;接下来我们配置本台服务器上的storage实例，先配置storage1.conf实例，这个实例位于group1中。</p>

<p>&emsp;&emsp;vim /usr/local/fastdfs/conf/storage1.conf，同样限于篇幅，我仅仅贴出重要配置项，其它的使用默认值。<!-- more--></p>

<p>```</p>

<h1>the name of the group this storage server belongs to</h1>

<p>group_name=group1</p>

<h1>the storage server port</h1>

<p>port=23001</p>

<h1>the base path to store data and log files</h1>

<p>base_path=/var/fastdfs/storage1</p>

<h1>store_path#, based 0, if store_path0 not exists, it&rsquo;s value is base_path</h1>

<h1>the paths must be exist</h1>

<p>store_path0=/var/fastdfs/store_group1_path0</p>

<h1>tracker_server can ocur more than once, and tracker_server format is</h1>

<h1>&ldquo;host:port&rdquo;, host can be hostname or ip address</h1>

<p>tracker_server=192.168.68.133:22122
tracker_server=192.168.68.136:22122</p>

<p>run_by_group=
run_by_user=</p>

<p>```
&emsp;&emsp;现在对上面的配置项进行解释：</p>

<p>&emsp;&emsp;<strong>group_name</strong>：本storage实例所属的组名称。</p>

<p>&emsp;&emsp;<strong>port</strong>：storage的端口号，同一组的storage实例必须采用同样的端口号，这就是说同一组中的storage实例必须部署在不同学的机器上，因为同一台机器上的端口号不能相同。</p>

<p>&emsp;&emsp;<strong>base_path</strong>：本storage的配置数据及运行日志文件存放的位置，和tracker中的base_path含义相同。</p>

<p>&emsp;&emsp;<strong>store_path0</strong>：真正的用户上传文件保存的位置目录，fastDfs会在该目录下新建许多子目录，在第一次启动实例时会进行这个操作。store_path可以有多个，一般可以分配成单独的磁盘挂载点。</p>

<p>&emsp;&emsp;<strong>tracker_server</strong>：指定本storaged的信息会注册到哪些tracker中去，故这里的tracker_server可以配置多个。</p>

<p>&emsp;&emsp;<strong>run_by_group、run_by_user</strong>与tracker中的含义相同，不再细说。</p>

<p>&emsp;&emsp;接下来，我们再来看本服务器上的另一个storage实例，这个实例是运行在group2中的，端口号与上面配置的那个storage是不同的，请看配置关键项：</p>

<p>```</p>

<h1>the name of the group this storage server belongs to</h1>

<p>group_name=group2</p>

<h1>the storage server port</h1>

<p>port=23002</p>

<p>base_path=/var/fastdfs/storage2</p>

<h1>store_path#, based 0, if store_path0 not exists, it&rsquo;s value is base_path</h1>

<h1>the paths must be exist</h1>

<p>store_path0=/var/fastdfs/store_group2_path0</p>

<h1>tracker_server can ocur more than once, and tracker_server format is</h1>

<h1>&ldquo;host:port&rdquo;, host can be hostname or ip address</h1>

<p>tracker_server=192.168.68.133:22122</p>

<p>```</p>

<p>&emsp;&emsp;上面配置文件中的内容和storage1.conf中的类似，只不过group_name、port不相同，两个文件的保存路径也是不同的，经过这些配置后，我们就可以启动服务实例了。</p>

<p>&emsp;&emsp;先来启动tracker实例，先编辑启动脚本文，vim /etc/init.d/fdfs_trackerd。</p>

<p>``` sh fdfs_trackerd</p>

<h1>!/bin/bash</h1>

<p>#</p>

<h1>fdfs_trackerd Starts fdfs_trackerd</h1>

<p>#
#</p>

<h1>chkconfig: 2345 99 01</h1>

<h1>description: FastDFS tracker server</h1>

<h3>BEGIN INIT INFO</h3>

<h1>Provides: $fdfs_trackerd</h1>

<h3>END INIT INFO</h3>

<h1>Source function library.</h1>

<p>. /etc/init.d/functions
FastDfs=&lsquo;/usr/local/fastdfs&rsquo;
CONF=&ldquo;$FastDfs/conf/tracker.conf&rdquo;
if [ ! -f $CONF ]; then
  echo &ldquo;file $CONF does not exist!&rdquo;
  exit 2
fi
PRG=&ldquo;$FastDfs/bin/fdfs_trackerd&rdquo;
if [ ! -f $PRG ]; then
  echo &ldquo;file $PRG does not exist!&rdquo;
  exit 2
fi
Stop=&ldquo;$FastDfs/bin/stop.sh&rdquo;
if [ ! -f $Stop ]; then
  echo &ldquo;file $Stop does not exist!&rdquo;
  exit 2
fi
Restart=&ldquo;$FastDfs/bin/restart.sh&rdquo;
if [ ! -f $Restart ]; then
  echo &ldquo;file $Restart does not exist!&rdquo;
  exit 2
fi
RETVAL=0
start() {</p>

<pre><code>echo -n $"Starting FastDFS tracker server: "
$PRG $CONF &amp;
RETVAL=$?
echo
return $RETVAL
</code></pre>

<p>}
stop() {</p>

<pre><code>echo -n $"Stop FastDFS tracker server: "
$Stop $PRG $CONF
RETVAL=$?
return $RETVAL
</code></pre>

<p>}
rhstatus() {</p>

<pre><code>status fdfs_trackerd
</code></pre>

<p>}
restart() {</p>

<pre><code>    $Restart $PRG $CONF &amp;
</code></pre>

<p>}
case &ldquo;$1&rdquo; in
  start)</p>

<pre><code>start
;;
</code></pre>

<p>  stop)</p>

<pre><code>stop
;;
</code></pre>

<p>  status)</p>

<pre><code>rhstatus
;;
</code></pre>

<p>  restart|reload)</p>

<pre><code>restart
;;
</code></pre>

<p>  condrestart)</p>

<pre><code>restart
;;
</code></pre>

<p>  *)</p>

<pre><code>echo $"Usage: $0 {start|stop|status|restart|condrestart}"
exit 1
</code></pre>

<p>esac
exit $?
```</p>

<p>&emsp;&emsp;这篇启动脚本中，主要修改的地方是FastDfs及CONF变量参数，这两个用来指定tracker配置文件所在的位置。</p>

<p>&emsp;&emsp;完成编辑后，使用命令：sudo /etc/init.d/fdfs_trackerd start，即可完成服务器的启动，如果启动成功你可通过netstat -lnpt查看到tracker的端口号。</p>

<p>&emsp;&emsp;接下来，将fdfs_storaged拷贝为fdfs_storaged1，用于启动storage1实例，要修改的地方也是FastDfs及CONF参数，这两个参数用来指定storage1.conf文件的在的目录及配置文件的名称。</p>

<p>``` sh fdfs_storaged1</p>

<h1>!/bin/bash</h1>

<p>#</p>

<h1>fdfs_storaged Starts fdfs_storaged</h1>

<p>#
#</p>

<h1>chkconfig: 2345 99 01</h1>

<h1>description: FastDFS storage server</h1>

<h3>BEGIN INIT INFO</h3>

<h1>Provides: $fdfs_storaged</h1>

<h3>END INIT INFO</h3>

<h1>Source function library.</h1>

<p>. /etc/init.d/functions
FastDfs=&lsquo;/usr/local/fastdfs&rsquo;
CONF=&ldquo;$FastDfs/conf/storage1.conf&rdquo;
if [ ! -f $CONF ]; then
  echo &ldquo;file $CONF does not exist!&rdquo;
  exit 2
fi
PRG=&ldquo;$FastDfs/bin/fdfs_storaged&rdquo;
if [ ! -f $PRG ]; then
  echo &ldquo;file $PRG does not exist!&rdquo;
  exit 2
fi
Stop=&ldquo;$FastDfs/bin/stop.sh&rdquo;
if [ ! -f $Stop ]; then
  echo &ldquo;file $Stop does not exist!&rdquo;
  exit 2
fi
Restart=&ldquo;$FastDfs/bin/restart.sh&rdquo;
if [ ! -f $Restart ]; then
  echo &ldquo;file $Restart does not exist!&rdquo;
  exit 2
fi
RETVAL=0
start() {</p>

<pre><code>echo -n $"Starting FastDFS storage server: "
$PRG $CONF &amp;
RETVAL=$?
echo
return $RETVAL
</code></pre>

<p>}
stop() {</p>

<pre><code>echo -n $"Stop FastDFS storage server: "
$Stop $PRG $CONF
RETVAL=$?
return $RETVAL
</code></pre>

<p>}
rhstatus() {</p>

<pre><code>status fdfs_storaged
</code></pre>

<p>}
restart() {</p>

<pre><code>    $Restart $PRG $CONF &amp;
</code></pre>

<p>}
case &ldquo;$1&rdquo; in
  start)</p>

<pre><code>start
;;
</code></pre>

<p>  stop)</p>

<pre><code>stop
;;
</code></pre>

<p>  status)</p>

<pre><code>rhstatus
;;
</code></pre>

<p>  restart|reload)</p>

<pre><code>restart
;;
</code></pre>

<p>  condrestart)</p>

<pre><code>restart
;;
</code></pre>

<p>  *)</p>

<pre><code>echo $"Usage: $0 {start|stop|status|restart|condrestart}"
exit 1
</code></pre>

<p>esac</p>

<p>exit $?
```</p>

<p>&emsp;&emsp;好，该来启动storaged1实例了，命令： sudo /etc/init.d/fdfs_storaged1 start，如果是第一次启动会观察到创建存储目录的过程。</p>

<p>&emsp;&emsp;启动storaged2实例的过程和storaged1相同，先编辑fdfs_storaged2文件，再fdfs_storaged2 start即完成。</p>

<p>&emsp;&emsp;当1号服务器上的fdfs全部服务都成功启动后，我们可以看到如下目录结构会建立起来。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/05/fdfs_dir_struct.jpg' width='' height='' title='fastdfs目录结构'><span class='caption-text'>fastdfs目录结构</span></span></p>

<p>&emsp;&emsp;至此，1号服务器上的所有配置及服务启动工作已经完成。2号服务器的配置及服务实例启动与1号服务器基本相同，惟一需要大家要注意的是group的名称，port端口号等，要和1号服务器相“呼应”，同时，我们在2号服务器上也配置了一个tracker实例以保证高可用性。</p>

<p>&emsp;&emsp;好了，fastDFS的配置先告一段落，下一篇我们来聊聊客户端对fastDFS的调用，除了java客户端外，还包括tengine-2.0.1服务器上访问插件的配置(2014-7-15:不写了，以后有空再说，大家在使用时，最后在网上找带连接池功能的fastDFS驱动)。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分布式文件系统fastdfs解析之一(安装)]]></title>
    <link href="http://yanyaner.com/blog/2014/05/30/fastDFS-setup/"/>
    <updated>2014-05-30T15:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/05/30/fastDFS-setup</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;fastdfs是一个轻量级的分布式文件系统服务，它在互联网项目中有比较广泛的用途，类似的还有tfs等，但fastdfs和hadoop这些又不相同，hadoop是分布式存储计算框架，比较重量级，而fastdfs针对的是海量的小文件。</p>

<p>&emsp;&emsp;项目中经常会有这样一些应用场景，比如：文件服务器需要存储海量的用户文件并且对外提供用户的访问操作；文件服务器需要高可用性和高性能；文件服务器需要实现负载均衡；文件服务器可实时扩容等等，这些需求在Fastdfs中有实现，因此它可以满足大部的项目需求。</p>

<p>&emsp;&emsp;先给大家简单介绍一下fastdfs的原理，下面这张图有助于大家了解分布式文件系统的原理（hadoop之类的分布式体系与之有相似之处）。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/seq_fastdfs.jpg' width='' height='' title='fastdfs调用时序图'><span class='caption-text'>fastdfs调用时序图</span></span></p>

<p>&emsp;&emsp;上面这张图中客户端针对文件服务系统的调用，首先得通过tracker服务器，这个服务器充当了调度者的作用。客户端可以是任何的程序客户端，比如java客户端、php客户端、nginx插件客户端等。</p>

<p>&emsp;&emsp;在客户端调用之前先得启动tracker server，然后再分别启动各个storage server，每个storage server启动后会注册自己的信息到指定的tracker server中（其实，tracker server服务器也可以有多个，从高可用性方面考虑我们一般会启动多个tracker server实例）。</p>

<p>&emsp;&emsp;storage server负责具体文件的存储。storage server按照分组的方式来保存文件的，比如group1,group2等。一个组中可以有多台服务器，同一个组里的所有服务器中保存的文件内容都是相同的，因为同一个组中的服务器之间会相互自动同步文件，这样就实现了冗余备份及负载均衡的功能（负载均衡由tracker server调试的哦）。</p>

<p>&emsp;&emsp;不同组中的storage server之间是独立的，当系统存储容量不够时，通过添加新服务器并分配到新的组中，tracker server发现新的服务器后会自动调度以实现后续客户文件的写入位置。</p>

<p>&emsp;&emsp;上图中，客户通过询问tracker server得到可用的storage server（tracker server会通过负载均衡及各个storage的存储可用容量大小算法决定，当然这个也可以在配置文件中指定），客户端得到storage server后进行相应的文件操作，同组服务器间会根据操作的结果进行文件同步（时序9，10是同步操作）。</p>

<p>&emsp;&emsp;好了，原理先说到这。下面，我将给大家简单介绍FastDfs的安装及使用，以及一些注意事项。</p>

<p>&emsp;&emsp;我的服务器是ubuntu server，我计划安装在两台服务器上，ip分别是:192.168.68.133, 192.168.68.136，暂时简称为1号服务器，2号服务器。</p>

<p>&emsp;&emsp;一号服务器上，将安装一个tracker server实例，一个位于group1中的storage server实例，一个位于group2中storage server实例。</p>

<p>&emsp;&emsp;二号服务器上，也将安装一个tracker server实例，一个位于group1中的storage server实例。需要大家注意的是，fastdfs中一台服务器上可以安装多个组，但一个组中的多个storade server必须安装在不同的服务器上，并且同组中的storage server的服务端口必须一致，否则无法实现文件同步。</p>

<p>&emsp;&emsp;我先在一号服务器192.168.68.133上安装fastdfs。首先要准备安装环境，不同的linux发行版本可能会有所不同，我用的服务器版本是ubuntu 12.04 server，以下的操作均以这个版本的ubuntu服务器为例。<!--more--></p>

<p><code>
vim /etc/profile
export LANGUAGE="en_US.UTF-8"
export LANG=en_US:zh_CN.UTF-8
export LC_ALL=C
</code>
&emsp;&emsp;接下来让语言环境配置参数立即生效：</p>

<p><code>
source /etc/profile
</code>
&emsp;&emsp;再接着，安装fastdfs编译依赖包，大家要注意的是少一个依赖都不行，我先前安装时缺少了libevent-dev，致使安装不成功但安装过程又不报错，花费了大量的时间。</p>

<p>```
aptitude install libevent
apt-get install libevent-dev</p>

<p>sudo apt-get update
sudo aptitude install build-essential m4</p>

<p>sudo ln -s /lib/lsb/init-functions  /etc/init.d/functions</p>

<p>```</p>

<p>&emsp;&emsp;好了，环境准备好了后就到<a href="https://code.google.com/p/fastdfs">fastdfs官网</a>上去下载安装包吧，地址<a href="https://code.google.com/p/fastdfs/downloads/list">https://code.google.com/p/fastdfs/downloads/list</a>，我下载的是
FastDFS_v4.06.tar.gz ，如果你想要安装最新版本，请用svn去下载最新的5.x版本。</p>

<p><code>
tar -zxvf FastDFS_v4.06.tar.gz
cd FastDFS
</code>
&emsp;&emsp;这样就进入了源代码目录，我们先要对安装的目录做一个规划(4.06版本默认的安装目录似乎不太合理)，我将fastdfs的所有文件都安装到/usr/local/fastdfs中，配置文件存放在/usr/local/fastdfs/conf下，这就需要我们修改源代码目录下的make.sh，下面是一些要修改的地方：</p>

<p><code>
vim make.sh
</code></p>

<p>&emsp;&emsp;需要对：</p>

<ol>
<li><p> TARGET_PREFIX，TARGET_CONF_PATH进行修改;</p></li>
<li><p> 需要对libpthread.so、libpthread.a的路径进行修改，这和ubuntu有关，其它linux发行版本并不需要改这个(你可以用find / -name &lsquo;libpthread.so&rsquo;  ，以及ind / -name &lsquo;libpthread.a&rsquo;  找到这两文件在系统中的位置)；</p></li>
<li><p> 另外要对mkdir,cp操作的几个路径进行修改为我们配置文件所在的路径。</p></li>
</ol>


<p>&emsp;&emsp;我贴出make.sh修改过的地方，请大家自行对照：</p>

<p>```
TARGET_PREFIX=/usr/local/fastdfs
TARGET_CONF_PATH=/usr/local/fastdfs/conf</p>

<p>if [ -f /usr/lib/i386-linux-gnu/libpthread.so ] || [ -f /usr/local/lib/libpthread.so ] || [ -f /lib64/libpthread.so ] || [ -f /usr/lib64/libpthread.so ] || [ -f /usr/lib/i386-linux-gnu/libpthread.a ] || [ -f /usr/local/lib/libpthread.a ] || [ -f /lib64/libpthread.a ] || [ -f /usr/lib64/libpthread.a ]; then
&hellip;&hellip;&hellip;&hellip;
&hellip;&hellip;&hellip;&hellip;</p>

<p>if [ &ldquo;$uname&rdquo; = &ldquo;Linux&rdquo; ]; then</p>

<pre><code>if [ "$WITH_LINUX_SERVICE" = "1" ]; then
  if [ ! -d /usr/local/fastdfs/conf ]; then
    mkdir -p /usr/local/fastdfs/conf
    cp -f conf/tracker.conf /usr/local/fastdfs/conf/
    cp -f conf/storage.conf /usr/local/fastdfs/conf/
    cp -f conf/client.conf /usr/local/fastdfs/conf/
    cp -f conf/http.conf /usr/local/fastdfs/conf/
    cp -f conf/mime.types /usr/local/fastdfs/conf/
  fi
</code></pre>

<p>&hellip;&hellip;&hellip;&hellip;</p>

<p>```</p>

<p>&emsp;&emsp;下面开始安装吧，如下命令：</p>

<p><code>
sudo make;
sudo make install;
sudo make clean;
</code>
&emsp;&emsp;不同的linux发行版本可能存在依赖包没有安装而报错，具体情况需要根据出错信息具体解决，我试过redhead,freebsd,openSuse,centos几个系统，都是要进行一些环境的配置才可以安装成功。</p>

<p>&emsp;&emsp;下一篇文章我将按照文章开头的服务器规划进行具体的配置，请大家关注。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[监控系统中的异步消息使用实例（二）]]></title>
    <link href="http://yanyaner.com/blog/2014/04/09/async_message_architect2/"/>
    <updated>2014-04-09T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/04/09/async_message_architect2</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;接上节，再次贴出架构图，我们接下来要讲的是图中黄色部分的配置。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/monitor_jms1.jpg' width='' height='' title='业务方法监控架构'><span class='caption-text'>业务方法监控架构</span></span></p>

<p>&emsp;&emsp;先将spy程序导成一个jar包，加入到需要监控的目标服务器lib目录，monitor_spy.jar结构如下所示：</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/jarinfo.jpg' width='' height='' title='monitor_spy.jar结构'><span class='caption-text'>monitor_spy.jar结构</span></span></p>

<p>&emsp;&emsp;为了能够实现对目标系统业务方法执行情况进行监控，需要将我们已经写好的拦截器配置到目标系统中去，下面是我的一个配置示例：</p>

<p>``` xml spring-spy.xml</p>

<pre><code>&lt;!-- jms连接工厂 --&gt;         
&lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactoryBean"&gt;
    &lt;property name="connectionFactory"&gt;
        &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt;
            &lt;property name="brokerURL" value="tcp://localhost:61616"&gt;&lt;/property&gt;
        &lt;/bean&gt;
    &lt;/property&gt;
    &lt;!-- 配置池中最大连接数据以及最大活动连接数 --&gt;
    &lt;property name="maxConnections" value="100"&gt;&lt;/property&gt;
    &lt;property name="maximumActive" value="100"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- jms模板方法 --&gt;    
&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt;
    &lt;constructor-arg ref="jmsFactory"&gt;
    &lt;/constructor-arg&gt;
    &lt;!-- 默认会创建queue类型的目标
    &lt;property name="defaultDestinationName" value="queue/methodSpyLogger"&gt;&lt;/property&gt; --&gt;
    &lt;property name="defaultDestination" ref="destinationQueue1"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 发送消息的目的地 --&gt;
&lt;bean id="destinationQueue1" class="org.apache.activemq.command.ActiveMQQueue"&gt;
    &lt;!-- 设置消息队列的名字 --&gt;
    &lt;constructor-arg  value="queue/methodSpyLogger" /&gt;
&lt;/bean&gt;


&lt;!-- 配置Spring和方法相关的监控 --&gt;
&lt;bean id="method-pointcut" class="org.springframework.aop.support.JdkRegexpMethodPointcut"&gt;
    &lt;property name="patterns"&gt;
        &lt;list&gt;
            &lt;value&gt;com.lovo.mis.xjgl.service.impl.*&lt;/value&gt;
        &lt;/list&gt;
    &lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 方法AOP拦截器 --&gt;
&lt;bean id="spy-method-interceptor"
      class="com.monitor.client.spy.SpyMethodIntercepter"&gt;
      &lt;property name="messageDao"&gt;
        &lt;bean class="com.monitor.client.dao.JMSMessageDaoImpl"&gt;
            &lt;property name="jmsTemplate" ref="jmsTemplate"&gt;&lt;/property&gt;
        &lt;/bean&gt;
      &lt;/property&gt;
      &lt;property name="userNameSessionKey" value="loginUserName"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 将切面应用到通知上 --&gt;
&lt;aop:config proxy-target-class="true"&gt;
    &lt;aop:advisor advice-ref="spy-method-interceptor"
                 pointcut-ref="method-pointcut" /&gt;
&lt;/aop:config&gt;
</code></pre>

<p>```</p>

<p>&emsp;&emsp;配置文件中有几个地方需要进行说明：<!-- more --></p>

<p>&emsp;&emsp;1、目标机器要修改的部分是JdkRegexpMethodPointcut中的patterns，由patterns指定需要监控的业务类所在的位置。</p>

<p>&emsp;&emsp;2、jmsFactory部分配置你的异步消息服务器连接信息，比如brokerURL等。</p>

<p>&emsp;&emsp;3、jmsTemplate中，通过defaultDestination指定一个Destination，因为一个消息服务器上存在多个Destination。也可以通过defaultDestinationName直接指定消息Destination的名称，系统默认创建的是queue，也就是说，如果你要使用topic类型的消息，就必须通过defaultDestination指定一个Destination。</p>

<p>&emsp;&emsp;4、messageDao可自由替换为其它实现类，比如你可以写一个mongoDB版本的实现以提供更好的性性，支持更大数据量。</p>

<p>&emsp;&emsp;最后来看看消费者代码，是直接使用ActiveMQ驱动实现的。</p>

<p>``` java</p>

<pre><code>    ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory("tcp://localhost:61616");

    Connection connection = factory.createConnection();

    //尝试真正建立连接，这里可以catch Exception
    connection.start();

    //得到一个会话，只有得到会话后，才可进行后续的操作
    Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);

    //创建一个目标队列
    Destination queue = session.createQueue("queue/methodSpyLogger"); 

    MessageConsumer consumer = session.createConsumer(queue);

    //可通过其它一些机制，来改变flag为false，以退出处理
    boolean flag = true;

    while (flag) {
        ObjectMessage msg = (ObjectMessage)consumer.receive();
        MethodLoggerMessage myMsg = (MethodLoggerMessage)msg.getObject();

        System.out.println(myMsg);
        //这里，可调用dao或service，向关系数据库(或nosql)中保存msg中的内容");

    }

    session.close();

    connection.close();
</code></pre>

<p>```</p>

<p>&emsp;&emsp;注意，如果队列中已经没有消息了，代码中的consumer.receive()会阻塞，直到有新的消息后再处理。我们也可以采用监听器的方式来处理消息服务器中的消息，比如下面的代码：</p>

<p>``` java</p>

<pre><code>    //处理消息者
    MessageConsumer consumer = session.createConsumer(queue);

    //处理多条消息
    consumer.setMessageListener(new MessageListener() {
        public void onMessage(Message msg) {
           //转换，这可以对类型进行检测，使用instance of
            TextMessage txtMsg = (TextMessage)msg;
            try {
                System.out.println("得到消息内容："+txtMsg.getText());
                System.out.println("处理完一条消息！！");
                //如果开启了事务，请session.commit();
            } catch (JMSException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
            }
        }
    });
</code></pre>

<p>```</p>

<p>&emsp;&emsp;当目标程序运行时，我们可以打开ActiveMQ的管理界面，即可发现这个queue及上面的消费者。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/active_mq_admin.jpg' width='' height='' title='ActiveMQ的管理界面'><span class='caption-text'>ActiveMQ的管理界面</span></span></p>

<p>&emsp;&emsp;大家还要注意的是，我们的AOP通知中，还获取了调用者的ip，访问者姓名等信息，这些和web环境相关的信息是通过类似于下面的代码实现的：</p>

<p>``` java</p>

<p>ServletRequestAttributes sas = (ServletRequestAttributes)RequestContextHolder.getRequestAttributes();
HttpServletRequest req = sas.getRequest();</p>

<p>logger.setIp(req.getLocalAddr());
logger.setSessionId(sas.getSessionId());</p>

<p>if (req.getSession() != null) {</p>

<pre><code>logger.setOperater((String)req.getSession().getAttribute(userNameSessionKey));
</code></pre>

<p>}</p>

<p>```
 &emsp;&emsp;其中的RequestContextHolder是由spring封装，具体做法是将用户web相关的信息通过filter或listener放入ThreadLocal对象中，在需要的地方通过RequestContextHolder从ThreadLocal中取得，因此，你想让上面的代码正常工作，要记得在web.xml中添加一个spring已经写好的RequestContextListener监听器哦。</p>

<p>``` xml  web.xml</p>

<pre><code>&lt;listener&gt;
    &lt;listener-class&gt;
        org.springframework.web.context.request.RequestContextListener
    &lt;/listener-class&gt;
&lt;/listener&gt;
</code></pre>

<p>```</p>

<p> &emsp;&emsp;当然，本例中所使用的消息服务器是ActiveMQ，这个服务器实现了JMS规范，在企业级应用场景中不会存在问题。如果在互联网行业中，由于会面临高并发、大流量等情况，ActiveMQ不能保证高可用性、稳定性及性能要求，这个时候我们可以考虑其它的第三方消息服务器，比如淘宝的taobao-metaq，alibaba-rocketmq等，这些服务器是经过实际考验的开源产品，值得在互联网场景中使用。当然，这些MQ服务器和JMS规范没有任何关系，JMS企业级要求中并没有考虑过多的并发、大数据量的需求。</p>

<p> &emsp;&emsp;另外，kafka，rabbitmq等消息服务器也具有不错的性能，都可以进入架构的技术方案选型范围。比如，下面是一段rabbitmq的调用示例代码(注：rabbitmq需要er_lang并发程序包支持哦)，和JMS的调用相当类似。</p>

<p>``` java
import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;</p>

<p>&hellip;&hellip;.//略去代码</p>

<pre><code>@Test
public void testSendMessage() throws Exception {
    SimpleDateFormat sf = new SimpleDateFormat("yyyy-MM-dd hh:mm:ss");

    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");

    Connection connection = factory.newConnection();
    Channel channel = connection.createChannel();

    String message = sf.format(new Date()) + ":Hello!!!";
    channel.basicPublish("", "queue/sendEmail", null, message.getBytes());


    channel.close();
    connection.close();

    System.out.println("send message ok!");



}


@Test
public void testReciveMessage() throws Exception {

    System.out.println("recever starting.....");

    String QUEUE_NAME = "queue/sendEmail";

    SimpleDateFormat sf = new SimpleDateFormat("yyyy-MM-dd hh:mm:ss");

    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");

    Connection connection = factory.newConnection();
    Channel channel = connection.createChannel();

    channel.queueDeclare(QUEUE_NAME, false, false, false, null);

    QueueingConsumer consumer = new QueueingConsumer(channel);
    channel.basicConsume(QUEUE_NAME, false, consumer);

    QueueingConsumer.Delivery delivery = consumer.nextDelivery();

    String msg = new String(delivery.getBody());

    System.out.println(msg);

    System.out.println("rec end!!!");
}
</code></pre>

<p>```</p>

<p> &emsp;&emsp;先说到这吧。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[监控系统中的异步消息使用实例（一）]]></title>
    <link href="http://yanyaner.com/blog/2014/04/08/async_message_architect1/"/>
    <updated>2014-04-08T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/04/08/async_message_architect1</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;以后的文章要尽量做到通俗，让非技术人员都读得懂，道理就跟艺术作品一样，一件好的作品，不需要配任何文字说明就足以打动普通观众，做到雅俗共赏而且有深度和内涵，其实，这需要作者相当的功力。</p>

<p>&emsp;&emsp;近期一些童鞋在实现一个监控系统，其中的一个功能是：对监控平台上布署的第三方应用业务方法执行细节进行监控，比如：方法调用者，调用者ip，应用系统名称，子系统名称，方法名称，执行耗时等信息。如何能够让监控系统得到目标机器上需要监控的业务方法执行情况呢？如何保证在监控的过程中不影响对方的业务的正常执行？下面我给出一种参考架构实现，这也是在概要设计的时候就应该明确的东西（专业名词叫架构原型）。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/monitor_jms1.jpg' width='' height='' title='业务方法监控架构'><span class='caption-text'>业务方法监控架构</span></span></p>

<p>&emsp;&emsp;首先，MonitorPlatform是我们的监控平台（图中青色部分），targetServer上运行着需要监控的系统hotel project（图中黄色部分）,如果我们想要获得目标机器上的我们需要的信息，最简单的办法是运行一个spy程序在对方的机器上，图中的spy app是起这个作用的（当然你也可以使用jmx规范来实现类似功能），举个不恰当的例子，就好比你在某人的机器上安装了一个木马程序，通过远程控制端你就可以得到对方机器上你感兴趣的任何东西，甚至包括控制摄像头哦。</p>

<p>&emsp;&emsp;其次，监控平台同时要监控多个目标系统，就我们例子中监控业务方法执行情况而言，就需要把监控得到的信息加以持久化以备后查，如果目标系统业务繁忙，而我们的spy app又要将取到的信息进行数据库持久化，数据库很可能会成为性能瓶颈从而造成性能问题，因此，我在这里采用了异步消息系统的设计，以缓解持久化压力。正如图所示，spy app将采集到的业务方法执行数据直接写入异步消息服务器的queue中，而monitor platform中的处理程序将从queue中取出消息，再进行后续的持久化处理。这种异步的消息设计方式可以有效缓解系统的压力，在很多项目中都可以采用（互联网项目中可用这种方式来"削峰"，缓解高并发压力）。</p>

<p>&emsp;&emsp;最后一个问题,spy如何采集到目标机器业务方法的执行情况呢。最佳答案当然是AOP。大家可以参考我的另一篇文章<a href="/blog/2013/03/26/logger/">一种日志记录解决方案</a>。</p>

<p>&emsp;&emsp;下面，我们一起来看看架构原型中的原代码实现吧。MethodLoggerMessage是需要持久化的消息对象，请注意实现Serializable接口。<!-- more --></p>

<p>``` java MethodLoggerMessage.java</p>

<p>package com.monitor.client.commons;</p>

<p>import java.io.Serializable;
import java.util.Date;</p>

<p>/<em>*
 * 需要持久化的对象消息
 * @author ljh
 *
 </em>/
public class MethodLoggerMessage implements Serializable {</p>

<pre><code>//方法执行时间，单位：毫秒
private double howLong;
//方法名
private String methodName;
//执行者ip地址
private String ip;
//执行者session会话id
private String sessionId;
//执行者
private String operater = "";
//执行时间
private Date execTimer;

public double getHowLong() {
    return howLong;
}
public void setHowLong(double howLong) {
    this.howLong = howLong;
}
public String getMethodName() {
    return methodName;
}
public void setMethodName(String methodName) {
    this.methodName = methodName;
}
public String getIp() {
    return ip;
}
public void setIp(String ip) {
    this.ip = ip;
}
public String getOperater() {
    return operater;
}
public void setOperater(String operater) {
    this.operater = operater;
}
public String getSessionId() {
    return sessionId;
}
public void setSessionId(String sessionId) {
    this.sessionId = sessionId;
}
public Date getExecTimer() {
    return execTimer;
}
public void setExecTimer(Date execTimer) {
    this.execTimer = execTimer;
}
@Override
public String toString() {
    return "MethodLoggerMessage [howLong=" + howLong + ", methodName="
            + methodName + ", ip=" + ip + ", sessionId=" + sessionId
            + ", operater=" + operater + ", execTimer=" + execTimer + "]";
}
</code></pre>

<p>```</p>

<p>&emsp;&emsp;IMessageDao接口用来定义消息持久化行为，可以有很同种不同的实现版本，如基于消息的，关系数据库的或nosql的等等，有了这个接口，我们在intercepter中就可以做到拦截代码和持久化代码的解耦。</p>

<p>``` java IMessageDao.java
package com.monitor.client.dao;</p>

<p>import java.io.Serializable;</p>

<p>/<em>*
 * 持久化消息服务
 * @author ljh
 *
 </em>/
public interface IMessageDao {</p>

<pre><code>public void persist(Serializable msg);
</code></pre>

<p>}
```</p>

<p>&emsp;&emsp;接下来是消息持久化实现类源代码。因为采用了jms，因此我直接使用了spring对jms封装的模板方法实现。</p>

<p>``` java JMSMessageDaoImpl.java
package com.monitor.client.dao;</p>

<p>import java.io.Serializable;</p>

<p>import javax.jms.JMSException;
import javax.jms.Message;
import javax.jms.ObjectMessage;
import javax.jms.Session;</p>

<p>import org.springframework.jms.core.JmsTemplate;
import org.springframework.jms.core.MessageCreator;</p>

<p>/<em>*
 * jms消息处理实现
 * @author ljh
 *
 </em>/
public class JMSMessageDaoImpl implements IMessageDao {</p>

<pre><code>//jms模板
private JmsTemplate jmsTemplate;
//目标队列名称
private String destinationName;

@Override
public void persist(final Serializable msg) {

    MessageCreator mc = new MessageCreator() {

        @Override
        public Message createMessage(Session session) throws JMSException {
            //创建对象消息，并发送之
            ObjectMessage objMsg = session.createObjectMessage();   
            objMsg.setObject(msg);

            return objMsg;
        }
    };

    if (destinationName == null) {
        jmsTemplate.send(mc);
    } else {
        //发送到指定的目标
        jmsTemplate.send(destinationName, mc);
    }


}

public void setJmsTemplate(JmsTemplate jmsTemplate) {
    this.jmsTemplate = jmsTemplate;
}

public void setDestinationName(String destinationName) {
    this.destinationName = destinationName;
}
</code></pre>

<p>}
```</p>

<p>&emsp;&emsp;最重要的就是这个拦截器实现了。环绕拦截器，功能最为强大。</p>

<p>``` java SpyMethodIntercepter.java
package com.monitor.client.spy;</p>

<p>import java.util.Date;</p>

<p>import javax.servlet.http.HttpServletRequest;</p>

<p>import org.aopalliance.intercept.MethodInterceptor;
import org.aopalliance.intercept.MethodInvocation;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.DisposableBean;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;</p>

<p>import com.monitor.client.commons.MethodLoggerMessage;
import com.monitor.client.dao.IMessageDao;
/<em>*
 * 目标服务器方法拦截器，调用信息可以通过异步消息机制持久化，具体要看IMessageDao实现
 * @author ljh
 *
 </em>/
public class SpyMethodIntercepter implements MethodInterceptor{</p>

<pre><code>public static final Logger LOG = LoggerFactory.getLogger(SpyMethodIntercepter.class);

//消息处理dao
private IMessageDao messageDao;
//当前登录者在目标系统中的登录用户名之key,在配置第三方程序时注入
private String userNameSessionKey = "loginedUserName";

@Override
public Object invoke(MethodInvocation method) throws Throwable {

    //取方法执行时的开始时间
    long start = System.nanoTime();

    try {
        return method.proceed();
    } catch (Exception ex) {
        throw ex;
    } finally {

        try {
            //为了不影响目标方法的运行，这里再次try
            //得到访问者request对象
            ServletRequestAttributes sas = (ServletRequestAttributes)RequestContextHolder.getRequestAttributes();
            HttpServletRequest req = sas.getRequest();

            //取方法执行后的时间
            long end = System.nanoTime();

            //方法执行时间
            long howLong = end - start;
            String methodName = method.getMethod().getName();

            //持久化方法调用日志
            MethodLoggerMessage logger = new MethodLoggerMessage();

            logger.setMethodName(methodName);

            //方法执行时间，单位：毫秒
            logger.setHowLong((double)howLong/(1000*1000));

            logger.setIp(req.getLocalAddr());
            logger.setSessionId(sas.getSessionId());

            if (req.getSession() != null) {
                logger.setOperater((String)req.getSession().getAttribute(userNameSessionKey));
            }

            logger.setExecTimer(new Date());

            messageDao.persist(logger);
        } catch (Exception exc) {
            //do nothing or LOG.debug(ex.getMessage());
            LOG.warn("Error in spy: {}", exc);
        }

    }

}

public void setMessageDao(IMessageDao messageDao) {
    this.messageDao = messageDao;
}

public void setUserNameSessionKey(String userNameSessionKey) {
    this.userNameSessionKey = userNameSessionKey;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;至此，spy程序这边基本开发完成了。目标服务器上，该如何配置呢？监控平台的消息处理者又该如何实现呢？</p>

<p>&emsp;&emsp;且听下回分解。</p>
]]></content>
  </entry>
  
</feed>
