<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[☺分类☺：javaEE | 刘江华的博客]]></title>
  <link href="http://yanyaner.com/blog/categories/javaee/atom.xml" rel="self"/>
  <link href="http://yanyaner.com/"/>
  <updated>2014-04-08T23:02:39+08:00</updated>
  <id>http://yanyaner.com/</id>
  <author>
    <name><![CDATA[冰雨]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[监控系统中的异步消息使用实例（一）]]></title>
    <link href="http://yanyaner.com/blog/2014/04/08/async_message_architect1/"/>
    <updated>2014-04-08T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/04/08/async_message_architect1</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;以后的文章要尽量做到通俗，让非技术人员都读得懂，道理就跟艺术作品一样，一件好的作品，不需要配任何文字说明就足以打动普通观众，做到雅俗共赏而且有深度和内涵，其实，这需要作者相当的功力。</p>

<p>&emsp;&emsp;近期一些童鞋在实现一个监控系统，其中的一个功能是：对监控平台上布署的第三方应用业务方法执行细节进行监控，比如：方法调用者，调用者ip，应用系统名称，子系统名称，方法名称，执行耗时等信息。如何能够让监控系统得到目标机器上需要监控的业务方法执行情况呢？如何保证在监控的过程中不影响对方的业务的正常执行？下面我给出一种参考架构实现，这也是在概要设计的时候就应该明确的东西（专业名词叫架构原型）。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/monitor_jms.jpg' width='' height='' title='业务方法监控架构图'><span class='caption-text'>业务方法监控架构图</span></span></p>

<p>&emsp;&emsp;首先，MonitorPlatform是我们的监控平台（图中青色部分），targetServer上运行着需要监控的系统hotel project（图中黄色部分）,如果我们想要获得目标机器上的我们需要的信息，最简单的办法是运行一个spy程序在对方的机器上，图中的spy app是起这个作用的（当然你也可以使用jmx规范来实现类似功能），举个不恰当的例子，就好比你在某人的机器上安装了一个木马程序，通过远程控制端你就可以得到对方机器上你感兴趣的任何东西，甚至包括控制摄像头哦。</p>

<p>&emsp;&emsp;其次，监控平台同时要监控多个目标系统，就我们例子中监控业务方法执行情况而言，就需要把监控得到的信息加以持久化以备后查，如果目标系统业务繁忙，而我们的spy app又要将取到的信息进行数据库持久化，数据库很可能会成为性能瓶颈从而造成性能问题，因此，我在这里采用了异步消息系统的设计，以缓解持久化压力。正如图所示，spy app将采集到的业务方法执行数据直接写入异步消息服务器的queue中，而monitor platform中的处理程序将从queue中取出消息，再进行后续的持久化处理。这种异步的消息设计方式可以有效缓解系统的压力，在很多项目中都可以采用（互联网项目中可用这种方式来"削峰"，缓解高并发压力）。</p>

<p>&emsp;&emsp;最后一个问题,spy如何采集到目标机器业务方法的执行情况呢。最佳答案当然是AOP。</p>

<p>&emsp;&emsp;下面，我们一起来看看架构原型中的原码实现吧。MethodLoggerMessage是需要持久化的消息对象，请注意实现Serializable接口。<!-- more --></p>

<p>``` java MethodLoggerMessage.java</p>

<p>package com.monitor.client.commons;</p>

<p>import java.io.Serializable;
import java.util.Date;</p>

<p>/<em>*
 * 需要持久化的对象消息
 * @author ljh
 *
 </em>/
public class MethodLoggerMessage implements Serializable {</p>

<pre><code>//方法执行时间，单位：毫秒
private double howLong;
//方法名
private String methodName;
//执行者ip地址
private String ip;
//执行者session会话id
private String sessionId;
//执行者
private String operater = "";
//执行时间
private Date execTimer;

public double getHowLong() {
    return howLong;
}
public void setHowLong(double howLong) {
    this.howLong = howLong;
}
public String getMethodName() {
    return methodName;
}
public void setMethodName(String methodName) {
    this.methodName = methodName;
}
public String getIp() {
    return ip;
}
public void setIp(String ip) {
    this.ip = ip;
}
public String getOperater() {
    return operater;
}
public void setOperater(String operater) {
    this.operater = operater;
}
public String getSessionId() {
    return sessionId;
}
public void setSessionId(String sessionId) {
    this.sessionId = sessionId;
}
public Date getExecTimer() {
    return execTimer;
}
public void setExecTimer(Date execTimer) {
    this.execTimer = execTimer;
}
@Override
public String toString() {
    return "MethodLoggerMessage [howLong=" + howLong + ", methodName="
            + methodName + ", ip=" + ip + ", sessionId=" + sessionId
            + ", operater=" + operater + ", execTimer=" + execTimer + "]";
}
</code></pre>

<p>```</p>

<p>&emsp;&emsp;IMessageDao接口用来定义消息持久化行为，可以有很同种不同的实现版本，如基于消息的，关系数据库的或nosql的等等，有了这个接口，我们在intercepter中就可以做到拦截代码和持久化代码的解耦。</p>

<p>``` java IMessageDao.java
package com.monitor.client.dao;</p>

<p>import java.io.Serializable;</p>

<p>/<em>*
 * 持久化消息服务
 * @author ljh
 *
 </em>/
public interface IMessageDao {</p>

<pre><code>public void persist(Serializable msg);
</code></pre>

<p>}
```</p>

<p>&emsp;&emsp;接下来是消息持久化实现类源代码。因为采用了jms，因此我直接使用了spring对jms封装的模板方法实现。</p>

<p>``` java JMSMessageDaoImpl.java
package com.monitor.client.dao;</p>

<p>import java.io.Serializable;</p>

<p>import javax.jms.JMSException;
import javax.jms.Message;
import javax.jms.ObjectMessage;
import javax.jms.Session;</p>

<p>import org.springframework.jms.core.JmsTemplate;
import org.springframework.jms.core.MessageCreator;</p>

<p>/<em>*
 * jms消息处理实现
 * @author ljh
 *
 </em>/
public class JMSMessageDaoImpl implements IMessageDao {</p>

<pre><code>//jms模板
private JmsTemplate jmsTemplate;
//目标队列名称
private String destinationName;

@Override
public void persist(final Serializable msg) {

    MessageCreator mc = new MessageCreator() {

        @Override
        public Message createMessage(Session session) throws JMSException {
            //创建对象消息，并发送之
            ObjectMessage objMsg = session.createObjectMessage();   
            objMsg.setObject(msg);

            return objMsg;
        }
    };

    if (destinationName == null) {
        jmsTemplate.send(mc);
    } else {
        //发送到指定的目标
        jmsTemplate.send(destinationName, mc);
    }


}

public void setJmsTemplate(JmsTemplate jmsTemplate) {
    this.jmsTemplate = jmsTemplate;
}

public void setDestinationName(String destinationName) {
    this.destinationName = destinationName;
}
</code></pre>

<p>}
```</p>

<p>&emsp;&emsp;最重要的就是这个拦截器实现了。环绕拦截器，功能最为强大。</p>

<p>``` java SpyMethodIntercepter.java
package com.monitor.client.spy;</p>

<p>import java.util.Date;</p>

<p>import javax.servlet.http.HttpServletRequest;</p>

<p>import org.aopalliance.intercept.MethodInterceptor;
import org.aopalliance.intercept.MethodInvocation;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.DisposableBean;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;</p>

<p>import com.monitor.client.commons.MethodLoggerMessage;
import com.monitor.client.dao.IMessageDao;
/<em>*
 * 目标服务器方法拦截器，调用信息可以通过异步消息机制持久化，具体要看IMessageDao实现
 * @author ljh
 *
 </em>/
public class SpyMethodIntercepter implements MethodInterceptor{</p>

<pre><code>public static final Logger LOG = LoggerFactory.getLogger(SpyMethodIntercepter.class);

//消息处理dao
private IMessageDao messageDao;
//当前登录者在目标系统中的登录用户名之key,在配置第三方程序时注入
private String userNameSessionKey = "loginedUserName";

@Override
public Object invoke(MethodInvocation method) throws Throwable {

    //取方法执行时的开始时间
    long start = System.nanoTime();

    try {
        return method.proceed();
    } catch (Exception ex) {
        throw ex;
    } finally {

        try {
            //为了不影响目标方法的运行，这里再次try
            //得到访问者request对象
            ServletRequestAttributes sas = (ServletRequestAttributes)RequestContextHolder.getRequestAttributes();
            HttpServletRequest req = sas.getRequest();

            //取方法执行后的时间
            long end = System.nanoTime();

            //方法执行时间
            long howLong = end - start;
            String methodName = method.getMethod().getName();

            //持久化方法调用日志
            MethodLoggerMessage logger = new MethodLoggerMessage();

            logger.setMethodName(methodName);

            //方法执行时间，单位：毫秒
            logger.setHowLong((double)howLong/(1000*1000));

            logger.setIp(req.getLocalAddr());
            logger.setSessionId(sas.getSessionId());

            if (req.getSession() != null) {
                logger.setOperater((String)req.getSession().getAttribute(userNameSessionKey));
            }

            logger.setExecTimer(new Date());

            messageDao.persist(logger);
        } catch (Exception exc) {
            //do nothing or LOG.debug(ex.getMessage());
            LOG.warn("Error in spy: {}", exc);
        }

    }

}

public void setMessageDao(IMessageDao messageDao) {
    this.messageDao = messageDao;
}

public void setUserNameSessionKey(String userNameSessionKey) {
    this.userNameSessionKey = userNameSessionKey;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;至此，spy程序这边基本开发完成了。目标服务器上，该如何配置呢？监控平台的消息处理者又该如何实现呢？</p>

<p>&emsp;&emsp;且听下回分解。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[缓存之redis]]></title>
    <link href="http://yanyaner.com/blog/2014/03/27/cache-redis/"/>
    <updated>2014-03-27T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/27/cache-redis</id>
    <content type="html"><![CDATA[<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/03/redis.jpg' width='' height='' title=''><span class='caption-text'></span></span></p>

<p>&emsp;&emsp;缓存在软件系统中有着不可替代的作用，特别是访问量巨大的网站，我们对系统热点数据的缓存将会降低数据库的压力，提高系统性能。目前常用的缓存大致分为本地缓存和独立的缓存服务，本地缓存常用的有ehcached,oscached等，而独立的服务器缓存常用的有memcached、redis等。</p>

<p>&emsp;&emsp;Redis is an open source, BSD licensed, advanced key-value store. It is often referred to as a data structure server since keys can contain strings, hashes, lists, sets and sorted sets.</p>

<p>&emsp;&emsp;这是redis官网<a href="http://redis.io/">redis.io</a>对redis的描述，我们从中可以看出，它是一个高性能的、更加高级的key-value缓存服务器。其中的更加高级，可能是相对于memcached这种简单的缓存服务器而言。比如redis可以在不取回缓存对象的情况下，通过指令直接对缓存的数字类型进行加、减操作，也可以对缓存的list中的内容进行修改操作，还可以对缓存的字符串进行直接的修改操作等等，这些操作都不需要取回缓存中的数据，因此没有序列化、反序列化的开销，性能会更高。另外，redis对一些复杂数据结构的支持，可以满足一些特定场景下的需求，比如sorted sets。</p>

<p>&emsp;&emsp;当然更高级、先进的redis，在功能强大的同时也增加了自身的复杂性。复杂可不是什么好事情，复杂的东西可能会给我们带来烦恼，实践证明，真正能够解决问题的方案一般都是简单的。因此，就redis和memcached而言，后者功能简单也更容易使用，这就造成了memcached在当前依然是缓存服务器中的老大（当然任何事都不能太绝对，我们在实际项目中可以根据不同的需求应用场景选择不同的缓存方案）。</p>

<p>&emsp;&emsp;本文是入门级文章，我在讲解redis的同时，也会顺便提到memcached，以便于大家对比。<!-- more --></p>

<p>&emsp;&emsp;先来安装redis，同样以windows系统为例（因为更多同鞋没有安装linux环境）。winodws的安装很简单，下载redis for windows的编译版本（地址在：<a href="http://code.google.com/p/servicestack/downloads/list">http://code.google.com/p/servicestack/downloads/list</a>），这是一个zip压缩包，将这个包解压到某个目录下，运行其中的redis-server.exe即可启动服务器。</p>

<p>&emsp;&emsp;如果你要指定一些额外的配置参数，可以在运行cmd中指定redis的配置文件，比如：</p>

<p>```
redis-server.exe conf/myredis.conf，</p>

<p>```</p>

<p>&emsp;&emsp;这样就可以在myredis.conf中配置更多的信息了。比如：daemonize，logfile，database，dbfilename，slaveof,loglevel等等，其中有两个参数我要说一下。</p>

<p>&emsp;&emsp;dbfilename参数，这个参数可以指定持久化文件名，默认是dump.rdb。这个参数说明redis可以将内存中缓存的东西进行持久化，如果您缓存服务器宕机重启了，redis下次重启时可以自动从这个文件中读取数据并恢复至内存中。这个功能在memcached中是没有的，memcached如果重新启动，缓存的数据将全部丢失。话又说回来，缓存的数据一般是来自数据库的，完全可以重新加载，系统在经过一段时间的运行后自然会重新填充到缓存服务器中的。当然，丢失缓存数据这对于一些大数据高并发发的网站来说，也许并不可接受，因为可能在瞬间造成数据库的极大访问压力而造成系统崩溃。</p>

<p>&emsp;&emsp;另一个参数是slaveof，这个参数可以指定redis主服务器，也就是说redis可以做成主从结构的，通过这种架构来保证系统的高可用性。当然，memcached也可以做成主从结构，但memcache需要第三方的插件支持（可以下载memcached-repcached并安装）。主从结构可以做到当主服务器发生故障的时候，从服务器可以升级以继续提供服务。</p>

<p>&emsp;&emsp;说到高可用性，另一个问题不得不提出，那就是分布式（即集群），因为缓存的东西都是在内在中的，一台服务器的内在毕竟有限，那我们就得搭建一个服务器集群在多台服务器上保存缓存的数据（即分片保存）。如何根据客户端的数据key找到集群中的正确的缓存服务器呢(实际项目中更有某台缓存服务器故障下线，或添加新的缓存服务器)？目前的做法是一致性hash，具体算法大家可以去查一下哦。</p>

<p>&emsp;&emsp;对分布式的Redis的访问，java客户端程序Jedis中已有实现，具体代码如下：</p>

<p>``` java</p>

<p>List<JedisShardInfo> jdsInfoList =new ArrayList<JedisShardInfo>();
//集群中的A服务器
JedisShardInfo infoA = new JedisShardInfo(hostA, portA);
//集群中的B服务器
JedisShardInfo infoB = new JedisShardInfo(hostB, portB);</p>

<p>//加入可用结点中
jdsInfoList.add(infoA);
jdsInfoList.add(infoB);</p>

<p>//下面的Hashing.MURMUR_HASH就是由Jedis提供的分布式的hash key算法
ShardedJedisPool pool =new ShardedJedisPool(config, jdsInfoList, Hashing.MURMUR_HASH, Sharded.DEFAULT_KEY_TAG_PATTERN);</p>

<p>ShardedJedis jedis = pool.getResource();</p>

<p>//下面就可以进行操作了哦</p>

<p>```</p>

<p>&emsp;&emsp;下面简单说一下，在java中如何访问redis。现在常用的客户端是jedis,具体的操作我也不想再写了，大家可以从这些方面去体验Redis的独特之处，我贴出网址。</p>

<p>&emsp;&emsp;一、丰富数据类型的支持。<a href="http://www.open-open.com/lib/view/open1385173126448.html">redis中各种数据类型对应的jedis操作命令 </a>.</p>

<p>&emsp;&emsp;二、对字符串的操作。<a href="http://blog.csdn.net/java2000_wl/article/details/8535486">redis &ndash; String字符串操作 </a>.</p>

<p>&emsp;&emsp;三、事务等特性。<a href="http://www.blogways.net/blog/2013/06/02/jedis-demo.html">Redis的Java客户端Jedis的八种调用方式(事务、管道、分布式…)介绍</a>.</p>

<p>&emsp;&emsp;四、其它的一些特殊用途，比如跨jvm主键生成器等。<a href="http://www.blogjava.net/masfay/archive/2012/07/03/382080.html">Jedis使用总结【pipeline】【分布式的id生成器】【分布式锁【watch】【multi】】【redis分布式】</a>.</p>

<p>&emsp;&emsp;大家要注意的是，大部分Jedis api的操作上传入的参数都是String或byte[],如果我们需要把对象放入redis中去，必须对对象进行序列化，而从redis中读出来又得反序列化，比如下面的代码：</p>

<p>``` java</p>

<p>tx.set(&ldquo;key_user1&rdquo;.getBytes(), SerializationUtils.serialize(u));</p>

<p>User u = (User)SerializationUtils.deserialize(jedis.get(&ldquo;key_user1&rdquo;.getBytes()));</p>

<p>```</p>

<p>&emsp;&emsp;其中SerializationUtils是由spring core提供的，你也可以使用apache工具包中提供的类似功能类，或都自己用对象流实现也是一样的。</p>

<p>&emsp;&emsp;另外，如果您的项目中使用spring框架，您可以使用<a href="http://projects.spring.io/spring-data-redis/#quick-start">spring-data-redis</a>，spring data redis提供了几个常用的redis客户端的封装，以在高层面抽像出统一的使用接口（其实相当于适配器），建议在spring项目中采用这种方式。</p>

<p>&emsp;&emsp;同时，taobao也开源了自己redis客户端<a href="https://github.com/taobao/tedis">tedis</a>，据说具有更好的性能和可用性，tedis还提供了object的高层api，使用起来更为方便。另外，taobao开源了很多的软件系统，对于中国的开源界来说是一件很好的事，相比腾讯这些自私的公司，品质自然不在一个档次，但阿里系统的开源源代码中似乎都不写什么注释说明的（比如druid连接池开源代码），也许是这些公司的牛人太忙了，也许是认为写了注释也没人会去看吧，呵呵。</p>

<p>&emsp;&emsp;好,redis的内容先简单介绍到这吧。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[读写分离架构之mysql实例]]></title>
    <link href="http://yanyaner.com/blog/2014/03/10/db-read-write-split/"/>
    <updated>2014-03-10T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/10/db-read-write-split</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;读写分离架构对提升系统性能非常重要，特别是在互联网项目中，查询操作可能达到90%以上，而且有较高的并发性。</p>

<p>&emsp;&emsp;对于数据库的读写分离，即是把所有的增、删、改操作发送到主数据库，所有查询操作发送到从数据库，通过增加从数据库实例个数以提升查询性能。当然也可以使用noSql数据库(如mongodb,hbase等)、搜索引擎（如lucene）等技术来做查询，关系数据库做核心数据保存，这种方式也是基于读写分离架构。</p>

<p>&emsp;&emsp;更多性能优化文章，大家可以参考我的文章：
<a href="/blog/2010/11/05/prof-web/">系统性能优化总结之表现层</a>，<a href="/blog/2010/11/08/prof-service/">系统性能优化总结之业务层</a>，<a href="/blog/2010/11/09/prof-dao/">系统性能优化总结之持久层篇</a>，技术在不断发展，这三篇文章是几年前写的，目前看来少了很多东西，我后续将把一些近年来新的内容添加上去以符合一些新的场景。</p>

<p>&emsp;&emsp;目前很多数据库都支持主从复制，读写分离，如：Oracle， SqlServer， Mysql等，主数据库在写入数据时同时同步到从数据库。此文以mysql为例给大家加以介绍。网上也有很多这样的文章，大家可以去搜索阅读，但这些文章基本上都是基于*inux平台的，我将以windows平台的配置为例（其实原理都是一样的，只是配置上的一些差异而已）。</p>

<p>&emsp;&emsp;简单起见，机器用我的笔记本。localhost:3307为主服务器master，localhost:3308为从属服务器slave（可以增加多个slave），mysql版本为5.6。先配置主服务器，编辑my.ini，内容如下：<!-- more--></p>

<p>``` ini</p>

<p>[mysqld]
 basedir =D:/server/db/MySQL Server5.6
 datadir =D:/server/db/mysql_db1/dbfile
 port = 3307
 server_id = 1
 log-bin=mysql-bin</p>

<p> skip-character-set-client-handshake
 init-connect = &lsquo;SET NAMES utf8&rsquo;
 character_set_server=utf8
 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</p>

<p>```</p>

<p>&emsp;&emsp;从属数据库配置是(和主服务器的差别在于port、server_id与datadir不同)：</p>

<p><code>ini
[mysqld]
 basedir =D:/server/db/MySQL Server5.6
 datadir =D:/server/db/mysql_db2/dbfile
 port = 3308
 server_id = 10
 log-bin=mysql-bin
 skip-character-set-client-handshake
 init-connect = 'SET NAMES utf8'
 character_set_server=utf8
 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
</code></p>

<p>&emsp;&emsp;为了方便启动，把这两个数据库都注册为win服务，命令如下：</p>

<p>```
 D:\server\db\MySQL Server5.6\bin>mysqld
 &mdash;install mysql5.6.master
 &mdash;defaults-file=D:\server\db\mysql_db1\my.ini</p>

<p>```</p>

<p>&emsp;&emsp;从属服务器的注册与之类似不在写出，我们接下来在系统服务中分别启动这两个服务器实例。</p>

<p>&emsp;&emsp;再接下来要做的事情是配置主从复制功能，主服务器的增、删、改数据操作都将同步到多台从属服务器上，先在主服务器上给从属服务器分配登录账号，这个账号将是从属服务器进行数据同步操作的授权，命令如下（账号是backup，密码是123）：</p>

<p>```
GRANT REPLICATION SLAVE ON
<em>.</em> to &lsquo;backup&rsquo;@&lsquo;localhost&rsquo;
identified by &lsquo;123’;</p>

<p>```</p>

<p>&emsp;&emsp;继续命令行中运行：show master status; 记录下File及Position两个输出内容，这两个参数在配置slave时需要用到。</p>

<p>&emsp;&emsp;登录从服务器，执行下面的命令：</p>

<p><code>
change master to
master_host=’localhost’,
master_port=3307,
master_user=’backup’,
master_password=’123’,
master_log_file=’mysql-bin.000006’,
master_log_pos=120;
</code></p>

<p>&emsp;&emsp;上面命令中的master_host及master_port是主服务器的地址和端口号，master_user及master_password是授权命令输入的账号、密码，master_log_file及master_log_pos是show master status输出的东西。</p>

<p>&emsp;&emsp;接下来，从属服务器上运行start slave就可以启动从属服务，运行show slave status\G查看状态，如果输出的Slave_IO_Running和Slave_SQL_Running都是yes，则表示配置成功（如果配置有误，可stop slave服务，再次运行change master命令）。</p>

<p>&emsp;&emsp;至此，mysql的主从复制功能就配置完成了。也许你会说，我们的所有增、删、改通过对localhost:3307这个数据库操作，查询通过localhost:3308这个数据库操作不就完成了么？确实如你所说，这种方案是可行的，我们可以在spring中配置两个Datasource，并在技术架构上进行处理，把查询接口单独封装出来以使用不同的数据源。大家可以到我的博客文章<a href="/blog/2010/11/01/p4/">四种持久层设计方案比较</a>中，查看其中的方案三设计。</p>

<p>&emsp;&emsp;当然，上面的访问方式也是有缺陷的，主要体现在，读写分离操作对应用程序并不透明，比如有多台读服务器，你的读操作数据源该如何去配置呢？读写分离会影响到应用代码？因此，我们还得寻找另一种对应用透明的访问方式，这就是用代理模式，屏蔽底层访问细节，这个代理类来负责低层的读写分离，缓存连接（相当于连接池），还包括读操作的负载均衡。</p>

<p>&emsp;&emsp;mysql-proxy就是这样一个程序，我下载的是mysql-proxy-0.8.4-win32-x86.zip，解压后运行bin中的mysql-proxy.exe即可。如果mysql-proxy.exe无法运行，可能是缺少vc2008支持包，大家到微软官网下载vcredist_x86.exe并安装。</p>

<p>&emsp;&emsp;为了后期运行方便，可以配置一个bat批处理文件，启动代理程序：</p>

<p><code>
D:\server\db\mysql-proxy\bin\mysql-proxy.exe
 --proxy-backend-addresses=localhost:3307
 --proxy-read-only-backend-addresses=localhost:3308
 --proxy-lua-script=D:\server\db\mysql-proxy\share\doc\mysql-proxy\rw-splitting.lua
</code></p>

<p>&emsp;&emsp;上面的配置中大家要注意：proxy-read-only-backend-addresses可以写多台服务器，用逗号分割开；rw-splitting.lua是读写分离lua脚本文件，您可以进行编辑以符合你的要求（比如有人修改min_idle_connections及max_idle_connections来观察到读写分离的效果），但一般情况下并不需要；你可以通过&mdash;proxy-address=host:port指定代理服务器端口号，如果不指定默认为4040(另，管理端口默认是4041，可以看到一些状态参数)。</p>

<p>&emsp;&emsp;应用程序中通过连接localhost:4040即可操作mysql数据库了，后台的一切都是通过mysql-proxy去处理的，数据库连接对应用程序变得透明了，我们的任务也就完成了。</p>

<p>&emsp;&emsp;下篇给出读写分离的性能测试数据。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[项目中ibatis与hibernate混用示例详解]]></title>
    <link href="http://yanyaner.com/blog/2014/03/06/ibatis-hibernate-in-query/"/>
    <updated>2014-03-06T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/06/ibatis-hibernate-in-query</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;对于一般的项目hibernate足以胜任，但在选择一个框架时都要考虑适用场景（比如非功能性需求），hibernate也不例外，比如：复杂多条件组合查询对于hibernate来说并不方便（我们需要手工拼接sql）。基于这样的原因，很多项目中会引入ibatis来做复杂查询操作以做为补充，这主要是针对编码复杂度的考虑，性能也是其次的一个因素（其实hibernate也不存在问题的，你还记得到hibernater中有SqlQuery么，呵呵）。</p>

<p>&emsp;&emsp;下面我给出一个简单的ibatis与hibernate混用示例，并在最后说明在实际使用过程中应该注意的问题。先来看spring的核心配置文件：</p>

<p>``` xml spring-core.xml</p>

<pre><code>&lt;!-- 读取配置参数 --&gt;
&lt;bean class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt;
    &lt;property name="location"&gt;
        &lt;value&gt;classpath:database.properties&lt;/value&gt;
    &lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 配置数据源 --&gt;
&lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource"
      init-method="init" destroy-method="close"
&gt;
    &lt;property name="driverClassName"&gt;
        &lt;value&gt;${driverClassName}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="url"&gt;
        &lt;value&gt;${url}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="username"&gt;
        &lt;value&gt;${username}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="password"&gt;
        &lt;value&gt;${pwd}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="defaultAutoCommit"&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="initialSize" value="1" /&gt;
    &lt;property name="filters" value="stat,log4j" /&gt;
    &lt;property name="name" value="myDatasource1"&gt;&lt;/property&gt;
    &lt;!-- 最大活动连接数，也就是连接池中的最大缓存连接数 --&gt;
    &lt;property name="maxActive" value="20" /&gt;
    &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt;
    &lt;property name="timeBetweenEvictionRunsMillis" value="10000" /&gt;
    &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt;
    &lt;property name="minEvictableIdleTimeMillis" value="10000" /&gt;
    &lt;property name="minIdle" value="1" /&gt; 


&lt;/bean&gt;

&lt;!-- hibernate参数配置文件，包括缓存的信息 --&gt;
&lt;bean id="hibernateProperties" class="org.springframework.beans.factory.config.PropertiesFactoryBean"&gt;
    &lt;property name="location"&gt;
        &lt;value&gt;classpath:hibernate-config.properties&lt;/value&gt;
    &lt;/property&gt;
&lt;/bean&gt;


&lt;!--  配置sessionFactory--&gt;
&lt;bean id="sessionFactory" class="org.springframework.orm.hibernate3.annotation.AnnotationSessionFactoryBean"&gt;
    &lt;property name="dataSource"&gt;
        &lt;ref bean="dataSource" /&gt;
    &lt;/property&gt;
    &lt;property name="hibernateProperties" ref="hibernateProperties"&gt;&lt;/property&gt;
    &lt;property name="packagesToScan"&gt;
        &lt;list&gt;
            &lt;value&gt;com.my.monitor.model&lt;/value&gt;
        &lt;/list&gt;
    &lt;/property&gt; 
&lt;/bean&gt;

&lt;!-- 配置事务管理器 --&gt;
&lt;bean id="transactionManager"
    class="org.springframework.orm.hibernate3.HibernateTransactionManager"&gt;
    &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 对注解事务的支持 --&gt;
&lt;tx:annotation-driven transaction-manager="transactionManager" /&gt;

&lt;!-- 注解驱动 --&gt;
&lt;context:component-scan base-package="com.my.monitor" &gt;&lt;/context:component-scan&gt; 

&lt;!-- hibernate通用dao --&gt;
&lt;bean id="hibernateBaseDao"
    class="com.my.ms.framework.persistence.hibernate.BaseDaoHibernateImpl"&gt;
    &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- ibatis通用dao，一般用于查询 --&gt;
&lt;bean id="ibatisBaseDao" class="com.my.ms.framework.persistence.ibatis.BaseDao"&gt;
    &lt;property name="sqlMapClient"&gt;
        &lt;bean class="org.springframework.orm.ibatis.SqlMapClientFactoryBean"&gt;
            &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;
            &lt;property name="configLocation"&gt;
                &lt;value&gt;classpath:config/ibatis/sqlMapConfig.xml&lt;/value&gt;
            &lt;/property&gt;
        &lt;/bean&gt;
    &lt;/property&gt;
&lt;/bean&gt;
</code></pre>

<p>```</p>

<p>&emsp;&emsp;这里封装了两个baseDao，分别针对的是hibernate与ibatis书写，源代码如下：<!-- more --></p>

<p>``` java BaseDaoHibernateImpl.java
package com.my.ms.framework.persistence.hibernate;</p>

<p>import java.io.Serializable;
import java.util.ArrayList;
import java.util.List;</p>

<p>import org.hibernate.HibernateException;
import org.hibernate.Query;
import org.hibernate.Session;
import org.springframework.orm.hibernate3.HibernateCallback;
import org.springframework.orm.hibernate3.support.HibernateDaoSupport;
import org.springframework.util.Assert;</p>

<p>import com.my.ms.framework.persistence.model.Page;</p>

<p>public class BaseDaoHibernateImpl extends HibernateDaoSupport implements</p>

<pre><code>    IBaseDao {

@Override
public void addEntity(Object entity) {
    getHibernateTemplate().save(entity);
}

@Override
public void updateEntity(Object entity) {
    getHibernateTemplate().update(entity);
}

@Override
public void deleteEntity(Object entity) {
    getHibernateTemplate().delete(entity);
}

@Override
public void deleteEntityById(Class clazz, Serializable id) {
    getHibernateTemplate().delete(this.queryEntityById(clazz, id));
}

@Override
public &lt;T&gt; T queryEntityById(Class&lt;T&gt; clazz, Serializable id) {
    return getHibernateTemplate().get(clazz, id);
}

@Override
public List queryEntitys(String queryString, Object[] values) {
    return getHibernateTemplate().find(queryString, values);
}

@Override
public Page queryEntityByPage(int pageNo, int pageSize, String queryString,
        Object[] parameters) {
    Assert.isTrue(pageNo &gt; 0, "起始页不能小于0！");
    // 去除select 子句，未考虑union的情况
    int beginPos = queryString.toLowerCase().indexOf("from");
    Assert.isTrue(beginPos != -1, queryString + "无效，必须包含from关键字");
    String hql4Count = " select count(*)  "
            + queryString.substring(beginPos);
    return queryEntityByPage(pageNo, pageSize, queryString, hql4Count,
            parameters);
}

@Override
public Page queryEntityByPage(final int pageNo, final int pageSize,
        final String queryString4Data, final String queryString4Count,
        final Object[] parameters) {
    Assert.hasText(queryString4Count, "用于计数的hql不能为空!");
    Assert.hasText(queryString4Data, "用于查询的hql不能为空！");
    Assert.isTrue(pageNo &gt; 0, "起始页不能小于0！");
    return (Page) getHibernateTemplate().execute(new HibernateCallback() {

        public Object doInHibernate(Session session)
                throws HibernateException {

            // 根据指定的参数执行hibernate hql查询
            List countlist = getHibernateTemplate().find(queryString4Count,
                    parameters);

            long totalCount = ((Long) countlist.get(0)).longValue();
            // 如果记录总数小于1则返回空的Page
            if (totalCount &lt; 1)
                return new Page(pageNo, pageSize, new ArrayList(), 0);
            int startIndex = Page.getStartOfPage(pageNo, pageSize);
            Query query = getSession().createQuery(queryString4Data);
            for (int i = 0; i &lt; parameters.length; i++) {
                query.setParameter(i, parameters[i]);
            }
            List list = query.setFirstResult(startIndex)
                    .setMaxResults(pageSize).list();
            return new Page(pageNo, pageSize, list, (int) totalCount);
        }

    });
}
</code></pre>

<p>}</p>

<p>```</p>

<p>针对ibatis的baseDao封装，主要是添加了一个分页方法，代码如下：</p>

<p>``` java BaseDao.java</p>

<p>package com.my.ms.framework.persistence.ibatis;</p>

<p>import java.util.Map;</p>

<p>import org.springframework.orm.ibatis.SqlMapClientTemplate;</p>

<p>import com.my.ms.framework.persistence.model.Page;</p>

<p>public class BaseDao extends SqlMapClientTemplate {</p>

<pre><code>/**
 * 分页查询(sql语句块中的分页参数，请使用start与end)
 * @param pageNo
 * @param pageSize
 * @param sqlId4Data
 * @param sqlId4count
 * @param queryParam
 * @return
 */
public Page queryEntityByPage(int pageNo, int pageSize, String sqlId4Data, String sqlId4Count, Map queryParam) {

    queryParam.put("start", (pageNo - 1) * pageSize);
    queryParam.put("end", pageSize);

    Page page = new Page(pageNo, pageSize);

    page.setData(queryForList(sqlId4Data, queryParam));
    page.setRowcounts(((Number)queryForObject(sqlId4Count, queryParam)).intValue());

    return page;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;上面两个实现的分页部分，用到了Page对象，请看分页对象的代码：</p>

<p>``` java</p>

<p>package com.my.ms.framework.persistence.model;</p>

<p>import java.util.List;</p>

<p>/<em>*
 * 分页对象
 * @author ljh
 *
 </em>/
public class Page<T> {</p>

<pre><code>/**
 * 数据对象
 */
private List&lt;T&gt; data;

private int rowcounts;
/**
 * 页码
 */
private int pageNo;
/**
 * 最大显示页数
 */
private int pageSize;

public Page(){

}

public Page(int pageNo, int pageSize) {
    this.pageNo = pageNo;
    this.pageSize = pageSize;
}

public Page(int pageNo, int pageSize, List&lt;T&gt; data, int rowcounts) {
    this.pageNo = pageNo;
    this.pageSize = pageSize;
    this.data = data;
    this.rowcounts = rowcounts;
}

//计算该页对应的数据库下标
public static int getStartOfPage(int pageNo, int pageSize) {
    if (0 &gt; pageNo)
        throw new IllegalArgumentException("页面索引不能小于0!");
    return (pageNo - 1) * pageSize;
}


//共有多少页
public int getPages() {
    if (rowcounts % pageSize == 0) 
    {
        return rowcounts/pageSize;
    } else {
        return rowcounts/pageSize + 1;
    }
}

public int getFirstNo() {
    return 1;
}

public int getLastNo() {
    return getPages();
}

public int getPreNo() {
    if (pageNo - 1 &gt; 0 ) {
        return pageNo - 1;
    } else {
        return 1;
    }
} 

public int getNextNo() {
    if (pageNo + 1  &lt;= getPages()) {
        return pageNo + 1;
    }
    return getPages();
}



public List&lt;T&gt; getData() {
    return data;
}

public void setData(List&lt;T&gt; data) {
    this.data = data;
}

public int getPageNo() {
    return pageNo;
}

public void setPageNo(int pageNo) {
    this.pageNo = pageNo;
}

public int getPageSize() {
    return pageSize;
}

public void setPageSize(int pageSize) {
    this.pageSize = pageSize;
}

public int getRowcounts() {
    return rowcounts;
}

public void setRowcounts(int rowcounts) {
    this.rowcounts = rowcounts;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;具体使用时就比较方便了，下面是一个调用示例：</p>

<p>``` java UserServiceImpl.java</p>

<p>@Service
@Transactional(readOnly=false)
public class UserServiceImpl implements IUserService{</p>

<pre><code>@Resource
private IBaseDao hibernateDao;

@Resource
private BaseDao ibatisDao;

@Override
public User someBizMethod(int userId) {

    ......

    User u1 = (User)hibernateDao.queryEntityById(User.class, userId);
    u1.setUserName(u2.getUserName() + "hibernate");
    hibernateDao.updateEntity(u1);

    User u2 = (User)ibatisDao.queryForObject("znjk.getUserById", userId);
    u2.setUserName(u2.getUserName() + "ibatis");
    ibatisDao.update("znjk.updateUser",  u2);

    ......
</code></pre>

<p>```</p>

<p>&emsp;&emsp;好了，在上面的示例中还存在一些必须要弄明白的问题。</p>

<p>&emsp;&emsp;一、事务管理问题。大家可以看到，我在spring文件中只配置了一个事务管理器，并且是hibernate的事务管理器，那么，有人就有会疑问：hibernater的事务可以应用在ibatis的dao上么？答案是肯定的。至于原因，你想想spring事务管理是通过AOP来实现的，并且最终映射到底层的话，事务是通过在jdbc的connection上完成的，而在我上面的这个业务方法中，两个dao拿到的是同一个连接，因此，方法中的所有操作都在一个事务环境中了，这个事务是通过hibernate事务管理器启动的。</p>

<p>&emsp;&emsp;二、缓存同步问题。两个框架都有自己不同的缓存配置及实现，而且互不相关。因为这个原因，我上面的代码没法对保证缓存的一致性，所以，我的建议是：ibatis仅仅只做复杂查询，hibernate什么都可以做。此外，还有一个方案是，配置ibatis的数据源事务管理器，在不同的方法中，通过@Transactional注解来指定这个业务方法使用的事务管理器（比如：@Transactional(readOnly=false,value=&ldquo;dataSourceTransactionManager&rdquo;)），也就是说，在每一个方法中不存在两个dao混用的情况，而在不同的方法中，用不同的事务管理器操作事务的提交。</p>

<p>&emsp;&emsp;ibatis的优势在于查询，特别是类似下面的组合查询，十分的方便。复杂查询更是如此。</p>

<p>``` xml
<sql id="where4pet"></p>

<pre><code>    &lt;dynamic prepend="where"&gt;
        &lt;isNotNull property="nickName" prepend="and"&gt;
            f_nick_name like '%$nickName$%'
        &lt;/isNotNull&gt;
        &lt;isNotNull property="password" prepend="and"&gt;
            f_password like '%$password$%'
        &lt;/isNotNull&gt;
        &lt;isNotNull property="birthday" prepend="and"&gt;
            f_birthday = #birthday#
        &lt;/isNotNull&gt;
        &lt;isNotNull property="gender" prepend="and"&gt;
            &lt;isEqual compareProperty="gender" compareValue="true"&gt;
                f_gender = 'T'
            &lt;/isEqual&gt;
            &lt;isEqual compareProperty="gender" compareValue="false"&gt;
                f_gender = 'F'
            &lt;/isEqual&gt;
        &lt;/isNotNull&gt;
        &lt;isNotNull property="age" prepend="and"&gt;
            f_age = #age#
        &lt;/isNotNull&gt;
    &lt;/dynamic&gt;
&lt;/sql&gt;

&lt;select id="getPetByPage4data" resultMap="resultMapPet" &gt;
    select *
    from t_pet
    &lt;include refid="where4pet"/&gt;
    order by $field$
    limit #start#, #end#
&lt;/select&gt;
&lt;select id="getPetByPage4count" resultClass="int"&gt;
    select count(*)
    from t_pet
    &lt;include refid="where4pet"/&gt;
&lt;/select&gt;
</code></pre>

<p>```</p>

<p>&emsp;&emsp;这样的话，我们就可以充分利用不同框架的优势，达到取长补短的目的。也许你会说，这种方式就是把增、删、改交由hibernate来做，把查询交由ibatis来做。本质上看确实如此，但实际项目中要灵活去做，比如hibernate除了增删改外也可以做查询，特别是简单的查询，这样也可以更好的利用到hibernate的缓存。</p>

<p>&emsp;&emsp;我在<a href="/blog/2010/11/01/p4">四种持久层设计方案比较</a>中，对查询的分离有所介绍，有兴趣的可以去看看其中的一个方案，另外，CQRS架构、mysql读写分离也有这方面的含义。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[再次简单封装的jackson]]></title>
    <link href="http://yanyaner.com/blog/2014/03/04/objectmapper-json/"/>
    <updated>2014-03-04T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/04/objectmapper-json</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;接上一篇<a href="/blog/2014/03/03/objectmapper-json">Json类库jackson使用之误区</a>，我对json的常用操作再次进行了简单的封装，上一版的封装大家可参阅<a href="/blog/2012/12/14/jackson">Jackson之json类二次封装</a>。</p>

<p>&emsp;&emsp;总计两个文件，只考虑到了一些简单常用的操作：</p>

<p>``` java FilterProvider.java</p>

<p>package com.my.ms.framework.commons;</p>

<p>import org.codehaus.jackson.map.ser.impl.SimpleBeanPropertyFilter;
import org.codehaus.jackson.map.ser.impl.SimpleFilterProvider;
/<em>*
 * 属性过滤器
 * @author ljh
 *
 </em>/
public class FilterProvider extends SimpleFilterProvider {</p>

<pre><code>/**
 * 将新的需要的属性添加到一个现有的FilterProvider中
 * @param id
 * @param includeProperties
 * @return
 */
public FilterProvider addIncludeProperties(String id,
        String... includeProperties) {
    this.addFilter(id,
            SimpleBeanPropertyFilter.filterOutAllExcept(includeProperties));
    return this;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;FilterProvider.java中主要增加了一个输出时添加包含属性的方法，并返回自身以支持方法链编程。<!-- more --></p>

<p>``` java JsonMapper.java</p>

<p>package com.my.ms.framework.commons;</p>

<p>import java.io.IOException;
import java.io.OutputStream;
import java.text.SimpleDateFormat;</p>

<p>import org.codehaus.jackson.JsonGenerationException;
import org.codehaus.jackson.map.DeserializationConfig;
import org.codehaus.jackson.map.JsonMappingException;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.map.SerializationConfig.Feature;
import org.codehaus.jackson.map.ser.impl.SimpleBeanPropertyFilter;
import org.codehaus.jackson.map.ser.impl.SimpleFilterProvider;</p>

<p>/<em>*
 * json之jackson封装
 * 主要对常用的几个json方法进行了再次包装，并具备线程安全性
 * @author ljh
 *
 </em>/
public class JsonMapper {</p>

<pre><code>private ObjectMapper objectMapper;

public JsonMapper() {
    objectMapper = new ObjectMapper();
    // 设置默认日期格式
    objectMapper.setDateFormat(new SimpleDateFormat("yyyy-MM-dd"));
    // 提供其它默认设置
    objectMapper
            .disable(DeserializationConfig.Feature.FAIL_ON_UNKNOWN_PROPERTIES);
    objectMapper.configure(Feature.FAIL_ON_EMPTY_BEANS, false);
    objectMapper.setFilters(new SimpleFilterProvider()
            .setFailOnUnknownId(false));

}

/**
 * 创建一个FilterProvider对象
 * 
 * @return
 */
public static FilterProvider buildFilterProvider() {
    FilterProvider filter = new FilterProvider();
    filter.setFailOnUnknownId(false);
    return filter;
}

/**
 * 根据需要的对象属性，创建一个属性过滤器FilterProvider
 * 
 * @param id
 *            对象id，通过jsonFilter声明
 * @param includeProperties
 *            该对象上需要的属性
 * @return  创建好的过滤器
 */
public static FilterProvider buildFilterProvider(String id,
        String... includeProperties) {
    FilterProvider filter = new FilterProvider();
    filter.setFailOnUnknownId(false);

    filter.addFilter(id,
            SimpleBeanPropertyFilter.filterOutAllExcept(includeProperties));
    return filter;
}

// 用提供的过滤器，将对象的json输出到流中
public void writeValue(FilterProvider filter, OutputStream os, Object value)
        throws JsonGenerationException, JsonMappingException, IOException {
    objectMapper.writer(filter).writeValue(os, value);
}

// 用提供的过滤器，将对象的json输出为字符串
public String writeValueAsString(FilterProvider filter, Object value)
        throws JsonGenerationException, JsonMappingException, IOException {
    return objectMapper.writer(filter).writeValueAsString(value);
}

// 将对象的json输出到流中
public void writeValue(OutputStream os, Object value)
        throws JsonGenerationException, JsonMappingException, IOException {
    objectMapper.writeValue(os, value);
}

// 将对象的json输出为字符串
public String writeValueAsString(Object value)
        throws JsonGenerationException, JsonMappingException, IOException {
    return objectMapper.writeValueAsString(value);
}

/**
 * 得到原始的objectMapper，以进行更复杂的操作
 * 
 * @return
 */
public ObjectMapper getObjectMapper() {
    return objectMapper;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;如果需要更强大的功能，我们可以通过getObjectMapper得到ObjectMapper后进行操作，或都添加你常用的其它方法到JsonMapper中，比如：排除属性的方法等。</p>

<p>&emsp;&emsp;使用时，请把JsonMapper放入spring容器(当然你也可以把这个类做成单例的哦)，在需要转换json的地方，通过@Resource注入即可，调用代码如下：</p>

<p>``` java</p>

<pre><code>@Resource
private JsonMapper mapper;

@Test
public void testJson() throws Exception {

    Object someObject = ....

    String result = mapper.writeValueAsString(
            JsonMapper.buildFilterProvider()
            .addIncludeProperties("myId1", "id","name")
            .addIncludeProperties("myId2", "code","money","name"), 
            someObject);

    assertEquals("xxxxxxxxxxxx", result);

}
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
</feed>
