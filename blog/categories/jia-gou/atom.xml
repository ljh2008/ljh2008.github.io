<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[☺分类☺：架构 | 刘江华的博客]]></title>
  <link href="http://yanyaner.com/blog/categories/jia-gou/atom.xml" rel="self"/>
  <link href="http://yanyaner.com/"/>
  <updated>2014-05-30T11:14:49+08:00</updated>
  <id>http://yanyaner.com/</id>
  <author>
    <name><![CDATA[冰雨]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[分布式文件系统fastdfs解析之一(安装)]]></title>
    <link href="http://yanyaner.com/blog/2014/05/30/fastDFS-setup/"/>
    <updated>2014-05-30T15:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/05/30/fastDFS-setup</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;fastdfs是一个轻量级的分布式文件系统服务，它在互联网项目中有比较广泛的用途，类似的还有tfs等，但fastdfs和hadoop这些又不相同，hadoop是分布式存储计算框架，比较重量级，而fastdfs针对的是海量的小文件。</p>

<p>&emsp;&emsp;项目中经常会有这样一些应用场景，比如：文件服务器需要存储海量的用户文件并且对外提供用户的访问操作；文件服务器需要高可用性和高性能；文件服务器需要实现负载均衡；文件服务器可实时扩容等等，这些需求在Fastdfs中有实现，因此它可以满足大部的项目需求。</p>

<p>&emsp;&emsp;先给大家简单介绍一下fastdfs的原理，下面这张图有助于大家了解分布式文件系统的原理（hadoop之类的分布式体系与之有相似之处）。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/seq_fastdfs.jpg' width='' height='' title='fastdfs调用时序图'><span class='caption-text'>fastdfs调用时序图</span></span></p>

<p>&emsp;&emsp;上面这张图中客户端针对文件服务系统的调用，首先得通过tracker服务器，这个服务器充当了调度者的作用。客户端可以是任何的程序客户端，比如java客户端、php客户端、nginx插件客户端等。</p>

<p>&emsp;&emsp;在客户端调用之前先得启动tracker server，然后再分别启动各个storage server，每个storage server启动后会注册自己的信息到指定的tracker server中（其实，tracker server服务器也可以有多个，从高可用性方面考虑我们一般会启动多个tracker server实例）。</p>

<p>&emsp;&emsp;storage server负责具体文件的存储。storage server按照分组的方式来保存文件的，比如group1,group2等。一个组中可以有多台服务器，同一个组里的所有服务器中保存的文件内容都是相同的，因为同一个组中的服务器之间会相互自动同步文件，这样就实现了冗余备份及负载均衡的功能（负载均衡由tracker server调试的哦）。</p>

<p>&emsp;&emsp;不同组中的storage server之间是独立的，当系统存储容量不够时，通过添加新服务器并分配到新的组中，tracker server发现新的服务器后会自动调度以实现后续客户文件的写入位置。</p>

<p>&emsp;&emsp;上图中，客户通过询问tracker server得到可用的storage server（tracker server会通过负载均衡及各个storage的存储可用容量大小算法决定，当然这个也可以在配置文件中指定），客户端得到storage server后进行相应的文件操作，同组服务器间会根据操作的结果进行文件同步（时序9，10是同步操作）。</p>

<p>&emsp;&emsp;好了，原理先说到这。下面，我将给大家简单介绍FastDfs的安装及使用，以及一些注意事项。</p>

<p>&emsp;&emsp;我的服务器是ubuntu server，我计划安装在两台服务器上，ip分别是:192.168.68.133, 192.168.68.136，暂时简称为1号服务器，2号服务器。</p>

<p>&emsp;&emsp;一号服务器上，将安装一个tracker server实例，一个位于group1中的storage server实例，一个位于group2中storage server实例。二号服务器上，也将安装一个tracker server实例，一个位于group1中的storage server实例。需要大家注意的是，fastdfs中一台服务器上可以安装多个组，但一个组中的多个storade server必须安装在不同的服务器上，并且同组中的storage server的服务端口必须一致，否则无法实现文件同步。</p>

<p>&emsp;&emsp;我先在一号服务器192.168.68.133上安装fastdfs。首先要准备安装环境，不同的linux发行版本可能会有所不同，我用的服务器版本是ubuntu 12.04 server，以下的操作均以这个版本的ubuntu服务器为例。<!--more--></p>

<p><code>
vim /etc/profile
export LANGUAGE="en_US.UTF-8"
export LANG=en_US:zh_CN.UTF-8
export LC_ALL=C
</code>
&emsp;&emsp;接下来让语言环境配置参数立即生效：</p>

<p><code>
source /etc/profile
</code>
&emsp;&emsp;再接着，安装fastdfs编译依赖包，大家要注意的是少一个依赖都不行，我先前安装时缺少了libevent-dev，致使安装不成功但安装过程又不报错，花费了大量的时间。</p>

<p>```
aptitude install libevent
apt-get install libevent-dev</p>

<p>sudo apt-get update
sudo aptitude install build-essential m4</p>

<p>sudo ln -s /lib/lsb/init-functions  /etc/init.d/functions</p>

<p>```</p>

<p>&emsp;&emsp;好了，环境准备好了后就到<a href="https://code.google.com/p/fastdfs">fastdfs官网</a>上去下载安装包吧，地址<a href="https://code.google.com/p/fastdfs/downloads/list">https://code.google.com/p/fastdfs/downloads/list</a>，我下载的是
FastDFS_v4.06.tar.gz ，如果你想要安装最新版本，请用svn去下载最新的5.x版本。</p>

<p><code>
tar -zxvf FastDFS_v4.06.tar.gz
cd FastDFS
</code>
&emsp;&emsp;这样就进入了源代码目录，我们先要对安装的目录做一个规划(4.06版本默认的安装目录似乎不太合理)，我将fastdfs的所有文件都安装到/usr/local/fastdfs中，配置文件存放在/usr/local/fastdfs/conf下，这就需要我们修改源代码目录下的make.sh，下面是一些要修改的地方：</p>

<p><code>
vim make.sh
</code></p>

<p>&emsp;&emsp;需要对：</p>

<ol>
<li><p> TARGET_PREFIX，TARGET_CONF_PATH进行修改;</p></li>
<li><p> 需要对libpthread.so、libpthread.a的路径进行修改，这和ubuntu有关，其它linux发行版本并不需要改这个(你可以用find / -name &lsquo;libpthread.so&rsquo;  ，以及ind / -name &lsquo;libpthread.a&rsquo;  找到这两文件在系统中的位置)；</p></li>
<li><p> 另外要对mkdir,cp操作的几个路径进行修改为我们配置文件所在的路径。</p></li>
</ol>


<p>&emsp;&emsp;我贴出make.sh修改过的地方，请大家自行对照：</p>

<p>```
TARGET_PREFIX=/usr/local/fastdfs
TARGET_CONF_PATH=/usr/local/fastdfs/conf</p>

<p>if [ -f /usr/lib/i386-linux-gnu/libpthread.so ] || [ -f /usr/local/lib/libpthread.so ] || [ -f /lib64/libpthread.so ] || [ -f /usr/lib64/libpthread.so ] || [ -f /usr/lib/i386-linux-gnu/libpthread.a ] || [ -f /usr/local/lib/libpthread.a ] || [ -f /lib64/libpthread.a ] || [ -f /usr/lib64/libpthread.a ]; then
&hellip;&hellip;&hellip;&hellip;
&hellip;&hellip;&hellip;&hellip;</p>

<p>if [ &ldquo;$uname&rdquo; = &ldquo;Linux&rdquo; ]; then</p>

<pre><code>if [ "$WITH_LINUX_SERVICE" = "1" ]; then
  if [ ! -d /usr/local/fastdfs/conf ]; then
    mkdir -p /usr/local/fastdfs/conf
    cp -f conf/tracker.conf /usr/local/fastdfs/conf/
    cp -f conf/storage.conf /usr/local/fastdfs/conf/
    cp -f conf/client.conf /usr/local/fastdfs/conf/
    cp -f conf/http.conf /usr/local/fastdfs/conf/
    cp -f conf/mime.types /usr/local/fastdfs/conf/
  fi
</code></pre>

<p>&hellip;&hellip;&hellip;&hellip;</p>

<p>```</p>

<p>&emsp;&emsp;下面开始安装吧，如下命令：</p>

<p><code>
sudo make;
sudo make install;
sudo make clean;
</code>
&emsp;&emsp;不同的linux发行版本可能存在依赖包没有安装而报错，具体情况需要根据出错信息具体解决，我试过redhead,freebsd,openSuse,centos几个系统，都是要进行一些环境的配置才可以安装成功。</p>

<p>&emsp;&emsp;下一篇文章我将按照文章开头的服务器规划进行具体的配置，请大家关注。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[监控系统中的异步消息使用实例（二）]]></title>
    <link href="http://yanyaner.com/blog/2014/04/09/async_message_architect2/"/>
    <updated>2014-04-09T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/04/09/async_message_architect2</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;接上节，再次贴出架构图，我们接下来要讲的是图中黄色部分的配置。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/monitor_jms1.jpg' width='' height='' title='业务方法监控架构'><span class='caption-text'>业务方法监控架构</span></span></p>

<p>&emsp;&emsp;先将spy程序导成一个jar包，加入到需要监控的目标服务器lib目录，monitor_spy.jar结构如下所示：</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/jarinfo.jpg' width='' height='' title='monitor_spy.jar结构'><span class='caption-text'>monitor_spy.jar结构</span></span></p>

<p>&emsp;&emsp;为了能够实现对目标系统业务方法执行情况进行监控，需要将我们已经写好的拦截器配置到目标系统中去，下面是我的一个配置示例：</p>

<p>``` xml spring-spy.xml</p>

<pre><code>&lt;!-- jms连接工厂 --&gt;         
&lt;bean id="jmsFactory" class="org.apache.activemq.pool.PooledConnectionFactoryBean"&gt;
    &lt;property name="connectionFactory"&gt;
        &lt;bean class="org.apache.activemq.ActiveMQConnectionFactory"&gt;
            &lt;property name="brokerURL" value="tcp://localhost:61616"&gt;&lt;/property&gt;
        &lt;/bean&gt;
    &lt;/property&gt;
    &lt;!-- 配置池中最大连接数据以及最大活动连接数 --&gt;
    &lt;property name="maxConnections" value="100"&gt;&lt;/property&gt;
    &lt;property name="maximumActive" value="100"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- jms模板方法 --&gt;    
&lt;bean id="jmsTemplate" class="org.springframework.jms.core.JmsTemplate"&gt;
    &lt;constructor-arg ref="jmsFactory"&gt;
    &lt;/constructor-arg&gt;
    &lt;!-- 默认会创建queue类型的目标
    &lt;property name="defaultDestinationName" value="queue/methodSpyLogger"&gt;&lt;/property&gt; --&gt;
    &lt;property name="defaultDestination" ref="destinationQueue1"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 发送消息的目的地 --&gt;
&lt;bean id="destinationQueue1" class="org.apache.activemq.command.ActiveMQQueue"&gt;
    &lt;!-- 设置消息队列的名字 --&gt;
    &lt;constructor-arg  value="queue/methodSpyLogger" /&gt;
&lt;/bean&gt;


&lt;!-- 配置Spring和方法相关的监控 --&gt;
&lt;bean id="method-pointcut" class="org.springframework.aop.support.JdkRegexpMethodPointcut"&gt;
    &lt;property name="patterns"&gt;
        &lt;list&gt;
            &lt;value&gt;com.lovo.mis.xjgl.service.impl.*&lt;/value&gt;
        &lt;/list&gt;
    &lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 方法AOP拦截器 --&gt;
&lt;bean id="spy-method-interceptor"
      class="com.monitor.client.spy.SpyMethodIntercepter"&gt;
      &lt;property name="messageDao"&gt;
        &lt;bean class="com.monitor.client.dao.JMSMessageDaoImpl"&gt;
            &lt;property name="jmsTemplate" ref="jmsTemplate"&gt;&lt;/property&gt;
        &lt;/bean&gt;
      &lt;/property&gt;
      &lt;property name="userNameSessionKey" value="loginUserName"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 将切面应用到通知上 --&gt;
&lt;aop:config proxy-target-class="true"&gt;
    &lt;aop:advisor advice-ref="spy-method-interceptor"
                 pointcut-ref="method-pointcut" /&gt;
&lt;/aop:config&gt;
</code></pre>

<p>```</p>

<p>&emsp;&emsp;配置文件中有几个地方需要进行说明：<!-- more --></p>

<p>&emsp;&emsp;1、目标机器要修改的部分是JdkRegexpMethodPointcut中的patterns，由patterns指定需要监控的业务类所在的位置。</p>

<p>&emsp;&emsp;2、jmsFactory部分配置你的异步消息服务器连接信息，比如brokerURL等。</p>

<p>&emsp;&emsp;3、jmsTemplate中，通过defaultDestination指定一个Destination，因为一个消息服务器上存在多个Destination。也可以通过defaultDestinationName直接指定消息Destination的名称，系统默认创建的是queue，也就是说，如果你要使用topic类型的消息，就必须通过defaultDestination指定一个Destination。</p>

<p>&emsp;&emsp;4、messageDao可自由替换为其它实现类，比如你可以写一个mongoDB版本的实现以提供更好的性性，支持更大数据量。</p>

<p>&emsp;&emsp;最后来看看消费者代码，是直接使用ActiveMQ驱动实现的。</p>

<p>``` java</p>

<pre><code>    ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory("tcp://localhost:61616");

    Connection connection = factory.createConnection();

    //尝试真正建立连接，这里可以catch Exception
    connection.start();

    //得到一个会话，只有得到会话后，才可进行后续的操作
    Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);

    //创建一个目标队列
    Destination queue = session.createQueue("queue/methodSpyLogger"); 

    MessageConsumer consumer = session.createConsumer(queue);

    //可通过其它一些机制，来改变flag为false，以退出处理
    boolean flag = true;

    while (flag) {
        ObjectMessage msg = (ObjectMessage)consumer.receive();
        MethodLoggerMessage myMsg = (MethodLoggerMessage)msg.getObject();

        System.out.println(myMsg);
        //这里，可调用dao或service，向关系数据库(或nosql)中保存msg中的内容");

    }

    session.close();

    connection.close();
</code></pre>

<p>```</p>

<p>&emsp;&emsp;注意，如果队列中已经没有消息了，代码中的consumer.receive()会阻塞，直到有新的消息后再处理。我们也可以采用监听器的方式来处理消息服务器中的消息，比如下面的代码：</p>

<p>``` java</p>

<pre><code>    //处理消息者
    MessageConsumer consumer = session.createConsumer(queue);

    //处理多条消息
    consumer.setMessageListener(new MessageListener() {
        public void onMessage(Message msg) {
           //转换，这可以对类型进行检测，使用instance of
            TextMessage txtMsg = (TextMessage)msg;
            try {
                System.out.println("得到消息内容："+txtMsg.getText());
                System.out.println("处理完一条消息！！");
                //如果开启了事务，请session.commit();
            } catch (JMSException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
            }
        }
    });
</code></pre>

<p>```</p>

<p>&emsp;&emsp;当目标程序运行时，我们可以打开ActiveMQ的管理界面，即可发现这个queue及上面的消费者。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/active_mq_admin.jpg' width='' height='' title='ActiveMQ的管理界面'><span class='caption-text'>ActiveMQ的管理界面</span></span></p>

<p>&emsp;&emsp;大家还要注意的是，我们的AOP通知中，还获取了调用者的ip，访问者姓名等信息，这些和web环境相关的信息是通过类似于下面的代码实现的：</p>

<p>``` java</p>

<p>ServletRequestAttributes sas = (ServletRequestAttributes)RequestContextHolder.getRequestAttributes();
HttpServletRequest req = sas.getRequest();</p>

<p>logger.setIp(req.getLocalAddr());
logger.setSessionId(sas.getSessionId());</p>

<p>if (req.getSession() != null) {</p>

<pre><code>logger.setOperater((String)req.getSession().getAttribute(userNameSessionKey));
</code></pre>

<p>}</p>

<p>```
 &emsp;&emsp;其中的RequestContextHolder是由spring封装，具体做法是将用户web相关的信息通过filter或listener放入ThreadLocal对象中，在需要的地方通过RequestContextHolder从ThreadLocal中取得，因此，你想让上面的代码正常工作，要记得在web.xml中添加一个spring已经写好的RequestContextListener监听器哦。</p>

<p>``` xml  web.xml</p>

<pre><code>&lt;listener&gt;
    &lt;listener-class&gt;
        org.springframework.web.context.request.RequestContextListener
    &lt;/listener-class&gt;
&lt;/listener&gt;
</code></pre>

<p>```</p>

<p> &emsp;&emsp;当然，本例中所使用的消息服务器是ActiveMQ，这个服务器实现了JMS规范，在企业级应用场景中不会存在问题。如果在互联网行业中，由于会面临高并发、大流量等情况，ActiveMQ不能保证高可用性、稳定性及性能要求，这个时候我们可以考虑其它的第三方消息服务器，比如淘宝的taobao-metaq，alibaba-rocketmq等，这些服务器是经过实际考验的开源产品，值得在互联网场景中使用。当然，这些MQ服务器和JMS规范没有任何关系，JMS企业级要求中并没有考虑过多的并发、大数据量的需求。</p>

<p> &emsp;&emsp;另外，kafka，rabbitmq等消息服务器也具有不错的性能，都可以进入架构的技术方案选型范围。比如，下面是一段rabbitmq的调用示例代码(注：rabbitmq需要er_lang并发程序包支持哦)，和JMS的调用相当类似。</p>

<p>``` java
import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;</p>

<p>&hellip;&hellip;.//略去代码</p>

<pre><code>@Test
public void testSendMessage() throws Exception {
    SimpleDateFormat sf = new SimpleDateFormat("yyyy-MM-dd hh:mm:ss");

    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");

    Connection connection = factory.newConnection();
    Channel channel = connection.createChannel();

    String message = sf.format(new Date()) + ":Hello!!!";
    channel.basicPublish("", "queue/sendEmail", null, message.getBytes());


    channel.close();
    connection.close();

    System.out.println("send message ok!");



}


@Test
public void testReciveMessage() throws Exception {

    System.out.println("recever starting.....");

    String QUEUE_NAME = "queue/sendEmail";

    SimpleDateFormat sf = new SimpleDateFormat("yyyy-MM-dd hh:mm:ss");

    ConnectionFactory factory = new ConnectionFactory();
    factory.setHost("localhost");

    Connection connection = factory.newConnection();
    Channel channel = connection.createChannel();

    channel.queueDeclare(QUEUE_NAME, false, false, false, null);

    QueueingConsumer consumer = new QueueingConsumer(channel);
    channel.basicConsume(QUEUE_NAME, false, consumer);

    QueueingConsumer.Delivery delivery = consumer.nextDelivery();

    String msg = new String(delivery.getBody());

    System.out.println(msg);

    System.out.println("rec end!!!");
}
</code></pre>

<p>```</p>

<p> &emsp;&emsp;先说到这吧。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[监控系统中的异步消息使用实例（一）]]></title>
    <link href="http://yanyaner.com/blog/2014/04/08/async_message_architect1/"/>
    <updated>2014-04-08T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/04/08/async_message_architect1</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;以后的文章要尽量做到通俗，让非技术人员都读得懂，道理就跟艺术作品一样，一件好的作品，不需要配任何文字说明就足以打动普通观众，做到雅俗共赏而且有深度和内涵，其实，这需要作者相当的功力。</p>

<p>&emsp;&emsp;近期一些童鞋在实现一个监控系统，其中的一个功能是：对监控平台上布署的第三方应用业务方法执行细节进行监控，比如：方法调用者，调用者ip，应用系统名称，子系统名称，方法名称，执行耗时等信息。如何能够让监控系统得到目标机器上需要监控的业务方法执行情况呢？如何保证在监控的过程中不影响对方的业务的正常执行？下面我给出一种参考架构实现，这也是在概要设计的时候就应该明确的东西（专业名词叫架构原型）。</p>

<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/04/monitor_jms1.jpg' width='' height='' title='业务方法监控架构'><span class='caption-text'>业务方法监控架构</span></span></p>

<p>&emsp;&emsp;首先，MonitorPlatform是我们的监控平台（图中青色部分），targetServer上运行着需要监控的系统hotel project（图中黄色部分）,如果我们想要获得目标机器上的我们需要的信息，最简单的办法是运行一个spy程序在对方的机器上，图中的spy app是起这个作用的（当然你也可以使用jmx规范来实现类似功能），举个不恰当的例子，就好比你在某人的机器上安装了一个木马程序，通过远程控制端你就可以得到对方机器上你感兴趣的任何东西，甚至包括控制摄像头哦。</p>

<p>&emsp;&emsp;其次，监控平台同时要监控多个目标系统，就我们例子中监控业务方法执行情况而言，就需要把监控得到的信息加以持久化以备后查，如果目标系统业务繁忙，而我们的spy app又要将取到的信息进行数据库持久化，数据库很可能会成为性能瓶颈从而造成性能问题，因此，我在这里采用了异步消息系统的设计，以缓解持久化压力。正如图所示，spy app将采集到的业务方法执行数据直接写入异步消息服务器的queue中，而monitor platform中的处理程序将从queue中取出消息，再进行后续的持久化处理。这种异步的消息设计方式可以有效缓解系统的压力，在很多项目中都可以采用（互联网项目中可用这种方式来"削峰"，缓解高并发压力）。</p>

<p>&emsp;&emsp;最后一个问题,spy如何采集到目标机器业务方法的执行情况呢。最佳答案当然是AOP。大家可以参考我的另一篇文章<a href="/blog/2013/03/26/logger/">一种日志记录解决方案</a>。</p>

<p>&emsp;&emsp;下面，我们一起来看看架构原型中的原代码实现吧。MethodLoggerMessage是需要持久化的消息对象，请注意实现Serializable接口。<!-- more --></p>

<p>``` java MethodLoggerMessage.java</p>

<p>package com.monitor.client.commons;</p>

<p>import java.io.Serializable;
import java.util.Date;</p>

<p>/<em>*
 * 需要持久化的对象消息
 * @author ljh
 *
 </em>/
public class MethodLoggerMessage implements Serializable {</p>

<pre><code>//方法执行时间，单位：毫秒
private double howLong;
//方法名
private String methodName;
//执行者ip地址
private String ip;
//执行者session会话id
private String sessionId;
//执行者
private String operater = "";
//执行时间
private Date execTimer;

public double getHowLong() {
    return howLong;
}
public void setHowLong(double howLong) {
    this.howLong = howLong;
}
public String getMethodName() {
    return methodName;
}
public void setMethodName(String methodName) {
    this.methodName = methodName;
}
public String getIp() {
    return ip;
}
public void setIp(String ip) {
    this.ip = ip;
}
public String getOperater() {
    return operater;
}
public void setOperater(String operater) {
    this.operater = operater;
}
public String getSessionId() {
    return sessionId;
}
public void setSessionId(String sessionId) {
    this.sessionId = sessionId;
}
public Date getExecTimer() {
    return execTimer;
}
public void setExecTimer(Date execTimer) {
    this.execTimer = execTimer;
}
@Override
public String toString() {
    return "MethodLoggerMessage [howLong=" + howLong + ", methodName="
            + methodName + ", ip=" + ip + ", sessionId=" + sessionId
            + ", operater=" + operater + ", execTimer=" + execTimer + "]";
}
</code></pre>

<p>```</p>

<p>&emsp;&emsp;IMessageDao接口用来定义消息持久化行为，可以有很同种不同的实现版本，如基于消息的，关系数据库的或nosql的等等，有了这个接口，我们在intercepter中就可以做到拦截代码和持久化代码的解耦。</p>

<p>``` java IMessageDao.java
package com.monitor.client.dao;</p>

<p>import java.io.Serializable;</p>

<p>/<em>*
 * 持久化消息服务
 * @author ljh
 *
 </em>/
public interface IMessageDao {</p>

<pre><code>public void persist(Serializable msg);
</code></pre>

<p>}
```</p>

<p>&emsp;&emsp;接下来是消息持久化实现类源代码。因为采用了jms，因此我直接使用了spring对jms封装的模板方法实现。</p>

<p>``` java JMSMessageDaoImpl.java
package com.monitor.client.dao;</p>

<p>import java.io.Serializable;</p>

<p>import javax.jms.JMSException;
import javax.jms.Message;
import javax.jms.ObjectMessage;
import javax.jms.Session;</p>

<p>import org.springframework.jms.core.JmsTemplate;
import org.springframework.jms.core.MessageCreator;</p>

<p>/<em>*
 * jms消息处理实现
 * @author ljh
 *
 </em>/
public class JMSMessageDaoImpl implements IMessageDao {</p>

<pre><code>//jms模板
private JmsTemplate jmsTemplate;
//目标队列名称
private String destinationName;

@Override
public void persist(final Serializable msg) {

    MessageCreator mc = new MessageCreator() {

        @Override
        public Message createMessage(Session session) throws JMSException {
            //创建对象消息，并发送之
            ObjectMessage objMsg = session.createObjectMessage();   
            objMsg.setObject(msg);

            return objMsg;
        }
    };

    if (destinationName == null) {
        jmsTemplate.send(mc);
    } else {
        //发送到指定的目标
        jmsTemplate.send(destinationName, mc);
    }


}

public void setJmsTemplate(JmsTemplate jmsTemplate) {
    this.jmsTemplate = jmsTemplate;
}

public void setDestinationName(String destinationName) {
    this.destinationName = destinationName;
}
</code></pre>

<p>}
```</p>

<p>&emsp;&emsp;最重要的就是这个拦截器实现了。环绕拦截器，功能最为强大。</p>

<p>``` java SpyMethodIntercepter.java
package com.monitor.client.spy;</p>

<p>import java.util.Date;</p>

<p>import javax.servlet.http.HttpServletRequest;</p>

<p>import org.aopalliance.intercept.MethodInterceptor;
import org.aopalliance.intercept.MethodInvocation;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.DisposableBean;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;</p>

<p>import com.monitor.client.commons.MethodLoggerMessage;
import com.monitor.client.dao.IMessageDao;
/<em>*
 * 目标服务器方法拦截器，调用信息可以通过异步消息机制持久化，具体要看IMessageDao实现
 * @author ljh
 *
 </em>/
public class SpyMethodIntercepter implements MethodInterceptor{</p>

<pre><code>public static final Logger LOG = LoggerFactory.getLogger(SpyMethodIntercepter.class);

//消息处理dao
private IMessageDao messageDao;
//当前登录者在目标系统中的登录用户名之key,在配置第三方程序时注入
private String userNameSessionKey = "loginedUserName";

@Override
public Object invoke(MethodInvocation method) throws Throwable {

    //取方法执行时的开始时间
    long start = System.nanoTime();

    try {
        return method.proceed();
    } catch (Exception ex) {
        throw ex;
    } finally {

        try {
            //为了不影响目标方法的运行，这里再次try
            //得到访问者request对象
            ServletRequestAttributes sas = (ServletRequestAttributes)RequestContextHolder.getRequestAttributes();
            HttpServletRequest req = sas.getRequest();

            //取方法执行后的时间
            long end = System.nanoTime();

            //方法执行时间
            long howLong = end - start;
            String methodName = method.getMethod().getName();

            //持久化方法调用日志
            MethodLoggerMessage logger = new MethodLoggerMessage();

            logger.setMethodName(methodName);

            //方法执行时间，单位：毫秒
            logger.setHowLong((double)howLong/(1000*1000));

            logger.setIp(req.getLocalAddr());
            logger.setSessionId(sas.getSessionId());

            if (req.getSession() != null) {
                logger.setOperater((String)req.getSession().getAttribute(userNameSessionKey));
            }

            logger.setExecTimer(new Date());

            messageDao.persist(logger);
        } catch (Exception exc) {
            //do nothing or LOG.debug(ex.getMessage());
            LOG.warn("Error in spy: {}", exc);
        }

    }

}

public void setMessageDao(IMessageDao messageDao) {
    this.messageDao = messageDao;
}

public void setUserNameSessionKey(String userNameSessionKey) {
    this.userNameSessionKey = userNameSessionKey;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;至此，spy程序这边基本开发完成了。目标服务器上，该如何配置呢？监控平台的消息处理者又该如何实现呢？</p>

<p>&emsp;&emsp;且听下回分解。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[读写分离架构之mysql实例]]></title>
    <link href="http://yanyaner.com/blog/2014/03/10/db-read-write-split/"/>
    <updated>2014-03-10T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/10/db-read-write-split</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;读写分离架构对提升系统性能非常重要，特别是在互联网项目中，查询操作可能达到90%以上，而且有较高的并发性。</p>

<p>&emsp;&emsp;对于数据库的读写分离，即是把所有的增、删、改操作发送到主数据库，所有查询操作发送到从数据库，通过增加从数据库实例个数以提升查询性能。当然也可以使用noSql数据库(如mongodb,hbase等)、搜索引擎（如lucene）等技术来做查询，关系数据库做核心数据保存，这种方式也是基于读写分离架构。</p>

<p>&emsp;&emsp;更多性能优化文章，大家可以参考我的文章：
<a href="/blog/2010/11/05/prof-web/">系统性能优化总结之表现层</a>，<a href="/blog/2010/11/08/prof-service/">系统性能优化总结之业务层</a>，<a href="/blog/2010/11/09/prof-dao/">系统性能优化总结之持久层篇</a>，技术在不断发展，这三篇文章是几年前写的，目前看来少了很多东西，我后续将把一些近年来新的内容添加上去以符合一些新的场景。</p>

<p>&emsp;&emsp;目前很多数据库都支持主从复制，读写分离，如：Oracle， SqlServer， Mysql等，主数据库在写入数据时同时同步到从数据库。此文以mysql为例给大家加以介绍。网上也有很多这样的文章，大家可以去搜索阅读，但这些文章基本上都是基于*inux平台的，我将以windows平台的配置为例（其实原理都是一样的，只是配置上的一些差异而已）。</p>

<p>&emsp;&emsp;简单起见，机器用我的笔记本。localhost:3307为主服务器master，localhost:3308为从属服务器slave（可以增加多个slave），mysql版本为5.6。先配置主服务器，编辑my.ini，内容如下：<!-- more--></p>

<p>``` ini</p>

<p>[mysqld]
 basedir =D:/server/db/MySQL Server5.6
 datadir =D:/server/db/mysql_db1/dbfile
 port = 3307
 server_id = 1
 log-bin=mysql-bin</p>

<p> skip-character-set-client-handshake
 init-connect = &lsquo;SET NAMES utf8&rsquo;
 character_set_server=utf8
 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</p>

<p>```</p>

<p>&emsp;&emsp;从属数据库配置是(和主服务器的差别在于port、server_id与datadir不同)：</p>

<p><code>ini
[mysqld]
 basedir =D:/server/db/MySQL Server5.6
 datadir =D:/server/db/mysql_db2/dbfile
 port = 3308
 server_id = 10
 log-bin=mysql-bin
 skip-character-set-client-handshake
 init-connect = 'SET NAMES utf8'
 character_set_server=utf8
 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
</code></p>

<p>&emsp;&emsp;为了方便启动，把这两个数据库都注册为win服务，命令如下：</p>

<p>```
 D:\server\db\MySQL Server5.6\bin>mysqld
 &mdash;install mysql5.6.master
 &mdash;defaults-file=D:\server\db\mysql_db1\my.ini</p>

<p>```</p>

<p>&emsp;&emsp;从属服务器的注册与之类似不在写出，我们接下来在系统服务中分别启动这两个服务器实例。</p>

<p>&emsp;&emsp;再接下来要做的事情是配置主从复制功能，主服务器的增、删、改数据操作都将同步到多台从属服务器上，先在主服务器上给从属服务器分配登录账号，这个账号将是从属服务器进行数据同步操作的授权，命令如下（账号是backup，密码是123）：</p>

<p>```
GRANT REPLICATION SLAVE ON
<em>.</em> to &lsquo;backup&rsquo;@&lsquo;localhost&rsquo;
identified by &lsquo;123’;</p>

<p>```</p>

<p>&emsp;&emsp;继续命令行中运行：show master status; 记录下File及Position两个输出内容，这两个参数在配置slave时需要用到。</p>

<p>&emsp;&emsp;登录从服务器，执行下面的命令：</p>

<p><code>
change master to
master_host=’localhost’,
master_port=3307,
master_user=’backup’,
master_password=’123’,
master_log_file=’mysql-bin.000006’,
master_log_pos=120;
</code></p>

<p>&emsp;&emsp;上面命令中的master_host及master_port是主服务器的地址和端口号，master_user及master_password是授权命令输入的账号、密码，master_log_file及master_log_pos是show master status输出的东西。</p>

<p>&emsp;&emsp;接下来，从属服务器上运行start slave就可以启动从属服务，运行show slave status\G查看状态，如果输出的Slave_IO_Running和Slave_SQL_Running都是yes，则表示配置成功（如果配置有误，可stop slave服务，再次运行change master命令）。</p>

<p>&emsp;&emsp;至此，mysql的主从复制功能就配置完成了。也许你会说，我们的所有增、删、改通过对localhost:3307这个数据库操作，查询通过localhost:3308这个数据库操作不就完成了么？确实如你所说，这种方案是可行的，我们可以在spring中配置两个Datasource，并在技术架构上进行处理，把查询接口单独封装出来以使用不同的数据源。大家可以到我的博客文章<a href="/blog/2010/11/01/p4/">四种持久层设计方案比较</a>中，查看其中的方案三设计。</p>

<p>&emsp;&emsp;当然，上面的访问方式也是有缺陷的，主要体现在，读写分离操作对应用程序并不透明，比如有多台读服务器，你的读操作数据源该如何去配置呢？读写分离会影响到应用代码？因此，我们还得寻找另一种对应用透明的访问方式，这就是用代理模式，屏蔽底层访问细节，这个代理类来负责低层的读写分离，缓存连接（相当于连接池），还包括读操作的负载均衡。</p>

<p>&emsp;&emsp;mysql-proxy就是这样一个程序，我下载的是mysql-proxy-0.8.4-win32-x86.zip，解压后运行bin中的mysql-proxy.exe即可。如果mysql-proxy.exe无法运行，可能是缺少vc2008支持包，大家到微软官网下载vcredist_x86.exe并安装。</p>

<p>&emsp;&emsp;为了后期运行方便，可以配置一个bat批处理文件，启动代理程序：</p>

<p><code>
D:\server\db\mysql-proxy\bin\mysql-proxy.exe
 --proxy-backend-addresses=localhost:3307
 --proxy-read-only-backend-addresses=localhost:3308
 --proxy-lua-script=D:\server\db\mysql-proxy\share\doc\mysql-proxy\rw-splitting.lua
</code></p>

<p>&emsp;&emsp;上面的配置中大家要注意：proxy-read-only-backend-addresses可以写多台服务器，用逗号分割开；rw-splitting.lua是读写分离lua脚本文件，您可以进行编辑以符合你的要求（比如有人修改min_idle_connections及max_idle_connections来观察到读写分离的效果），但一般情况下并不需要；你可以通过&mdash;proxy-address=host:port指定代理服务器端口号，如果不指定默认为4040(另，管理端口默认是4041，可以看到一些状态参数)。</p>

<p>&emsp;&emsp;应用程序中通过连接localhost:4040即可操作mysql数据库了，后台的一切都是通过mysql-proxy去处理的，数据库连接对应用程序变得透明了，我们的任务也就完成了。</p>

<p>&emsp;&emsp;下篇给出读写分离的性能测试数据。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[项目中ibatis与hibernate混用示例详解]]></title>
    <link href="http://yanyaner.com/blog/2014/03/06/ibatis-hibernate-in-query/"/>
    <updated>2014-03-06T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/06/ibatis-hibernate-in-query</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;对于一般的项目hibernate足以胜任，但在选择一个框架时都要考虑适用场景（比如非功能性需求），hibernate也不例外，比如：复杂多条件组合查询对于hibernate来说并不方便（我们需要手工拼接sql）。基于这样的原因，很多项目中会引入ibatis来做复杂查询操作以做为补充，这主要是针对编码复杂度的考虑，性能也是其次的一个因素（其实hibernate也不存在问题的，你还记得到hibernater中有SqlQuery么，呵呵）。</p>

<p>&emsp;&emsp;下面我给出一个简单的ibatis与hibernate混用示例，并在最后说明在实际使用过程中应该注意的问题。先来看spring的核心配置文件：</p>

<p>``` xml spring-core.xml</p>

<pre><code>&lt;!-- 读取配置参数 --&gt;
&lt;bean class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt;
    &lt;property name="location"&gt;
        &lt;value&gt;classpath:database.properties&lt;/value&gt;
    &lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 配置数据源 --&gt;
&lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource"
      init-method="init" destroy-method="close"
&gt;
    &lt;property name="driverClassName"&gt;
        &lt;value&gt;${driverClassName}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="url"&gt;
        &lt;value&gt;${url}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="username"&gt;
        &lt;value&gt;${username}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="password"&gt;
        &lt;value&gt;${pwd}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="defaultAutoCommit"&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="initialSize" value="1" /&gt;
    &lt;property name="filters" value="stat,log4j" /&gt;
    &lt;property name="name" value="myDatasource1"&gt;&lt;/property&gt;
    &lt;!-- 最大活动连接数，也就是连接池中的最大缓存连接数 --&gt;
    &lt;property name="maxActive" value="20" /&gt;
    &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt;
    &lt;property name="timeBetweenEvictionRunsMillis" value="10000" /&gt;
    &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt;
    &lt;property name="minEvictableIdleTimeMillis" value="10000" /&gt;
    &lt;property name="minIdle" value="1" /&gt; 


&lt;/bean&gt;

&lt;!-- hibernate参数配置文件，包括缓存的信息 --&gt;
&lt;bean id="hibernateProperties" class="org.springframework.beans.factory.config.PropertiesFactoryBean"&gt;
    &lt;property name="location"&gt;
        &lt;value&gt;classpath:hibernate-config.properties&lt;/value&gt;
    &lt;/property&gt;
&lt;/bean&gt;


&lt;!--  配置sessionFactory--&gt;
&lt;bean id="sessionFactory" class="org.springframework.orm.hibernate3.annotation.AnnotationSessionFactoryBean"&gt;
    &lt;property name="dataSource"&gt;
        &lt;ref bean="dataSource" /&gt;
    &lt;/property&gt;
    &lt;property name="hibernateProperties" ref="hibernateProperties"&gt;&lt;/property&gt;
    &lt;property name="packagesToScan"&gt;
        &lt;list&gt;
            &lt;value&gt;com.my.monitor.model&lt;/value&gt;
        &lt;/list&gt;
    &lt;/property&gt; 
&lt;/bean&gt;

&lt;!-- 配置事务管理器 --&gt;
&lt;bean id="transactionManager"
    class="org.springframework.orm.hibernate3.HibernateTransactionManager"&gt;
    &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 对注解事务的支持 --&gt;
&lt;tx:annotation-driven transaction-manager="transactionManager" /&gt;

&lt;!-- 注解驱动 --&gt;
&lt;context:component-scan base-package="com.my.monitor" &gt;&lt;/context:component-scan&gt; 

&lt;!-- hibernate通用dao --&gt;
&lt;bean id="hibernateBaseDao"
    class="com.my.ms.framework.persistence.hibernate.BaseDaoHibernateImpl"&gt;
    &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- ibatis通用dao，一般用于查询 --&gt;
&lt;bean id="ibatisBaseDao" class="com.my.ms.framework.persistence.ibatis.BaseDao"&gt;
    &lt;property name="sqlMapClient"&gt;
        &lt;bean class="org.springframework.orm.ibatis.SqlMapClientFactoryBean"&gt;
            &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;
            &lt;property name="configLocation"&gt;
                &lt;value&gt;classpath:config/ibatis/sqlMapConfig.xml&lt;/value&gt;
            &lt;/property&gt;
        &lt;/bean&gt;
    &lt;/property&gt;
&lt;/bean&gt;
</code></pre>

<p>```</p>

<p>&emsp;&emsp;这里封装了两个baseDao，分别针对的是hibernate与ibatis书写，源代码如下：<!-- more --></p>

<p>``` java BaseDaoHibernateImpl.java
package com.my.ms.framework.persistence.hibernate;</p>

<p>import java.io.Serializable;
import java.util.ArrayList;
import java.util.List;</p>

<p>import org.hibernate.HibernateException;
import org.hibernate.Query;
import org.hibernate.Session;
import org.springframework.orm.hibernate3.HibernateCallback;
import org.springframework.orm.hibernate3.support.HibernateDaoSupport;
import org.springframework.util.Assert;</p>

<p>import com.my.ms.framework.persistence.model.Page;</p>

<p>public class BaseDaoHibernateImpl extends HibernateDaoSupport implements</p>

<pre><code>    IBaseDao {

@Override
public void addEntity(Object entity) {
    getHibernateTemplate().save(entity);
}

@Override
public void updateEntity(Object entity) {
    getHibernateTemplate().update(entity);
}

@Override
public void deleteEntity(Object entity) {
    getHibernateTemplate().delete(entity);
}

@Override
public void deleteEntityById(Class clazz, Serializable id) {
    getHibernateTemplate().delete(this.queryEntityById(clazz, id));
}

@Override
public &lt;T&gt; T queryEntityById(Class&lt;T&gt; clazz, Serializable id) {
    return getHibernateTemplate().get(clazz, id);
}

@Override
public List queryEntitys(String queryString, Object[] values) {
    return getHibernateTemplate().find(queryString, values);
}

@Override
public Page queryEntityByPage(int pageNo, int pageSize, String queryString,
        Object[] parameters) {
    Assert.isTrue(pageNo &gt; 0, "起始页不能小于0！");
    // 去除select 子句，未考虑union的情况
    int beginPos = queryString.toLowerCase().indexOf("from");
    Assert.isTrue(beginPos != -1, queryString + "无效，必须包含from关键字");
    String hql4Count = " select count(*)  "
            + queryString.substring(beginPos);
    return queryEntityByPage(pageNo, pageSize, queryString, hql4Count,
            parameters);
}

@Override
public Page queryEntityByPage(final int pageNo, final int pageSize,
        final String queryString4Data, final String queryString4Count,
        final Object[] parameters) {
    Assert.hasText(queryString4Count, "用于计数的hql不能为空!");
    Assert.hasText(queryString4Data, "用于查询的hql不能为空！");
    Assert.isTrue(pageNo &gt; 0, "起始页不能小于0！");
    return (Page) getHibernateTemplate().execute(new HibernateCallback() {

        public Object doInHibernate(Session session)
                throws HibernateException {

            // 根据指定的参数执行hibernate hql查询
            List countlist = getHibernateTemplate().find(queryString4Count,
                    parameters);

            long totalCount = ((Long) countlist.get(0)).longValue();
            // 如果记录总数小于1则返回空的Page
            if (totalCount &lt; 1)
                return new Page(pageNo, pageSize, new ArrayList(), 0);
            int startIndex = Page.getStartOfPage(pageNo, pageSize);
            Query query = getSession().createQuery(queryString4Data);
            for (int i = 0; i &lt; parameters.length; i++) {
                query.setParameter(i, parameters[i]);
            }
            List list = query.setFirstResult(startIndex)
                    .setMaxResults(pageSize).list();
            return new Page(pageNo, pageSize, list, (int) totalCount);
        }

    });
}
</code></pre>

<p>}</p>

<p>```</p>

<p>针对ibatis的baseDao封装，主要是添加了一个分页方法，代码如下：</p>

<p>``` java BaseDao.java</p>

<p>package com.my.ms.framework.persistence.ibatis;</p>

<p>import java.util.Map;</p>

<p>import org.springframework.orm.ibatis.SqlMapClientTemplate;</p>

<p>import com.my.ms.framework.persistence.model.Page;</p>

<p>public class BaseDao extends SqlMapClientTemplate {</p>

<pre><code>/**
 * 分页查询(sql语句块中的分页参数，请使用start与end)
 * @param pageNo
 * @param pageSize
 * @param sqlId4Data
 * @param sqlId4count
 * @param queryParam
 * @return
 */
public Page queryEntityByPage(int pageNo, int pageSize, String sqlId4Data, String sqlId4Count, Map queryParam) {

    queryParam.put("start", (pageNo - 1) * pageSize);
    queryParam.put("end", pageSize);

    Page page = new Page(pageNo, pageSize);

    page.setData(queryForList(sqlId4Data, queryParam));
    page.setRowcounts(((Number)queryForObject(sqlId4Count, queryParam)).intValue());

    return page;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;上面两个实现的分页部分，用到了Page对象，请看分页对象的代码：</p>

<p>``` java</p>

<p>package com.my.ms.framework.persistence.model;</p>

<p>import java.util.List;</p>

<p>/<em>*
 * 分页对象
 * @author ljh
 *
 </em>/
public class Page<T> {</p>

<pre><code>/**
 * 数据对象
 */
private List&lt;T&gt; data;

private int rowcounts;
/**
 * 页码
 */
private int pageNo;
/**
 * 最大显示页数
 */
private int pageSize;

public Page(){

}

public Page(int pageNo, int pageSize) {
    this.pageNo = pageNo;
    this.pageSize = pageSize;
}

public Page(int pageNo, int pageSize, List&lt;T&gt; data, int rowcounts) {
    this.pageNo = pageNo;
    this.pageSize = pageSize;
    this.data = data;
    this.rowcounts = rowcounts;
}

//计算该页对应的数据库下标
public static int getStartOfPage(int pageNo, int pageSize) {
    if (0 &gt; pageNo)
        throw new IllegalArgumentException("页面索引不能小于0!");
    return (pageNo - 1) * pageSize;
}


//共有多少页
public int getPages() {
    if (rowcounts % pageSize == 0) 
    {
        return rowcounts/pageSize;
    } else {
        return rowcounts/pageSize + 1;
    }
}

public int getFirstNo() {
    return 1;
}

public int getLastNo() {
    return getPages();
}

public int getPreNo() {
    if (pageNo - 1 &gt; 0 ) {
        return pageNo - 1;
    } else {
        return 1;
    }
} 

public int getNextNo() {
    if (pageNo + 1  &lt;= getPages()) {
        return pageNo + 1;
    }
    return getPages();
}



public List&lt;T&gt; getData() {
    return data;
}

public void setData(List&lt;T&gt; data) {
    this.data = data;
}

public int getPageNo() {
    return pageNo;
}

public void setPageNo(int pageNo) {
    this.pageNo = pageNo;
}

public int getPageSize() {
    return pageSize;
}

public void setPageSize(int pageSize) {
    this.pageSize = pageSize;
}

public int getRowcounts() {
    return rowcounts;
}

public void setRowcounts(int rowcounts) {
    this.rowcounts = rowcounts;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;具体使用时就比较方便了，下面是一个调用示例：</p>

<p>``` java UserServiceImpl.java</p>

<p>@Service
@Transactional(readOnly=false)
public class UserServiceImpl implements IUserService{</p>

<pre><code>@Resource
private IBaseDao hibernateDao;

@Resource
private BaseDao ibatisDao;

@Override
public User someBizMethod(int userId) {

    ......

    User u1 = (User)hibernateDao.queryEntityById(User.class, userId);
    u1.setUserName(u2.getUserName() + "hibernate");
    hibernateDao.updateEntity(u1);

    User u2 = (User)ibatisDao.queryForObject("znjk.getUserById", userId);
    u2.setUserName(u2.getUserName() + "ibatis");
    ibatisDao.update("znjk.updateUser",  u2);

    ......
</code></pre>

<p>```</p>

<p>&emsp;&emsp;好了，在上面的示例中还存在一些必须要弄明白的问题。</p>

<p>&emsp;&emsp;一、事务管理问题。大家可以看到，我在spring文件中只配置了一个事务管理器，并且是hibernate的事务管理器，那么，有人就有会疑问：hibernater的事务可以应用在ibatis的dao上么？答案是肯定的。至于原因，你想想spring事务管理是通过AOP来实现的，并且最终映射到底层的话，事务是通过在jdbc的connection上完成的，而在我上面的这个业务方法中，两个dao拿到的是同一个连接，因此，方法中的所有操作都在一个事务环境中了，这个事务是通过hibernate事务管理器启动的。</p>

<p>&emsp;&emsp;二、缓存同步问题。两个框架都有自己不同的缓存配置及实现，而且互不相关。因为这个原因，我上面的代码没法对保证缓存的一致性，所以，我的建议是：ibatis仅仅只做复杂查询，hibernate什么都可以做。此外，还有一个方案是，配置ibatis的数据源事务管理器，在不同的方法中，通过@Transactional注解来指定这个业务方法使用的事务管理器（比如：@Transactional(readOnly=false,value=&ldquo;dataSourceTransactionManager&rdquo;)），也就是说，在每一个方法中不存在两个dao混用的情况，而在不同的方法中，用不同的事务管理器操作事务的提交。</p>

<p>&emsp;&emsp;ibatis的优势在于查询，特别是类似下面的组合查询，十分的方便。复杂查询更是如此。</p>

<p>``` xml
<sql id="where4pet"></p>

<pre><code>    &lt;dynamic prepend="where"&gt;
        &lt;isNotNull property="nickName" prepend="and"&gt;
            f_nick_name like '%$nickName$%'
        &lt;/isNotNull&gt;
        &lt;isNotNull property="password" prepend="and"&gt;
            f_password like '%$password$%'
        &lt;/isNotNull&gt;
        &lt;isNotNull property="birthday" prepend="and"&gt;
            f_birthday = #birthday#
        &lt;/isNotNull&gt;
        &lt;isNotNull property="gender" prepend="and"&gt;
            &lt;isEqual compareProperty="gender" compareValue="true"&gt;
                f_gender = 'T'
            &lt;/isEqual&gt;
            &lt;isEqual compareProperty="gender" compareValue="false"&gt;
                f_gender = 'F'
            &lt;/isEqual&gt;
        &lt;/isNotNull&gt;
        &lt;isNotNull property="age" prepend="and"&gt;
            f_age = #age#
        &lt;/isNotNull&gt;
    &lt;/dynamic&gt;
&lt;/sql&gt;

&lt;select id="getPetByPage4data" resultMap="resultMapPet" &gt;
    select *
    from t_pet
    &lt;include refid="where4pet"/&gt;
    order by $field$
    limit #start#, #end#
&lt;/select&gt;
&lt;select id="getPetByPage4count" resultClass="int"&gt;
    select count(*)
    from t_pet
    &lt;include refid="where4pet"/&gt;
&lt;/select&gt;
</code></pre>

<p>```</p>

<p>&emsp;&emsp;这样的话，我们就可以充分利用不同框架的优势，达到取长补短的目的。也许你会说，这种方式就是把增、删、改交由hibernate来做，把查询交由ibatis来做。本质上看确实如此，但实际项目中要灵活去做，比如hibernate除了增删改外也可以做查询，特别是简单的查询，这样也可以更好的利用到hibernate的缓存。</p>

<p>&emsp;&emsp;我在<a href="/blog/2010/11/01/p4">四种持久层设计方案比较</a>中，对查询的分离有所介绍，有兴趣的可以去看看其中的一个方案，另外，CQRS架构、mysql读写分离也有这方面的含义。</p>
]]></content>
  </entry>
  
</feed>
