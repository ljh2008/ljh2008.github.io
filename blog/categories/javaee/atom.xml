<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[☺分类☺：javaEE | 刘江华的博客]]></title>
  <link href="http://yanyaner.com/blog/categories/javaee/atom.xml" rel="self"/>
  <link href="http://yanyaner.com/"/>
  <updated>2014-03-28T19:34:27+08:00</updated>
  <id>http://yanyaner.com/</id>
  <author>
    <name><![CDATA[冰雨]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[缓存之redis]]></title>
    <link href="http://yanyaner.com/blog/2014/03/27/cache-redis/"/>
    <updated>2014-03-27T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/27/cache-redis</id>
    <content type="html"><![CDATA[<p><span class='caption-wrapper'><img class='caption' src='/uploads/2014/03/redis.jpg' width='' height='' title=''><span class='caption-text'></span></span></p>

<p>&emsp;&emsp;缓存在软件系统中有着不可替代的作用，特别是访问量巨大的网站，我们对系统热点数据的缓存将会降低数据库的压力，提高系统性能。目前常用的缓存大致分为本地缓存和独立的缓存服务，本地缓存常用的有ehcached,oscached等，而独立的服务器缓存常用的有memcached、redis等。</p>

<p>&emsp;&emsp;Redis is an open source, BSD licensed, advanced key-value store. It is often referred to as a data structure server since keys can contain strings, hashes, lists, sets and sorted sets.</p>

<p>&emsp;&emsp;这是redis官网<a href="http://redis.io/">redis.io</a>对redis的描述，我们从中可以看出，它是一个高性能的、更加高级的key-value缓存服务器。其中的更加高级，可能是相对于memcached这种简单的缓存服务器而言。比如redis可以在不取回缓存对象的情况下，通过指令直接对缓存的数字类型进行加、减操作，也可以对缓存的list进行修改操作，也可以对缓存的字符串进行直接的修改操作等等，这些操作都不需要取回缓存中的数据，因此没有序列化、反序列化的开销，性能会更高。还有redis对一些复杂数据结构的支持，可以满足一些特定场景下的需求。</p>

<p>&emsp;&emsp;当然更高级、先进的redis，在功能强大的同时也增加了自身的复杂性。复杂可不是什么好事情，复杂的东西可能会给我们带来烦恼，实践证明，真正能够解决问题的东西一般都是简单的。因此，就redis和memcached而言，后者功能简单也更容易使用，这就造成了memcached在当前依然是缓存服务器中的老大（当然也不能太绝对，我们在实际项目可以根据不同的需求应用场景选择不同的缓存方案）。</p>

<p>&emsp;&emsp;本文是入门级文章，我在讲解redis的同时，也会顺便提到memcached，以便于大家对比。<!-- more --></p>

<p>&emsp;&emsp;先来安装redis，同样以windows系统为例（因为更多同鞋没有安装linux环境）。winodws的安装很简单，下载redis for windows的编译版本（地址在：<a href="http://code.google.com/p/servicestack/downloads/list">http://code.google.com/p/servicestack/downloads/list</a>），这是一个zip压缩包，将这个包解压到某个目录下，运行其中的redis-server.exe即可启动服务器。</p>

<p>&emsp;&emsp;如果你要指定一些额外的配置参数，可以在运行cmd中指定redis的配置文件，比如：</p>

<p>```
redis-server.exe conf/myredis.conf，</p>

<p>```</p>

<p>&emsp;&emsp;这样就可以配置更多的信息了。比如：daemonize，logfile，database，dbfilename，slaveof,loglevel等等，其中有两个参数我要说一下。</p>

<p>&emsp;&emsp;dbfilename参数，这个参数可以指定持久化文件名，默认是dump.rdb。这个参数说明redis可以将内存中缓存的东西进行持久化，如果您缓存服务器宕机重启了，redis可以自动从这个文件中读取数据并恢复至内存中。这个功能在memcached中是没有的，memcached如果重新启动，缓存的数据将全部丢失。话又说回来，缓存的数据一般是来自数据库的，完全可以重新加载，系统在经过一段时间的运行后自然会重新填充到缓存服务器中的。当然，丢失缓存数据这对于一些大数据高并发发的网站来说，也许并不可接受，因为可能在瞬间造成数据库的压力。</p>

<p>&emsp;&emsp;另一个参数是slaveof，这个参数可以指定redis主服务器，也就是说redis可以做成主从结构的，通过这种架构来保证系统的高可用性。当然，memcached也可以做成主从结构，但memcache需要第三方的插件支持（可以下载memcached-repcached并安装）。主从结构可以做到当主服务器发生故障的时候，从服务器可以升级以继续提供服务。</p>

<p>&emsp;&emsp;说到高可用性，另一个问题也要提出来，那就是分布式（即集群），因为缓存的东西都是在内在中的，一台服务器的内在毕竟有限，那我们就得搭建一个服务器集群，在多台服务器上保存缓存的数据（即分片保存）。如何根据客户端的数据key找到集群中的正确的缓存服务器呢(实际项目中更有某台缓存服务器故障下线，或添加新的缓存服务器)？目前的做法是一致性hash，具体算法大家可以去查一下哦。</p>

<p>&emsp;&emsp;对分布式的Redis的访问，java客户端程序Jedis中已有实现，具体代码如下：</p>

<p>``` java</p>

<p>List<JedisShardInfo> jdsInfoList =new ArrayList<JedisShardInfo>();
//集群中的A服务器
JedisShardInfo infoA = new JedisShardInfo(hostA, portA);
//集群中的B服务器
JedisShardInfo infoB = new JedisShardInfo(hostB, portB);</p>

<p>//加入可用结点中
jdsInfoList.add(infoA);
jdsInfoList.add(infoB);</p>

<p>//下面的Hashing.MURMUR_HASH就是由Jedis提供的分布式的hash key算法
ShardedJedisPool pool =new ShardedJedisPool(config, jdsInfoList, Hashing.MURMUR_HASH, Sharded.DEFAULT_KEY_TAG_PATTERN);</p>

<p>ShardedJedis jedis = pool.getResource();</p>

<p>//下面就可以进行操作了哦</p>

<p>```</p>

<p>&emsp;&emsp;下面简单说一下，在java中如何访问redis。现在常用的各户端是jedis,具体的操作我也不想再写了，大家可以从这些方面去体验Redis的独特之处，我贴出网址。</p>

<p>&emsp;&emsp;一、丰富数据类型的支持。<a href="http://www.open-open.com/lib/view/open1385173126448.html">redis中各种数据类型对应的jedis操作命令 </a>.</p>

<p>&emsp;&emsp;二、对字符串的操作。<a href="http://blog.csdn.net/java2000_wl/article/details/8535486">redis &ndash; String字符串操作 </a>.</p>

<p>&emsp;&emsp;三、事务等特性。<a href="http://www.blogways.net/blog/2013/06/02/jedis-demo.html">Redis的Java客户端Jedis的八种调用方式(事务、管道、分布式…)介绍</a>.</p>

<p>&emsp;&emsp;四、其它的一些特殊用途，比如跨jvm主键生成器等。<a href="http://www.blogjava.net/masfay/archive/2012/07/03/382080.html">Jedis使用总结【pipeline】【分布式的id生成器】【分布式锁【watch】【multi】】【redis分布式】</a>.</p>

<p>&emsp;&emsp;大家要注意的是，大部分Jedis api的操作上传入的参数都是String或byte[],如果我们需要把对象放入redis中去，必须对对象进行序列化，而从redis中读出来又得反序列化，比如下面的代码：</p>

<p>``` java</p>

<p>tx.set(&ldquo;key_user1&rdquo;.getBytes(),
SerializationUtils.serialize(u));</p>

<p>User u = (User)SerializationUtils.deserialize(
jedis.get(&ldquo;key_user1&rdquo;.getBytes()));
```</p>

<p>&emsp;&emsp;其中SerializationUtils是由spring core提供的，你也可以使用apache工具包中提供的类似功能类，或都自己用对象流实现也是一样的。</p>

<p>&emsp;&emsp;另外，如果使用spring框架，可以使用<a href="http://projects.spring.io/spring-data-redis/#quick-start">spring-data-redis</a>，spring data redis提供了几个常用的redis客户端的封装，以在高层面抽像出统一的使用接口，建议在spring项目中采用这种方式。</p>

<p>&emsp;&emsp;同时，taobao也开源了自己redis客户端<a href="https://github.com/taobao/tedis">tedis</a>，据说具有更好的性能和可用性，tedis还提供了object的高层api，使用起来更为方便。另外，taobao开源了很多的软件系统，对于中国的开源界来说是一件很好的事，相比腾讯这些自私的公司，品质不在一个档次。但alib系统的开源源代码中似乎都不写什么注释说明的（比如druid连接池开源代码），也许是这些牛人太忙了，也许是写了注释也没人会去看吧，呵呵。</p>

<p>&emsp;&emsp;好,redis的内容先简单介绍到这吧。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[读写分离架构之mysql实例]]></title>
    <link href="http://yanyaner.com/blog/2014/03/10/db-read-write-split/"/>
    <updated>2014-03-10T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/10/db-read-write-split</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;读写分离架构对提升系统性能非常重要，特别是在互联网项目中，查询操作可能达到90%以上，而且有较高的并发性。</p>

<p>&emsp;&emsp;对于数据库的读写分离，即是把所有的增、删、改操作发送到主数据库，所有查询操作发送到从数据库，通过增加从数据库实例个数以提升查询性能。当然也可以使用noSql数据库(如mongodb,hbase等)、搜索引擎（如lucene）等技术来做查询，关系数据库做核心数据保存，这种方式也是基于读写分离架构。</p>

<p>&emsp;&emsp;更多性能优化文章，大家可以参考我的文章：
<a href="/blog/2010/11/05/prof-web/">系统性能优化总结之表现层</a>，<a href="/blog/2010/11/08/prof-service/">系统性能优化总结之业务层</a>，<a href="/blog/2010/11/09/prof-dao/">系统性能优化总结之持久层篇</a>，技术在不断发展，这三篇文章是几年前写的，目前看来少了很多东西，我后续将把一些近年来新的内容添加上去以符合一些新的场景。</p>

<p>&emsp;&emsp;目前很多数据库都支持主从复制，读写分离，如：Oracle， SqlServer， Mysql等，主数据库在写入数据时同时同步到从数据库。此文以mysql为例给大家加以介绍。网上也有很多这样的文章，大家可以去搜索阅读，但这些文章基本上都是基于*inux平台的，我将以windows平台的配置为例（其实原理都是一样的，只是配置上的一些差异而已）。</p>

<p>&emsp;&emsp;简单起见，机器用我的笔记本。localhost:3307为主服务器master，localhost:3308为从属服务器slave（可以增加多个slave），mysql版本为5.6。先配置主服务器，编辑my.ini，内容如下：<!-- more--></p>

<p>``` ini</p>

<p>[mysqld]
 basedir =D:/server/db/MySQL Server5.6
 datadir =D:/server/db/mysql_db1/dbfile
 port = 3307
 server_id = 1
 log-bin=mysql-bin</p>

<p> skip-character-set-client-handshake
 init-connect = &lsquo;SET NAMES utf8&rsquo;
 character_set_server=utf8
 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</p>

<p>```</p>

<p>&emsp;&emsp;从属数据库配置是(和主服务器的差别在于port、server_id与datadir不同)：</p>

<p><code>ini
[mysqld]
 basedir =D:/server/db/MySQL Server5.6
 datadir =D:/server/db/mysql_db2/dbfile
 port = 3308
 server_id = 10
 log-bin=mysql-bin
 skip-character-set-client-handshake
 init-connect = 'SET NAMES utf8'
 character_set_server=utf8
 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
</code></p>

<p>&emsp;&emsp;为了方便启动，把这两个数据库都注册为win服务，命令如下：</p>

<p>```
 D:\server\db\MySQL Server5.6\bin>mysqld
 &mdash;install mysql5.6.master
 &mdash;defaults-file=D:\server\db\mysql_db1\my.ini</p>

<p>```</p>

<p>&emsp;&emsp;从属服务器的注册与之类似不在写出，我们接下来在系统服务中分别启动这两个服务器实例。</p>

<p>&emsp;&emsp;再接下来要做的事情是配置主从复制功能，主服务器的增、删、改数据操作都将同步到多台从属服务器上，先在主服务器上给从属服务器分配登录账号，这个账号将是从属服务器进行数据同步操作的授权，命令如下（账号是backup，密码是123）：</p>

<p>```
GRANT REPLICATION SLAVE ON
<em>.</em> to &lsquo;backup&rsquo;@&lsquo;localhost&rsquo;
identified by &lsquo;123’;</p>

<p>```</p>

<p>&emsp;&emsp;继续命令行中运行：show master status; 记录下File及Position两个输出内容，这两个参数在配置slave时需要用到。</p>

<p>&emsp;&emsp;登录从服务器，执行下面的命令：</p>

<p><code>
change master to
master_host=’localhost’,
master_port=3307,
master_user=’backup’,
master_password=’123’,
master_log_file=’mysql-bin.000006’,
master_log_pos=120;
</code></p>

<p>&emsp;&emsp;上面命令中的master_host及master_port是主服务器的地址和端口号，master_user及master_password是授权命令输入的账号、密码，master_log_file及master_log_pos是show master status输出的东西。</p>

<p>&emsp;&emsp;接下来，从属服务器上运行start slave就可以启动从属服务，运行show slave status\G查看状态，如果输出的Slave_IO_Running和Slave_SQL_Running都是yes，则表示配置成功（如果配置有误，可stop slave服务，再次运行change master命令）。</p>

<p>&emsp;&emsp;至此，mysql的主从复制功能就配置完成了。也许你会说，我们的所有增、删、改通过对localhost:3307这个数据库操作，查询通过localhost:3308这个数据库操作不就完成了么？确实如你所说，这种方案是可行的，我们可以在spring中配置两个Datasource，并在技术架构上进行处理，把查询接口单独封装出来以使用不同的数据源。大家可以到我的博客文章<a href="/blog/2010/11/01/p4/">四种持久层设计方案比较</a>中，查看其中的方案三设计。</p>

<p>&emsp;&emsp;当然，上面的访问方式也是有缺陷的，主要体现在，读写分离操作对应用程序并不透明，比如有多台读服务器，你的读操作数据源该如何去配置呢？读写分离会影响到应用代码？因此，我们还得寻找另一种对应用透明的访问方式，这就是用代理模式，屏蔽底层访问细节，这个代理类来负责低层的读写分离，缓存连接（相当于连接池），还包括读操作的负载均衡。</p>

<p>&emsp;&emsp;mysql-proxy就是这样一个程序，我下载的是mysql-proxy-0.8.4-win32-x86.zip，解压后运行bin中的mysql-proxy.exe即可。如果mysql-proxy.exe无法运行，可能是缺少vc2008支持包，大家到微软官网下载vcredist_x86.exe并安装。</p>

<p>&emsp;&emsp;为了后期运行方便，可以配置一个bat批处理文件，启动代理程序：</p>

<p><code>
D:\server\db\mysql-proxy\bin\mysql-proxy.exe
 --proxy-backend-addresses=localhost:3307
 --proxy-read-only-backend-addresses=localhost:3308
 --proxy-lua-script=D:\server\db\mysql-proxy\share\doc\mysql-proxy\rw-splitting.lua
</code></p>

<p>&emsp;&emsp;上面的配置中大家要注意：proxy-read-only-backend-addresses可以写多台服务器，用逗号分割开；rw-splitting.lua是读写分离lua脚本文件，您可以进行编辑以符合你的要求（比如有人修改min_idle_connections及max_idle_connections来观察到读写分离的效果），但一般情况下并不需要；你可以通过&mdash;proxy-address=host:port指定代理服务器端口号，如果不指定默认为4040(另，管理端口默认是4041，可以看到一些状态参数)。</p>

<p>&emsp;&emsp;应用程序中通过连接localhost:4040即可操作mysql数据库了，后台的一切都是通过mysql-proxy去处理的，数据库连接对应用程序变得透明了，我们的任务也就完成了。</p>

<p>&emsp;&emsp;下篇给出读写分离的性能测试数据。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[项目中ibatis与hibernate混用示例详解]]></title>
    <link href="http://yanyaner.com/blog/2014/03/06/ibatis-hibernate-in-query/"/>
    <updated>2014-03-06T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/06/ibatis-hibernate-in-query</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;对于一般的项目hibernate足以胜任，但在选择一个框架时都要考虑适用场景（比如非功能性需求），hibernate也不例外，比如：复杂多条件组合查询对于hibernate来说并不方便（我们需要手工拼接sql）。基于这样的原因，很多项目中会引入ibatis来做复杂查询操作以做为补充，这主要是针对编码复杂度的考虑，性能也是其次的一个因素（其实hibernate也不存在问题的，你还记得到hibernater中有SqlQuery么，呵呵）。</p>

<p>&emsp;&emsp;下面我给出一个简单的ibatis与hibernate混用示例，并在最后说明在实际使用过程中应该注意的问题。先来看spring的核心配置文件：</p>

<p>``` xml spring-core.xml</p>

<pre><code>&lt;!-- 读取配置参数 --&gt;
&lt;bean class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt;
    &lt;property name="location"&gt;
        &lt;value&gt;classpath:database.properties&lt;/value&gt;
    &lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 配置数据源 --&gt;
&lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource"
      init-method="init" destroy-method="close"
&gt;
    &lt;property name="driverClassName"&gt;
        &lt;value&gt;${driverClassName}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="url"&gt;
        &lt;value&gt;${url}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="username"&gt;
        &lt;value&gt;${username}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="password"&gt;
        &lt;value&gt;${pwd}&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="defaultAutoCommit"&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;property name="initialSize" value="1" /&gt;
    &lt;property name="filters" value="stat,log4j" /&gt;
    &lt;property name="name" value="myDatasource1"&gt;&lt;/property&gt;
    &lt;!-- 最大活动连接数，也就是连接池中的最大缓存连接数 --&gt;
    &lt;property name="maxActive" value="20" /&gt;
    &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt;
    &lt;property name="timeBetweenEvictionRunsMillis" value="10000" /&gt;
    &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt;
    &lt;property name="minEvictableIdleTimeMillis" value="10000" /&gt;
    &lt;property name="minIdle" value="1" /&gt; 


&lt;/bean&gt;

&lt;!-- hibernate参数配置文件，包括缓存的信息 --&gt;
&lt;bean id="hibernateProperties" class="org.springframework.beans.factory.config.PropertiesFactoryBean"&gt;
    &lt;property name="location"&gt;
        &lt;value&gt;classpath:hibernate-config.properties&lt;/value&gt;
    &lt;/property&gt;
&lt;/bean&gt;


&lt;!--  配置sessionFactory--&gt;
&lt;bean id="sessionFactory" class="org.springframework.orm.hibernate3.annotation.AnnotationSessionFactoryBean"&gt;
    &lt;property name="dataSource"&gt;
        &lt;ref bean="dataSource" /&gt;
    &lt;/property&gt;
    &lt;property name="hibernateProperties" ref="hibernateProperties"&gt;&lt;/property&gt;
    &lt;property name="packagesToScan"&gt;
        &lt;list&gt;
            &lt;value&gt;com.my.monitor.model&lt;/value&gt;
        &lt;/list&gt;
    &lt;/property&gt; 
&lt;/bean&gt;

&lt;!-- 配置事务管理器 --&gt;
&lt;bean id="transactionManager"
    class="org.springframework.orm.hibernate3.HibernateTransactionManager"&gt;
    &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- 对注解事务的支持 --&gt;
&lt;tx:annotation-driven transaction-manager="transactionManager" /&gt;

&lt;!-- 注解驱动 --&gt;
&lt;context:component-scan base-package="com.my.monitor" &gt;&lt;/context:component-scan&gt; 

&lt;!-- hibernate通用dao --&gt;
&lt;bean id="hibernateBaseDao"
    class="com.my.ms.framework.persistence.hibernate.BaseDaoHibernateImpl"&gt;
    &lt;property name="sessionFactory" ref="sessionFactory"&gt;&lt;/property&gt;
&lt;/bean&gt;

&lt;!-- ibatis通用dao，一般用于查询 --&gt;
&lt;bean id="ibatisBaseDao" class="com.my.ms.framework.persistence.ibatis.BaseDao"&gt;
    &lt;property name="sqlMapClient"&gt;
        &lt;bean class="org.springframework.orm.ibatis.SqlMapClientFactoryBean"&gt;
            &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt;
            &lt;property name="configLocation"&gt;
                &lt;value&gt;classpath:config/ibatis/sqlMapConfig.xml&lt;/value&gt;
            &lt;/property&gt;
        &lt;/bean&gt;
    &lt;/property&gt;
&lt;/bean&gt;
</code></pre>

<p>```</p>

<p>&emsp;&emsp;这里封装了两个baseDao，分别针对的是hibernate与ibatis书写，源代码如下：<!-- more --></p>

<p>``` java BaseDaoHibernateImpl.java
package com.my.ms.framework.persistence.hibernate;</p>

<p>import java.io.Serializable;
import java.util.ArrayList;
import java.util.List;</p>

<p>import org.hibernate.HibernateException;
import org.hibernate.Query;
import org.hibernate.Session;
import org.springframework.orm.hibernate3.HibernateCallback;
import org.springframework.orm.hibernate3.support.HibernateDaoSupport;
import org.springframework.util.Assert;</p>

<p>import com.my.ms.framework.persistence.model.Page;</p>

<p>public class BaseDaoHibernateImpl extends HibernateDaoSupport implements</p>

<pre><code>    IBaseDao {

@Override
public void addEntity(Object entity) {
    getHibernateTemplate().save(entity);
}

@Override
public void updateEntity(Object entity) {
    getHibernateTemplate().update(entity);
}

@Override
public void deleteEntity(Object entity) {
    getHibernateTemplate().delete(entity);
}

@Override
public void deleteEntityById(Class clazz, Serializable id) {
    getHibernateTemplate().delete(this.queryEntityById(clazz, id));
}

@Override
public &lt;T&gt; T queryEntityById(Class&lt;T&gt; clazz, Serializable id) {
    return getHibernateTemplate().get(clazz, id);
}

@Override
public List queryEntitys(String queryString, Object[] values) {
    return getHibernateTemplate().find(queryString, values);
}

@Override
public Page queryEntityByPage(int pageNo, int pageSize, String queryString,
        Object[] parameters) {
    Assert.isTrue(pageNo &gt; 0, "起始页不能小于0！");
    // 去除select 子句，未考虑union的情况
    int beginPos = queryString.toLowerCase().indexOf("from");
    Assert.isTrue(beginPos != -1, queryString + "无效，必须包含from关键字");
    String hql4Count = " select count(*)  "
            + queryString.substring(beginPos);
    return queryEntityByPage(pageNo, pageSize, queryString, hql4Count,
            parameters);
}

@Override
public Page queryEntityByPage(final int pageNo, final int pageSize,
        final String queryString4Data, final String queryString4Count,
        final Object[] parameters) {
    Assert.hasText(queryString4Count, "用于计数的hql不能为空!");
    Assert.hasText(queryString4Data, "用于查询的hql不能为空！");
    Assert.isTrue(pageNo &gt; 0, "起始页不能小于0！");
    return (Page) getHibernateTemplate().execute(new HibernateCallback() {

        public Object doInHibernate(Session session)
                throws HibernateException {

            // 根据指定的参数执行hibernate hql查询
            List countlist = getHibernateTemplate().find(queryString4Count,
                    parameters);

            long totalCount = ((Long) countlist.get(0)).longValue();
            // 如果记录总数小于1则返回空的Page
            if (totalCount &lt; 1)
                return new Page(pageNo, pageSize, new ArrayList(), 0);
            int startIndex = Page.getStartOfPage(pageNo, pageSize);
            Query query = getSession().createQuery(queryString4Data);
            for (int i = 0; i &lt; parameters.length; i++) {
                query.setParameter(i, parameters[i]);
            }
            List list = query.setFirstResult(startIndex)
                    .setMaxResults(pageSize).list();
            return new Page(pageNo, pageSize, list, (int) totalCount);
        }

    });
}
</code></pre>

<p>}</p>

<p>```</p>

<p>针对ibatis的baseDao封装，主要是添加了一个分页方法，代码如下：</p>

<p>``` java BaseDao.java</p>

<p>package com.my.ms.framework.persistence.ibatis;</p>

<p>import java.util.Map;</p>

<p>import org.springframework.orm.ibatis.SqlMapClientTemplate;</p>

<p>import com.my.ms.framework.persistence.model.Page;</p>

<p>public class BaseDao extends SqlMapClientTemplate {</p>

<pre><code>/**
 * 分页查询(sql语句块中的分页参数，请使用start与end)
 * @param pageNo
 * @param pageSize
 * @param sqlId4Data
 * @param sqlId4count
 * @param queryParam
 * @return
 */
public Page queryEntityByPage(int pageNo, int pageSize, String sqlId4Data, String sqlId4Count, Map queryParam) {

    queryParam.put("start", (pageNo - 1) * pageSize);
    queryParam.put("end", pageSize);

    Page page = new Page(pageNo, pageSize);

    page.setData(queryForList(sqlId4Data, queryParam));
    page.setRowcounts(((Number)queryForObject(sqlId4Count, queryParam)).intValue());

    return page;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;上面两个实现的分页部分，用到了Page对象，请看分页对象的代码：</p>

<p>``` java</p>

<p>package com.my.ms.framework.persistence.model;</p>

<p>import java.util.List;</p>

<p>/<em>*
 * 分页对象
 * @author ljh
 *
 </em>/
public class Page<T> {</p>

<pre><code>/**
 * 数据对象
 */
private List&lt;T&gt; data;

private int rowcounts;
/**
 * 页码
 */
private int pageNo;
/**
 * 最大显示页数
 */
private int pageSize;

public Page(){

}

public Page(int pageNo, int pageSize) {
    this.pageNo = pageNo;
    this.pageSize = pageSize;
}

public Page(int pageNo, int pageSize, List&lt;T&gt; data, int rowcounts) {
    this.pageNo = pageNo;
    this.pageSize = pageSize;
    this.data = data;
    this.rowcounts = rowcounts;
}

//计算该页对应的数据库下标
public static int getStartOfPage(int pageNo, int pageSize) {
    if (0 &gt; pageNo)
        throw new IllegalArgumentException("页面索引不能小于0!");
    return (pageNo - 1) * pageSize;
}


//共有多少页
public int getPages() {
    if (rowcounts % pageSize == 0) 
    {
        return rowcounts/pageSize;
    } else {
        return rowcounts/pageSize + 1;
    }
}

public int getFirstNo() {
    return 1;
}

public int getLastNo() {
    return getPages();
}

public int getPreNo() {
    if (pageNo - 1 &gt; 0 ) {
        return pageNo - 1;
    } else {
        return 1;
    }
} 

public int getNextNo() {
    if (pageNo + 1  &lt;= getPages()) {
        return pageNo + 1;
    }
    return getPages();
}



public List&lt;T&gt; getData() {
    return data;
}

public void setData(List&lt;T&gt; data) {
    this.data = data;
}

public int getPageNo() {
    return pageNo;
}

public void setPageNo(int pageNo) {
    this.pageNo = pageNo;
}

public int getPageSize() {
    return pageSize;
}

public void setPageSize(int pageSize) {
    this.pageSize = pageSize;
}

public int getRowcounts() {
    return rowcounts;
}

public void setRowcounts(int rowcounts) {
    this.rowcounts = rowcounts;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;具体使用时就比较方便了，下面是一个调用示例：</p>

<p>``` java UserServiceImpl.java</p>

<p>@Service
@Transactional(readOnly=false)
public class UserServiceImpl implements IUserService{</p>

<pre><code>@Resource
private IBaseDao hibernateDao;

@Resource
private BaseDao ibatisDao;

@Override
public User someBizMethod(int userId) {

    ......

    User u1 = (User)hibernateDao.queryEntityById(User.class, userId);
    u1.setUserName(u2.getUserName() + "hibernate");
    hibernateDao.updateEntity(u1);

    User u2 = (User)ibatisDao.queryForObject("znjk.getUserById", userId);
    u2.setUserName(u2.getUserName() + "ibatis");
    ibatisDao.update("znjk.updateUser",  u2);

    ......
</code></pre>

<p>```</p>

<p>&emsp;&emsp;好了，在上面的示例中还存在一些必须要弄明白的问题。</p>

<p>&emsp;&emsp;一、事务管理问题。大家可以看到，我在spring文件中只配置了一个事务管理器，并且是hibernate的事务管理器，那么，有人就有会疑问：hibernater的事务可以应用在ibatis的dao上么？答案是肯定的。至于原因，你想想spring事务管理是通过AOP来实现的，并且最终映射到底层的话，事务是通过在jdbc的connection上完成的，而在我上面的这个业务方法中，两个dao拿到的是同一个连接，因此，方法中的所有操作都在一个事务环境中了，这个事务是通过hibernate事务管理器启动的。</p>

<p>&emsp;&emsp;二、缓存同步问题。两个框架都有自己不同的缓存配置及实现，而且互不相关。因为这个原因，我上面的代码没法对保证缓存的一致性，所以，我的建议是：ibatis仅仅只做复杂查询，hibernate什么都可以做。此外，还有一个方案是，配置ibatis的数据源事务管理器，在不同的方法中，通过@Transactional注解来指定这个业务方法使用的事务管理器（比如：@Transactional(readOnly=false,value=&ldquo;dataSourceTransactionManager&rdquo;)），也就是说，在每一个方法中不存在两个dao混用的情况，而在不同的方法中，用不同的事务管理器操作事务的提交。</p>

<p>&emsp;&emsp;ibatis的优势在于查询，特别是类似下面的组合查询，十分的方便。复杂查询更是如此。</p>

<p>``` xml
<sql id="where4pet"></p>

<pre><code>    &lt;dynamic prepend="where"&gt;
        &lt;isNotNull property="nickName" prepend="and"&gt;
            f_nick_name like '%$nickName$%'
        &lt;/isNotNull&gt;
        &lt;isNotNull property="password" prepend="and"&gt;
            f_password like '%$password$%'
        &lt;/isNotNull&gt;
        &lt;isNotNull property="birthday" prepend="and"&gt;
            f_birthday = #birthday#
        &lt;/isNotNull&gt;
        &lt;isNotNull property="gender" prepend="and"&gt;
            &lt;isEqual compareProperty="gender" compareValue="true"&gt;
                f_gender = 'T'
            &lt;/isEqual&gt;
            &lt;isEqual compareProperty="gender" compareValue="false"&gt;
                f_gender = 'F'
            &lt;/isEqual&gt;
        &lt;/isNotNull&gt;
        &lt;isNotNull property="age" prepend="and"&gt;
            f_age = #age#
        &lt;/isNotNull&gt;
    &lt;/dynamic&gt;
&lt;/sql&gt;

&lt;select id="getPetByPage4data" resultMap="resultMapPet" &gt;
    select *
    from t_pet
    &lt;include refid="where4pet"/&gt;
    order by $field$
    limit #start#, #end#
&lt;/select&gt;
&lt;select id="getPetByPage4count" resultClass="int"&gt;
    select count(*)
    from t_pet
    &lt;include refid="where4pet"/&gt;
&lt;/select&gt;
</code></pre>

<p>```</p>

<p>&emsp;&emsp;这样的话，我们就可以充分利用不同框架的优势，达到取长补短的目的。也许你会说，这种方式就是把增、删、改交由hibernate来做，把查询交由ibatis来做。本质上看确实如此，但实际项目中要灵活去做，比如hibernate除了增删改外也可以做查询，特别是简单的查询，这样也可以更好的利用到hibernate的缓存。</p>

<p>&emsp;&emsp;我在<a href="/blog/2010/11/01/p4">四种持久层设计方案比较</a>中，对查询的分离有所介绍，有兴趣的可以去看看其中的一个方案，另外，CQRS架构、mysql读写分离也有这方面的含义。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[再次简单封装的jackson]]></title>
    <link href="http://yanyaner.com/blog/2014/03/04/objectmapper-json/"/>
    <updated>2014-03-04T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/04/objectmapper-json</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;接上一篇<a href="/blog/2014/03/03/objectmapper-json">Json类库jackson使用之误区</a>，我对json的常用操作再次进行了简单的封装，上一版的封装大家可参阅<a href="/blog/2012/12/14/jackson">Jackson之json类二次封装</a>。</p>

<p>&emsp;&emsp;总计两个文件，只考虑到了一些简单常用的操作：</p>

<p>``` java FilterProvider.java</p>

<p>package com.my.ms.framework.commons;</p>

<p>import org.codehaus.jackson.map.ser.impl.SimpleBeanPropertyFilter;
import org.codehaus.jackson.map.ser.impl.SimpleFilterProvider;
/<em>*
 * 属性过滤器
 * @author ljh
 *
 </em>/
public class FilterProvider extends SimpleFilterProvider {</p>

<pre><code>/**
 * 将新的需要的属性添加到一个现有的FilterProvider中
 * @param id
 * @param includeProperties
 * @return
 */
public FilterProvider addIncludeProperties(String id,
        String... includeProperties) {
    this.addFilter(id,
            SimpleBeanPropertyFilter.filterOutAllExcept(includeProperties));
    return this;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;FilterProvider.java中主要增加了一个输出时添加包含属性的方法，并返回自身以支持方法链编程。<!-- more --></p>

<p>``` java JsonMapper.java</p>

<p>package com.my.ms.framework.commons;</p>

<p>import java.io.IOException;
import java.io.OutputStream;
import java.text.SimpleDateFormat;</p>

<p>import org.codehaus.jackson.JsonGenerationException;
import org.codehaus.jackson.map.DeserializationConfig;
import org.codehaus.jackson.map.JsonMappingException;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jackson.map.SerializationConfig.Feature;
import org.codehaus.jackson.map.ser.impl.SimpleBeanPropertyFilter;
import org.codehaus.jackson.map.ser.impl.SimpleFilterProvider;</p>

<p>/<em>*
 * json之jackson封装
 * 主要对常用的几个json方法进行了再次包装，并具备线程安全性
 * @author ljh
 *
 </em>/
public class JsonMapper {</p>

<pre><code>private ObjectMapper objectMapper;

public JsonMapper() {
    objectMapper = new ObjectMapper();
    // 设置默认日期格式
    objectMapper.setDateFormat(new SimpleDateFormat("yyyy-MM-dd"));
    // 提供其它默认设置
    objectMapper
            .disable(DeserializationConfig.Feature.FAIL_ON_UNKNOWN_PROPERTIES);
    objectMapper.configure(Feature.FAIL_ON_EMPTY_BEANS, false);
    objectMapper.setFilters(new SimpleFilterProvider()
            .setFailOnUnknownId(false));

}

/**
 * 创建一个FilterProvider对象
 * 
 * @return
 */
public static FilterProvider buildFilterProvider() {
    FilterProvider filter = new FilterProvider();
    filter.setFailOnUnknownId(false);
    return filter;
}

/**
 * 根据需要的对象属性，创建一个属性过滤器FilterProvider
 * 
 * @param id
 *            对象id，通过jsonFilter声明
 * @param includeProperties
 *            该对象上需要的属性
 * @return  创建好的过滤器
 */
public static FilterProvider buildFilterProvider(String id,
        String... includeProperties) {
    FilterProvider filter = new FilterProvider();
    filter.setFailOnUnknownId(false);

    filter.addFilter(id,
            SimpleBeanPropertyFilter.filterOutAllExcept(includeProperties));
    return filter;
}

// 用提供的过滤器，将对象的json输出到流中
public void writeValue(FilterProvider filter, OutputStream os, Object value)
        throws JsonGenerationException, JsonMappingException, IOException {
    objectMapper.writer(filter).writeValue(os, value);
}

// 用提供的过滤器，将对象的json输出为字符串
public String writeValueAsString(FilterProvider filter, Object value)
        throws JsonGenerationException, JsonMappingException, IOException {
    return objectMapper.writer(filter).writeValueAsString(value);
}

// 将对象的json输出到流中
public void writeValue(OutputStream os, Object value)
        throws JsonGenerationException, JsonMappingException, IOException {
    objectMapper.writeValue(os, value);
}

// 将对象的json输出为字符串
public String writeValueAsString(Object value)
        throws JsonGenerationException, JsonMappingException, IOException {
    return objectMapper.writeValueAsString(value);
}

/**
 * 得到原始的objectMapper，以进行更复杂的操作
 * 
 * @return
 */
public ObjectMapper getObjectMapper() {
    return objectMapper;
}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;如果需要更强大的功能，我们可以通过getObjectMapper得到ObjectMapper后进行操作，或都添加你常用的其它方法到JsonMapper中，比如：排除属性的方法等。</p>

<p>&emsp;&emsp;使用时，请把JsonMapper放入spring容器(当然你也可以把这个类做成单例的哦)，在需要转换json的地方，通过@Resource注入即可，调用代码如下：</p>

<p>``` java</p>

<pre><code>@Resource
private JsonMapper mapper;

@Test
public void testJson() throws Exception {

    Object someObject = ....

    String result = mapper.writeValueAsString(
            JsonMapper.buildFilterProvider()
            .addIncludeProperties("myId1", "id","name")
            .addIncludeProperties("myId2", "code","money","name"), 
            someObject);

    assertEquals("xxxxxxxxxxxx", result);

}
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[json类库jackson使用之误区]]></title>
    <link href="http://yanyaner.com/blog/2014/03/03/objectmapper-json/"/>
    <updated>2014-03-03T12:18:00+08:00</updated>
    <id>http://yanyaner.com/blog/2014/03/03/objectmapper-json</id>
    <content type="html"><![CDATA[<p>&emsp;&emsp;json数据类型在系统通讯中得到了非常广泛的应用，jsonlib, Gson, fastJson, jackson等开源的json操作类库层出不穷，根据对这些json的测试，我们发现jsckson的效率比其它的都要高。但在实际中，我发现很多人使用jackson都存在一定的问题，下面我给大家讲讲jackson使用中容易出现的一些问题。</p>

<p>&emsp;&emsp;先来看看下面的这一段代码，很多人在控制器代码中就是这么写的：</p>

<p>``` java
/**</p>

<pre><code> * 得到所有的班级
 * 
 * @param sid
 * @param resp
 * @throws Exception
 */

@RequestMapping(value = "/classes", method = RequestMethod.GET)
public void getAllClasses(HttpServletResponse resp) throws Exception {

    ObjectMapper om = new ObjectMapper();

    RespMessage msg = new RespMessage();

    SimpleFilterProvider filterProvider = new SimpleFilterProvider()
            .setFailOnUnknownId(false);
    filterProvider.addFilter("my_classes",
            SimpleBeanPropertyFilter.filterOutAllExcept("id", "name"));
    om.setFilters(filterProvider);

    List&lt;Classes&gt; data = systemService.getAllClasses();

    msg.setData(data);

    om.writeValue(resp.getOutputStream(), msg);

}
</code></pre>

<p>```</p>

<p>&emsp;&emsp;晃眼一看，似乎没有问题，但是，这段代码在高并发操作下，性能非常的低下。有人说，这个容易，改一下代码即可，如下：<!-- more --></p>

<p>``` java</p>

<pre><code>private ObjectMapper om = new ObjectMapper();

/**
 * 得到所有的班级
 * 
 * @param sid
 * @param resp
 * @throws Exception
 */
@RequestMapping(value = "/classes", method = RequestMethod.GET)
public void getAllClasses(HttpServletResponse resp) throws Exception {

    ....
    SimpleFilterProvider filterProvider = new SimpleFilterProvider()
            .setFailOnUnknownId(false);
    filterProvider.addFilter("my_classes",
            SimpleBeanPropertyFilter.filterOutAllExcept("id", "name"));
    om.setFilters(filterProvider);
    ....

    om.writeValue(resp.getOutputStream(), msg);

}
</code></pre>

<p>```</p>

<p>&emsp;&emsp;上面的代码中，让ObjectMapper做为全局对象（或者干脆放入spring容器中，保持一个实例），不反复创建这个对象，应该就没有问题了吧。</p>

<p>&emsp;&emsp;不幸的是，上面这段代码仍然存在问题，因为ObjectMapper的全局性，致使过渡属性的操作在多线程中出现问题，请看下面的测试代码：</p>

<p>``` java
public class CopyOfTest {</p>

<pre><code>public static void main(String[] args) {

    ObjectMapper o1 = new ObjectMapper();
    ObjectMapper o2 = o1;

    Thread t1 = new MyThread(o1, 1);
    Thread t2 = new MyThread(o2, 2);

    t1.start();
    t2.start();

}
</code></pre>

<p>}</p>

<p>class MyThread extends Thread {</p>

<pre><code>private ObjectMapper om;

private int threadId;

public MyThread(ObjectMapper om, int threadId) {
    this.om = om;
    this.threadId = threadId;
}

//产生1秒内的随机暂停
private void pauseRandomTimes() {
    try {
        Thread.sleep((long)Math.ceil(Math.random()*1000));
    } catch (InterruptedException e1) {
        e1.printStackTrace();
    }
}

@Override
public void run() {

    Student s = new Student();
    s.setId(1);
    s.setName("张三");

    for (int i = 0; i &lt; 10 ; i++) {


        if (threadId == 1)   {
            SimpleFilterProvider filterProvider = new SimpleFilterProvider().setFailOnUnknownId(false);
            filterProvider.addFilter("myStudent", SimpleBeanPropertyFilter.filterOutAllExcept("id"));
            om.setFilters(filterProvider);
            try {
                //随机休眠一段时间
                pauseRandomTimes();
                System.out.println("线程1中的输出是：" + om.writeValueAsString(s));
            } catch (Exception e) {
                e.printStackTrace();
            }
        } else {
            SimpleFilterProvider filterProvider = new SimpleFilterProvider().setFailOnUnknownId(false);
            filterProvider.addFilter("myStudent", SimpleBeanPropertyFilter.filterOutAllExcept("id","name"));
            om.setFilters(filterProvider);
            try {
                //随机休眠一段时间
                pauseRandomTimes();
                System.out.println("线程2中的输出是：" + om.writeValueAsString(s));
            } catch (Exception e) {
                e.printStackTrace();
            }
        }

    }

}
</code></pre>

<p>}</p>

<p>```</p>

<p>&emsp;&emsp;上面的这段多线程测试程序中，本计划在线程1中只输入对象的id属性，线程2中输出id、name两个属性，但通过下面的结果，我们发现事与愿违，两个线程中的输出混乱了，这就是共享了一个ObjectMapper并通过om.setFilters造成的原因。</p>

<p>```</p>

<p>线程2中的输出是：{&ldquo;id&rdquo;:1}
线程2中的输出是：{&ldquo;id&rdquo;:1,&ldquo;name&rdquo;:&ldquo;张三&rdquo;}
线程2中的输出是：{&ldquo;id&rdquo;:1,&ldquo;name&rdquo;:&ldquo;张三&rdquo;}
线程2中的输出是：{&ldquo;id&rdquo;:1,&ldquo;name&rdquo;:&ldquo;张三&rdquo;}
线程1中的输出是：{&ldquo;id&rdquo;:1,&ldquo;name&rdquo;:&ldquo;张三&rdquo;}
线程2中的输出是：{&ldquo;id&rdquo;:1}
线程1中的输出是：{&ldquo;id&rdquo;:1,&ldquo;name&rdquo;:&ldquo;张三&rdquo;}
线程1中的输出是：{&ldquo;id&rdquo;:1}
线程1中的输出是：{&ldquo;id&rdquo;:1}
线程1中的输出是：{&ldquo;id&rdquo;:1}
线程2中的输出是：{&ldquo;id&rdquo;:1}
线程1中的输出是：{&ldquo;id&rdquo;:1,&ldquo;name&rdquo;:&ldquo;张三&rdquo;}
线程1中的输出是：{&ldquo;id&rdquo;:1}
线程2中的输出是：{&ldquo;id&rdquo;:1}
线程2中的输出是：{&ldquo;id&rdquo;:1,&ldquo;name&rdquo;:&ldquo;张三&rdquo;}
线程1中的输出是：{&ldquo;id&rdquo;:1,&ldquo;name&rdquo;:&ldquo;张三&rdquo;}
线程2中的输出是：{&ldquo;id&rdquo;:1}
线程2中的输出是：{&ldquo;id&rdquo;:1,&ldquo;name&rdquo;:&ldquo;张三&rdquo;}
线程1中的输出是：{&ldquo;id&rdquo;:1,&ldquo;name&rdquo;:&ldquo;张三&rdquo;}
线程1中的输出是：{&ldquo;id&rdquo;:1}</p>

<p>```</p>

<p>&emsp;&emsp;如何改造达到我们的要求呢？如下即可，但这又会造成并发下的性能问题。</p>

<p>``` java
ObjectMapper o1 = new ObjectMapper();
ObjectMapper o2 = new ObjectMapper();
Thread t1 = new My2Thread(o1, 1);
Thread t2 = new My2Thread(o2, 2);</p>

<p>```</p>

<p>&emsp;&emsp;最终的做法是：</p>

<p>&emsp;&emsp;1、将ObjectMapper作为全局；</p>

<p>&emsp;&emsp;2、通过om.writer(filterProvider).write&hellip;.. 的方式输出。即保证性能，出满足多线程。</p>

<p>&emsp;&emsp;最后，看一看两种写法的性能测试结果：</p>

<p>``` java
public static void main1(String[] args) {</p>

<pre><code>    Student s = new Student();
    s.setId(1);
    s.setName("张三");

    System.out.println("开始执行.....");
    long start = System.currentTimeMillis();

    ObjectMapper om;
    for (int i = 0; i &lt; 10000; i ++ ) {
        om = new ObjectMapper();
        SimpleFilterProvider filterProvider = new SimpleFilterProvider().setFailOnUnknownId(false);
        filterProvider.addFilter("myStudent", SimpleBeanPropertyFilter.filterOutAllExcept("id","name"));
        om.setFilters(filterProvider);
        try {
            om.writeValueAsString(s);
        } catch (Exception e) {
            e.printStackTrace();
        } 

    }
    long end = System.currentTimeMillis();
    System.out.println("执行所花时间：" + (end - start) + "ms.");


}
</code></pre>

<p>```
&emsp;&emsp;这段测试代码的输出是：执行所花时间：6078ms.</p>

<p>&emsp;&emsp;而另一种写法的测试代码如下：</p>

<p>``` java</p>

<p>public static void main(String[] args) {</p>

<pre><code>    Student s = new Student();
    s.setId(1);
    s.setName("张三");

    System.out.println("开始执行.....");
    long start = System.currentTimeMillis();

    ObjectMapper om = new ObjectMapper();
    for (int i = 0; i &lt; 10000; i ++ ) {
        SimpleFilterProvider filterProvider = new SimpleFilterProvider().setFailOnUnknownId(false);
        filterProvider.addFilter("myStudent", SimpleBeanPropertyFilter.filterOutAllExcept("id","name"));
        try {
            om.writer(filterProvider).writeValueAsString(s);
        } catch (Exception e) {
            e.printStackTrace();
        } 

    }
    long end = System.currentTimeMillis();
    System.out.println("执行所花时间：" + (end - start) + "ms.");
}
</code></pre>

<p>```</p>

<p>&emsp;&emsp;这段测试代码的输出是：执行所花时间：547ms.同样的功能，不同的实现代码，时间差距非常巨大，所以，大家在实际编码须注意到这个问题。</p>

<p>&emsp;&emsp;大家可以对ObjectMapper进行简单封装，具体请参阅我的另一篇文章<a href="/blog/2012/12/14/jackson">Jackson之json类二次封装</a>。</p>
]]></content>
  </entry>
  
</feed>
